\documentclass[a4paper, 12pt]{article}

% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{lstautogobble}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{tipa}
\usepackage{pgfplots}
\usepackage{adjustbox}
\usepackage{dsfont}

% tikz libraries
\usetikzlibrary{
    decorations.pathreplacing,
    arrows,
    shapes,
    shapes.gates.logic.US,
    circuits.logic.US,
    calc,
    automata,
    positioning,
    intersections
}

\pgfplotsset{compat=1.16}

\pgfmathdeclarefunction{gauss}{2}{%
  \pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%
}

\allowdisplaybreaks % allow environments to break
\setlength\parindent{0pt} % no indent

% shorthand for verbatim
% this clashes with logicproof, so maybe fix this at some point?
\catcode`~=\active
\def~#1~{\texttt{#1}}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\newcommand{\dollar}{\mbox{\textdollar}} %
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\pdif}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\lim_{#1 \to #2}}$}}}
\newcommand{\limitsup}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\limsup_{#1 \to #2}}$}}}
\newcommand{\summation}[2]{\sum\limits_{#1}^{#2}}
\newcommand{\product}[2]{\prod\limits_{#1}^{#2}}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}
\newcommand{\laplace}{\mathcal{L}}
\newcommand{\fourier}{\mathcal{F}}
\newcommand{\mat}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\rowt}[1]{\begin{bmatrix}
    #1
\end{bmatrix}^\top}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\lto}[0]{\leadsto\ }

\newcommand{\ulsmash}[1]{\underline{\smash{#1}}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}

\makeatletter
\newsavebox{\@brx}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother
\newcommand{\lla}{\llangle}
\newcommand{\rra}{\rrangle}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\crnr}[1]{\text{\textopencorner} #1 \text{\textcorner}}
\newcommand{\bnfsep}[0]{\ |\ }
\newcommand{\concsep}[0]{\ ||\ }

\newcommand{\axiom}[1]{\AxiomC{#1}}
\newcommand{\unary}[1]{\UnaryInfC{#1}}
\newcommand{\binary}[1]{\BinaryInfC{#1}}
\newcommand{\trinary}[1]{\TrinaryInfC{#1}}
\newcommand{\quaternary}[1]{\QuaternaryInfC{#1}}
\newcommand{\quinary}[1]{\QuinaryInfC{#1}}
\newcommand{\dproof}[0]{\DisplayProof}
\newcommand{\llabel}[1]{\LeftLabel{\scriptsize #1}}
\newcommand{\rlabel}[1]{\RightLabel{\scriptsize #1}}

\newcommand{\ttbs}{\char`\\}
\newcommand{\lrbt}[0]{\ \bullet\ }

% colours
\newcommand{\violet}[1]{\textcolor{violet}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\teal}[1]{\textcolor{teal}{#1}}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofmath}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% ER diagrams
\newcommand{\nattribute}[4]{
    \node[draw, state, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\mattribute}[4]{
    \node[draw, state, accepting, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\dattribute}[4]{
    \node[draw, state, dashed, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\entity}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 0.5)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -0.5)$) {};
    \draw
    ($(#1-c) + (-1, 0.5)$) -- ($(#1-c) + (1, 0.5)$) -- ($(#1-c) + (1, -0.5)$) -- ($(#1-c) + (-1, -0.5)$) -- cycle;
}
\newcommand{\relationship}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 1)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -1)$) {};
    \draw
    ($(#1-c) + (-1, 0)$) -- ($(#1-c) + (0, 1)$) -- ($(#1-c) + (1, 0)$) -- ($(#1-c) + (0, -1)$) -- cycle;
}

% AVL Trees
\newcommand{\avltri}[4]{
    \draw ($(#1)$) -- ($(#1) + #4*(0.5, -1)$) -- ($(#1) + #4*(-0.5, -1)$) -- cycle;
    \node at ($(#1) + #4*(0, -1) + (0, 0.5)$) {#3};
    \node at ($(#1) + #4*(0, -1) + (0, -0.5)$) {#2};
}

% RB Trees
\tikzset{rbtr/.style={inner sep=2pt, circle, draw=black, fill=red}}
\tikzset{rbtb/.style={inner sep=2pt, circle, draw=black, fill=black}}

% Samples
\tikzset{spos/.style={inner sep=2pt, circle, draw=black, fill=blue!20}}
\tikzset{sneg/.style={inner sep=2pt, circle, draw=black, fill=red!20}}

% Joins
\newcommand\ljoin{\stackrel{\mathclap{\normalfont\mbox{\tiny L}}}{\bowtie}}
\newcommand\rjoin{\stackrel{\mathclap{\normalfont\mbox{\tiny R}}}{\bowtie}}
\newcommand\ojoin{\stackrel{\mathclap{\normalfont\mbox{\tiny O}}}{\bowtie}}

\setcounter{MaxMatrixCols}{100}

% actual document
\begin{document}
    {\sc Computing $4^\text{th}$ Year Notes} \hfill ~https://github.com/lin-e/imperial-revision~
    \rule{\textwidth}{0.1pt}
    \section*{Mathematics for Machine Learning \hfill (70015)}
        \subsection*{Lecture 1.1 - Linear Regression Intro}
            Linear regression aims to provide a solution to the supervised learning problem; we are given a dataset of $N$ examples of inputs and expected outputs, with a goal of predicting the correct output for a new input.
            Examples of this include image classification (such as digit classification) and translation.
            A curve fitting problem in 1-dimension has an input space $\in \mathbb{R}$, and an output space $\in \mathbb{R}$.
            \medskip

            To tackle this problem mathematically, we need to first describe the curve fitting problem mathematically.
            As each input is associated with a single output, this is equivalent to a function in mathematics.
            We are given a dataset of $N$ pairs, of inputs and outputs, where $\vec{x_n} \in \mathcal{X}$, which is usually $\mathbb{R}^D$ and $y_n \in \mathcal{Y}$ (usually $\mathbb{R}$ in this case); $\{(\vec{x_n}, y_n)\}_{n = 1}^N$.
            The goal is to find a function that maps from the input space to the output space \textbf{well}; $f : \mathcal{X} \to \mathcal{Y}$.
            \medskip

            We need to first find candidates for functions that can perform the predictions.
            Functions need to be parameterised, such that some numbers $\vec{\theta}$ map to a function.
            From here, we need to pick the `best' function, thus requiring us to define what good and bad functions are.
            A good function has the property $f(\vec{x_i}, \vec{\theta^*}) \approx y_i$; the output of the function closely matches the outputs of the training points.
            This can be defined with a \textbf{loss function}, for example;
            $$L(\vec{\theta}) = \summation{i = 1}{N} (y_i - f(\vec{x_i}, \vec{\theta}))^2$$
            Therefore, a good function is chosen by minimising the loss; $\vec{\theta^*} = \argmin_{\vec{\theta}}L(\vec{\theta})$.
        \subsection*{Lecture 1.2 - Scalar Differentiation}
            We can plot the loss against the parameters for a function.
            This raises two questions; how to change the parameter to make the loss smaller and how we know if we can't get a better loss.
            The derivative is defined as the limit of the difference quotient (as usual);
            $$f^\prime(x) = \dif{f}{x} = \limit{h}{0} \frac{f(x + h) - f(x)}{h}$$
            Several examples of this are as follows;
            \begin{center}
                \begin{tabular}{c|c}
                    $f(x)$ & $f^\prime(x)$ \\
                    \hline
                    $x^n$ & $nx^{n - 1}$ \\
                    $\sin(x)$ & $\cos(x)$ \\
                    $\tanh(x)$ & $1 - \tanh^2(x)$ \\
                    $e^x = \exp(x)$ & $e^x$ \\
                    $\log(x)$ & $\frac{1}{x}$
                \end{tabular}
            \end{center}
            There are also the following rules which combine the basic functions;
            \begin{itemize}
                \itemsep0em
                \item sum rule \hfill describes the derivative of sum of two functions
                    $$(f(x) + g(x))^\prime = f^\prime(x) + g^\prime(x)$$
                \item product rule \hfill similarly, for multiplication
                    $$(f(x)g(x))^\prime = f^\prime(x)g(x) + f(x)g^\prime(x)$$
                \item chain rule \hfill describes how to differentiate functions that are composed
                    $$(g \circ f)^\prime(x) = (g(f(x)))^\prime = g^\prime(f(x))f^\prime(x)$$
                \item quotient rule \hfill describes division, special case of the product rule
                    $$\left(\frac{f(x)}{g(x)}\right)^\prime = \frac{f^\prime(x)g(x) - f(x)g^\prime(x)}{(g(x))^2}$$
            \end{itemize}
            This tells us how to change the input in the function; the gradient tells us how much the output changes based on an increase in the input.
            We first compute the derivative function at a point to find the point's gradient.
            If the gradient is negative, this tells us the function will decrease if we increase the input (hence increase to minimise), and vice versa; decrease for positive gradients - this is the idea behind gradient descent.
            \medskip

            Similarly, we know we are done (at a minimum for the loss function) when there is nothing that can be done to lower the output, hence the gradient must be 0.
            However, this isn't sufficient to tell us that we have reached a minimum, as a maximum also has a gradient of zero.
            A minimum has a decreasing function followed by an increasing function; hence the gradient of the gradient (second derivative) is positive.
            \medskip

            However, this only gives us a local minima.
            We should be concerned with getting stuck in a local minima (rather than a global minima) when dealing with non-convex functions.
            Working through a simple example, with a linear regression problem (aiming to find an optimal $a$) - the final step takes the second derivative to verify we have a minimum;
            \begin{align*}
                f(x) & = a \cdot x \\
                L(a) & = \summation{n = 1}{N} (f(x_n) - y_n)^2 \\
                \dif{L}{a} & = \summation{n = 1}{N} 2(ax_n - y_n)x_n \\
                & = \summation{n = 1}{N} 2ax_n^2 - 2x_ny_n \\
                & = 0 \\
                2a\summation{n}{} x_n^2 & = \summation{n}{} 2x_ny_n \\
                a & = \frac{\summation{n}{} 2x_ny_n}{\summation{n}{} x_n^2} \\
                \dif{^2L}{a^2} & = \summation{n = 1}{N} 2x_n^2 \\
                & \geq 0
            \end{align*}
        \subsubsection*{Lecture 1.3 - Scalar-by-vector Differentiation}
            The previous example is too simple for real applications - we will need to differentiate by more parameters (vectors).
            Consider the following example, a polynomial, which has 4 vectors parametising it - each vector now corresponds to a single cubic polynomial;
            \begin{align*}
                f(x) & = \theta_3x^3 + \theta_2x^2 + \theta_1x + \theta_0 \\
                & = \vec{\theta}^\top\vec{\phi}(x) \\
                \vec{\phi}(x) & = \begin{bmatrix}
                    x^3 & x^2 & x & 1
                \end{bmatrix}^\top
            \end{align*}
            Our goal still remains to understand how a function changes with our parameter and to characterise what an optimum is for a function of a vector.
            Both of these change a multi-dimensional problem into many 1-dimensional problems.
            \medskip

            We want to change it into a 1-dimensional question; instead of asking about a change to $\vec{\theta}$, we ask what happens when we move along a particular line / direction.
            A directional derivative is how much the function changes, when we move in a direction $\vec{v}$;
            $$\nabla_{\vec{v}}L(\vec{\theta}) = \limit{h}{0}\frac{L(\vec{\theta} + h\vec{v}) - L(\vec{\theta})}{h}$$ % assuming a mistake in the slides, the -L(theta) wasn't there
            The distance that we move away from the starting point ($\vec{\theta}$) is determined by \textbf{both} the norm / scale of the direction vector $\vec{v}$, as well as $h$.
            If we can understand how the function changes based on a change in \textbf{any} direction, we can fully characterise differentiation with respect to a vector.
            \medskip

            Consider the following example, where we deal with two parameters (also notice the second equality holds as the values in \violet{violet} are equal and cancel each other out);
            \begin{align*}
                \nabla_{\vec{v}}L(\vec{\theta}) & = \limit{h}{0}\frac{L(\theta_1 + hv_1, \theta_2 + hv_2) - L(\theta_1, \theta_2)}{h} \\
                & = \limit{h}{0}\underbrace{\frac{L(\theta_1 + hv_1, \theta_2 + hv_2) - \violet{L(\theta_1, \theta_2 + hv_2)}}{h}}_\text{only change in first parameter} + \underbrace{\frac{\violet{L(\theta_1, \theta_2 + hv_2)} - L(\theta_1, \theta_2)}{h}}_\text{only change in second parameter} \\
                & = \limit{h}{0}\frac{L(\theta_1 + h^\prime, \theta_2 + h^\prime\frac{v_2}{v_1}) - \violet{L(\theta_1, \theta_2 + h^\prime\frac{v_2}{v_1})}}{\frac{h^\prime}{v_1}} + \frac{\violet{L(\theta_1, \theta_2 + h^{\prime\prime})} - L(\theta_1, \theta_2)}{\frac{h^{\prime\prime}}{v_2}} \\
                & = \pdif{L}{\theta_1}v_1 + \pdif{L}{\theta_2}v_2
            \end{align*}
            This means that we can find the gradient in any direction with the partial derivatives, as we chose arbitrary $v_1, v_2$.
            With a partial derivative, we change only one coordinate at a time - see the following for a function $f : \mathbb{R}^N \to \mathbb{R}$;
            \begin{align*}
                y & = f(\vec{x}) \\
                x & = \begin{bmatrix}
                    x_1 \\ \vdots \\ x_N
                \end{bmatrix} \\
                \pdif{f}{x_i} & = \limit{h}{0} \frac{f(x_1, \dots, x_{i - 1}, \violet{x_i + h}, x_{i + 1}, \dots, x_N) - f(\vec{x})}{h}
            \end{align*}
            The Jacobian vector collects all partial derivatives into a row vector;
            $$\dif{f}{\vec{x}} = \begin{bmatrix}
                \pdif{f}{x_1} & \cdots & \pdif{f}{x_N}
            \end{bmatrix} \in \mathbb{R}^{1 \times N}$$
            We now want to know which direction to go in, to decrease the value of the function the most.
            The directional derivative can be written as the inner product;
            $$\nabla_{\vec{v}}f(\vec{\theta}) = \dif{f}{\vec{\theta}}\vec{v} = \left|\dif{f}{\vec{\theta}}\right|\left|\vec{v}\right| \cos \beta$$
            We can maximise this by making $\cos \beta$ as large as possible, since the norms of the two vectors are fixed.
            If we choose a unit vector $\vec{v}$, we want the largest value possible, hence $\cos \beta = 1$, so the angle between the vectors should be zero (such that $\beta = 0$).
            As such, we move in the direction of the Jacobian / gradient vector.
            \medskip

            We can reuse the intuition from the 1-D case, where moving in either direction doesn't change your value - the directional derivative should be zero in \textbf{all directions} (hence the zero vector, $\vec{0}$).
            Additionally, to verify it's a minimum, we want the second directional derivative to also be positive in \textbf{all directions}.
\end{document}