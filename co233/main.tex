\documentclass[a4paper, 12pt]{article}
% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{lstautogobble}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{tipa}
\usetikzlibrary{decorations.pathreplacing, arrows, shapes.gates.logic.US, circuits.logic.US, calc, automata, positioning}

% shorthand for verbatim
% this clashes with logicproof, so maybe fix this at some point?
\catcode`~=\active
\def~#1~{\texttt{#1}}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\newcommand{\dollar}{\mbox{\textdollar}} %
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\pdif}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\lim_{#1 \to #2}}$}}}
\newcommand{\summation}[2]{\sum\limits_{#1}^{#2}}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}
\newcommand{\ulsmash}[1]{\underline{\smash{#1}}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}

\makeatletter
\newsavebox{\@brx}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother
\newcommand{\lla}{\llangle}
\newcommand{\rra}{\rrangle}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\rowt}[1]{\begin{bmatrix}
    #1
\end{bmatrix}^\top}

\newcommand{\unaryproof}[2]{\AxiomC{#1} \UnaryInfC{#2} \DisplayProof}
\newcommand{\binaryproof}[3]{\AxiomC{#1} \AxiomC{#2} \BinaryInfC{#3} \DisplayProof}
\newcommand{\trinaryproof}[4]{\AxiomC{#1} \AxiomC{#2} \AxiomC{#3} \TrinaryInfC{#4} \DisplayProof}

\newcommand{\axiom}[1]{\AxiomC{#1}}
\newcommand{\unary}[1]{\UnaryInfC{#1}}
\newcommand{\binary}[1]{\BinaryInfC{#1}}
\newcommand{\trinary}[1]{\TrinaryInfC{#1}}
\newcommand{\quaternary}[1]{\QuaternaryInfC{#1}}
\newcommand{\quinary}[1]{\QuinaryInfC{#1}}
\newcommand{\dproof}[0]{\DisplayProof}

\newcommand{\bnfsep}[0]{\ |\ }
\newcommand{\concsep}[0]{\ ||\ }
\newcommand{\violet}[1]{\textcolor{violet}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}

% no indent
\setlength\parindent{0pt}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofmath}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% reasoning er diagrams
\newcommand{\nattribute}[4]{
    \node[draw, state, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\mattribute}[4]{
    \node[draw, state, accepting, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\dattribute}[4]{
    \node[draw, state, dashed, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\entity}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 0.5)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -0.5)$) {};
    \draw
    ($(#1-c) + (-1, 0.5)$) -- ($(#1-c) + (1, 0.5)$) -- ($(#1-c) + (1, -0.5)$) -- ($(#1-c) + (-1, -0.5)$) -- cycle;
}
\newcommand{\relationship}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 1)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -1)$) {};
    \draw
    ($(#1-c) + (-1, 0)$) -- ($(#1-c) + (0, 1)$) -- ($(#1-c) + (1, 0)$) -- ($(#1-c) + (0, -1)$) -- cycle;
}

% actual document
\begin{document}
    \section*{CO233 - Computational Techniques}
        \subsection*{15th January 2020}
            \subsubsection*{Vector and Matrix Norms}
                An orthonormal basis of $\mathbb{R}^n$ are unit vectors that are pairwise mutually perpendicular; such that for $(e_1, \cdots, e_n)$;
                \begin{itemize}
                    \itemsep0em
                    \item $e_i \cdot e_i = 1$
                    \item $e_i \cdot e_j = 0$, if $i \neq j$
                \end{itemize}
                The standard canonical basis of $\mathbb{R}^3$ are the $i,j,k$ vectors, and similar in $\mathbb{R}^2$.
                However, we can form another orthonormal basis of $\mathbb{R}^2$ by bisecting the angles as such;
                \begin{center}
                    \begin{tikzpicture}
                        \node (y) at (0, 1.3) {$y$};
                        \node (x) at (1.3, 0) {$x$};
                        \node (e1) at (1.3, 1.3) {$e_1$};
                        \node (e2) at (-1.3, 1.3) {$e_2$};
                        \draw
                        (0, -1) edge[->] (0, 1)
                        (-1, 0) edge[->] (1, 0)
                        (-1, -1) edge[->] (1, 1)
                        (1, -1) edge[->] (-1, 1);
                    \end{tikzpicture}
                \end{center}
                If we take a vector $\vec{v} \in \mathbb{R}^n$, the Euclidean norm (or the $\ell_2$-norm) is defined as such;
                \begin{center}
                    $|| \vec{v} ||_2 = \sqrt{\summation{i=1}{n} v_i^2}$
                \end{center}
                A norm, a mapping $|| \cdot || : \mathbb{R}^n \to \mathbb{R}^+$, must satisfy these 3 axioms;
                \begin{enumerate}[(i)]
                    \itemsep0em
                    \item $|| \vec{v} || > 0$ given that $\vec{v} \neq \vec{0}$
                    \item $|| \lambda \vec{v} || = |\lambda|\ || \vec{v} ||$
                    \item $|| \vec{v} + \vec{w} || \leq || \vec{v} || + || \vec{w} ||$ (triangular inequality)
                \end{enumerate}
                Some other ($\ell_p$) norms are defined as follows;
                \begin{align*}
                    \ell_1\text{-norm } || \vec{v} ||_1 & = \summation{i=1}{n}|v_i| \\
                    \ell_\infty\text{-norm } || \vec{v} ||_\infty & = \max \{|v_i| : 1 \leq i \leq n\} \\
                    \ell_p\text{-norm } || \vec{v} ||_p & = \left(\summation{i=1}{n} |v_i|^p\right)^\frac{1}{p}
                \end{align*}
                In each dimension, we have the following;
                \begin{itemize}
                    \itemsep0em
                    \item $n = 1$
                        \begin{itemize}
                            \itemsep0em
                            \item $|| \vec{v} ||_1 = | v | = | v |$
                            \item $|| \vec{v} ||_2 = \sqrt{v^2} = | v |$
                            \item $|| \vec{v} ||_\infty = \max \{| v |\} = | v |$
                        \end{itemize}
                    \item $n = 2$
                        \smallskip

                        We can represent this geometrically as such;
                        \begin{center}
                            \begin{tikzpicture}[x=0.25cm, y=0.25cm]
                                \node at (4, -1) {$v_1$};
                                \node at (-1, 3) {$v_2$};
                                \node at (5, 4) {$\vec{v}$};

                                \draw (0, 0) circle (5);
                                \draw (0, 0) edge[->] (4, 0);
                                \draw (0, 0) edge[->] (0, 3);
                                \draw (0, 0) edge[->] (4, 3);
                            \end{tikzpicture}
                        \end{center}
                        In our case $|| \vec{v} ||_\infty = \max\{ | v_1 |, | v_2 | \} = | v_1 |$, but the point is that it's either of the "sides" of the triangle.
                        Obviously, $|| \vec{v} ||_2 \geq || \vec{v} ||_\infty$, as it's the hypotenuse of the triangle, and similarly, $|| \vec{v} ||_1 \geq || \vec{v} ||_2$, due to the triangle inequality.
                        Therefore we have $|| \vec{v} ||_1 \geq || \vec{v} ||_2 \geq || \vec{v} ||_\infty$.
                        \smallskip

                        Even if the orthonormal base changes, the Euclidean norm stays the same, whereas the other norms can change.
                        As such, we can say the $\ell_2$-norm is invariant under an \textbf{orthogonal transformation} (a basis change from an orthonormal bases to another orthonormal bases).
                    \item $n =\ ?$ (general)
                        \smallskip

                        The goal is to prove $|| \vec{v} ||_\infty \leq || \vec{v} ||_2 \leq || \vec{v} ||_1$.
                        If we first take the squares of all of them, such that we have the following;
                        \begin{align*}
                            || \vec{v} ||_1^2 & = \left(\summation{i = 1}{n} | v_i |\right)^2 \\
                            || \vec{v} ||_2^2 & = \summation{i = 1}{n} | v_i |^2 \\
                            || \vec{v} ||_\infty^2 & = (\max\{| v_i | : 1 \leq i \leq n\})^2 \\
                        \end{align*}
                        Since the $\ell_\infty$-norm corresponds to a single $v_i$, it's obvious that the following inequality holds (since the $\ell_2$-norm squared has all the other terms squared, as well as the $\ell_\infty$-norm squared);
                        \begin{center}
                            $|| \vec{v} ||_2^2 = \summation{i = 1}{n} | v_i |^2 \geq (\max\{| v_i | : 1 \leq i \leq n\})^2 = || \vec{v} ||_\infty^2 \Rightarrow || \vec{v} ||_2 \geq || \vec{v} ||_\infty$
                        \end{center}
                        To prove the other inequality, we see that the square of the sum of absolutes is greater than the sum of the squares, as the square of the sum contains the cross terms (which will be positive).
                        \begin{center}
                            $|| \vec{v} ||_2^2 = \summation{i = 1}{n} | v_i |^2 \leq \left(\summation{i = 1}{n} | v_i |\right)^2 = || \vec{v} ||_\infty^1 \Rightarrow || \vec{v} ||_2 \leq || \vec{v} ||_1$
                        \end{center}
                        As such, we can conclude that $|| \vec{v} ||_\infty \leq || \vec{v} ||_2 \leq || \vec{v} ||_1$ in any dimension. \hfill $\blacksquare$
                \end{itemize}
            \subsubsection*{Tutorial Question}
                Find the locus of vectors such that $|| \vec{v} ||_p \leq 1$, for $p = \red{1}, \blue{2}, \violet{\infty}$ in $n = 2$;
                \begin{center}
                    \begin{tikzpicture}
                        \node at (1.75, 0) {$x$};
                        \node at (0, 1.75) {$y$};

                        \draw[violet] (-1, 1) -- (1, 1) -- (1, -1) -- (-1, -1) -- cycle;
                        \draw[blue] (0, 0) circle (1);
                        \draw[red] (0, 1) -- (1, 0) -- (0, -1) -- (-1, 0) -- cycle;
                        \draw
                        (0, 0) edge[->] (1.5, 0)
                        (0, 0) edge[->] (0, 1.5);
                    \end{tikzpicture}
                \end{center}
                Imagine they're all shaded from the border to the origin.
            \subsubsection*{$\ell_p$-norm}
                Our goal is to show that as $p \to \infty$, we get the definition of the $\ell_\infty$-norm previously stated.
                Take a vector $\vec{v} \in \mathbb{R}^n$, where both $\vec{v}$ and $n$ are fixed.
                \begin{center}
                    $|| \vec{v} ||_p^p = \summation{i = 1}{n} | v_i |^p$
                \end{center}
                Obviously, this is greater than or equal to $|| \vec{v} ||_\infty^p$, as it would only be a single $| v_i |^p$.
                Similarly, it must be less than or equal to $n | v_i |^p$, as $v_i$ is the maximum of all the components.
                \begin{center}
                    $|| \vec{v} ||_\infty^p \leq || \vec{v} ||_p^p = \summation{i = 1}{n} | v_i |^p \leq n || \vec{v} ||_\infty^p$
                \end{center}
                Taking everything to the power of $\frac{1}{p}$, we obtain the following result (note that $p > 0$ hence the signs don't change);
                \begin{center}
                    $|| \vec{v} ||_\infty \leq || \vec{v} ||_p = \leq n^\frac{1}{p} || \vec{v} ||_\infty$
                \end{center}
                As $p \to \infty$, since $n \geq 2$ ($n = 1$ is shown to collapse to the same component), we have $n^\frac{1}{p} \to 1$, which sandwiches the middle term.
            \subsubsection*{Some Proposition ($\ell_\infty$-norm vs $\ell_2$-norm)}
                The proposition is as follows; for a vector $\vec{v} \in \mathbb{R}^n$, $|| \vec{v} ||_2 \leq \sqrt{n} || \vec{v} ||_\infty$.
                To show this, we know that each of $| v_i |$ is less than or equal to $|| \vec{v} ||_\infty$, by definition of the maximum.
                The same can be said for $| v_i |^2$, vs $|| \vec{v} ||_\infty^2$.
                Taking square roots, we have the following;
                \begin{center}
                    $|| \vec{v} ||_2^2 = \summation{i = 1}{n} | v_i |^2 \leq n || \vec{v} ||_\infty^2 \Rightarrow || \vec{v} ||_2 \leq \sqrt{n} || \vec{v} ||_\infty$
                \end{center}
                To show this holds similarly for $|| \vec{v} ||_1 \leq \sqrt{n} || \vec{v} ||_2$, we employ the Cauchy-Schwarz inequality, which states $| \vec{x} \cdot \vec{y} | \leq || \vec{x} ||_2 || \vec{y} ||_2$.
                The Cauchy-Schwarz inequality uses the fact that $\vec{x} \cdot \vec{y} = || \vec{x} ||_2 || \vec{y} ||_2 \cos \theta$.
                To do this, we need to define a sign function $\text{sgn} : \mathbb{R} \to \{1, -1\}$ as follows;
                \begin{align*}
                    \text{sgn}\ x & = \begin{cases}
                        1 & x \geq 0 \\
                        -1 & x < 0
                    \end{cases}
                    \intertext{We also need to craft a vector $\vec{w}$, as follows;}
                    w_i & = \frac{\text{sgn}\ v_i}{\sqrt{n}} & 1 \leq i \leq n \\
                    \vec{v} \cdot \vec{w} & = \summation{i = 1}{n} v_i w_i \\
                    & = \summation{i = 1}{n} \frac{v_i \cdot \text{sgn}\ v_i}{\sqrt{n}} & \text{product of same sign becomes positive} \\
                    & = \summation{i = 1}{n} \frac{| v_i |}{\sqrt{n}} \\
                    & = \sqrt{n} \summation{i = 1}{n} | v_i | \\
                    & = \sqrt{n} || \vec{v} ||_1 \\
                    || \vec{w} ||_2 & = \summation{i = 1}{n} \frac{\pm 1}{\sqrt{n}}^2 \\
                    & = \summation{i = 1}{n} \frac{1}{n} \\
                    & = 1
                \end{align*}
                By \violet{Cauchy-Schwarz}, we get;
                \begin{center}
                    $\sqrt{n} || \vec{v} ||_1 = \violet{| \vec{v} \cdot \vec{w} | \leq || \vec{v} ||_2 || \vec{w} ||_2} = || \vec{v} ||_2$
                \end{center}
        \subsection*{16th January 2020}
            Note that this recording has \textbf{no audio}, and therefore will just be the board transcribed.
            I honestly have no idea what he was doing in this lecture, it seems to just jump from topic to topic.
            \subsubsection*{Equivalence of Norms?}
                Take any two norms on $\mathbb{R}^n$; $|| \cdot ||_a$, and $|| \cdot ||_b$.
                \begin{center}
                    $\exists r, s \in \mathbb{R}^+\ \forall \vec{v} \in \mathbb{R}^n\ [r || \vec{v} ||_b \leq || \vec{v} ||_a \leq s || \vec{v} ||_b]$
                \end{center}
                This means that norms in finite dimensional vector spaces are equivalent (no idea why, look it up).
            \subsubsection*{Convergence of Vector Sequences}
                $(\vec{r}_n)$ is a sequence of vectors, and $(a_{i, j})$ is the $i, j^\text{th}$ entry of $\mat{A}$.
                For a vector $\vec{v}^{(m)} \in \mathbb{R}^n$, where $m = 0, 1, 2, \dots$
                \begin{align*}
                    \vec{v}^{(m)} & = \begin{bmatrix}
                        v_1^{(m)} \\ v_2^{(m)} \\ \vdots \\ v_n^{(m)}
                    \end{bmatrix}
                \end{align*}
                For a vector sequence $\vec{v}^{(m)}$ to converge to some vector $\vec{v} \in \mathbb{R}^n$, the following must hold;
                \begin{center}
                    $\vec{v}^{(m)} \to \vec{v} \in \mathbb{R}^n \Leftrightarrow \limit{m}{\infty} || \vec{v}^{(m)} - \vec{v} || \to 0$
                \end{center}
                This is componentwise convergence, such that $\forall i \in [1, n]\ [v_i^{(m)} \to v_i]$.
            \subsubsection*{Matrix Norms}
                Vectors are a type of matrix.
                For a matrix $\mat{A} \in \mathbb{R}^{m \times n}$, the following properties of its norms must hold, where $|| \cdot || : \mathbb{R}^{m \times n} \to \mathbb{R}_{\geq 0}$;
                \begin{enumerate}[(i)]
                    \itemsep0em
                    \item $|| \mat{A} || > 0$ given that $\mat{A} \neq \mat{0}$
                    \item $|| \lambda \mat{A} || = | \lambda | || \mat{A} ||$
                    \item $|| \mat{A} + \mat{B} || \leq || \mat{A} || + || \mat{B} ||$
                    \item $|| \mat{B} \mat{A} || \leq || \mat{B} || || \mat{A} ||$
                \end{enumerate}
                \begin{center}
                    \begin{tikzpicture}
                        \node (v) at (0, 0) {$\vec{v} \in \mathbb{R}^n$};
                        \node at (0, -0.75) {$|| \cdot ||_a$};
                        \node (av) at (6, 0) {$\mat{A} \vec{v} \in \mathbb{R}^m$};
                        \node at (6, -0.75) {$|| \cdot ||_b$};
                        \node at (3, 0) {$\mat{A}$};
                        \draw
                        (v) edge[->] (2, 0)
                        (4, 0) edge[->] (av)
                        (2, 1) -- (4, 1) -- (4, -1) -- (2, -1) -- cycle;
                    \end{tikzpicture}
                    \medskip

                    $|| \mat{A} \vec{v} ||_b \leq || \mat{A} || || \vec{v} ||_a$
                \end{center}
                For the following example, take $(a_{i,j}) = \mat{A} \in \mathbb{R}^{m \times n}$;
                \begin{align*}
                    a_j & = \begin{bmatrix}
                        a_{1, j} \\ a_{2, j} \\ \vdots \\ a_{m, j}
                    \end{bmatrix} & \text{the $j^\text{th}$ column of $\mat{A}$} \\
                    a^i & = \begin{bmatrix}
                        a_{i, 1} & a_{i, 2} & \cdots & a_{i, n}
                    \end{bmatrix} & \text{the $i^\text{th}$ row of $\mat{A}$}
                \end{align*}
                We have the following norms on matrices;
                \begin{align*}
                    || \mat{A} ||_1 & = \max \{|| a_j ||_1 : 1 \leq j \leq n \} \\
                    || \mat{A} ||_\infty & = \max \{|| (a^i)^\top ||_1 : 1 \leq i \leq m \} \\
                    || \mat{A} ||_F & = \sqrt{\summation{i = 1}{m} \summation{j = 1}{n} | a_{i, j} |^2} & \text{Frobenius norm} \\
                    || \mat{A} ||_2 & = \text{largest singular value of } \mat{A} \\
                    \text{let } \mat{A} & = \begin{bmatrix}
                        2 & 3 & 1 & 4 \\
                        1 & 3 & -1 & 5 \\
                        \sqrt{2} & 0 & -2 & 2
                    \end{bmatrix} \\
                    || \mat{A} ||_1 & = \max \{ 3 + \sqrt{2}, 6, 4, 11 \}
                    \\
                    & = 11 \\
                    || \mat{A} ||_\infty & = \max \{ 10, 10, 4 + \sqrt{2} \} \\
                    & = 10 \\
                    || \mat{A} ||_F & = \sqrt{4 + 9 + 1 + 16 + 1 + 9 + 1 + 25 + 2 + 0 + 4 + 4} \\
                    & = 2 \sqrt{19}
                \end{align*}
\end{document}