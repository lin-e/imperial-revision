\documentclass[a4paper, 12pt]{article}

% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{lstautogobble}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{tipa}
\usepackage{pgfplots}
\usepackage{adjustbox}

% tikz libraries
\usetikzlibrary{
    decorations.pathreplacing,
    arrows,
    shapes,
    shapes.gates.logic.US,
    circuits.logic.US,
    calc,
    automata,
    positioning,
    intersections
}

\pgfplotsset{compat=1.16}

\pgfmathdeclarefunction{gauss}{2}{%
  \pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%
}

\allowdisplaybreaks % allow environments to break
\setlength\parindent{0pt} % no indent

% shorthand for verbatim
% this clashes with logicproof, so maybe fix this at some point?
\catcode`~=\active
\def~#1~{\texttt{#1}}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\newcommand{\dollar}{\mbox{\textdollar}} %
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\pdif}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\lim_{#1 \to #2}}$}}}
\newcommand{\limitsup}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\limsup_{#1 \to #2}}$}}}
\newcommand{\summation}[2]{\sum\limits_{#1}^{#2}}
\newcommand{\product}[2]{\prod\limits_{#1}^{#2}}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}
\newcommand{\laplace}{\mathcal{L}}
\newcommand{\fourier}{\mathcal{F}}
\newcommand{\mat}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\rowt}[1]{\begin{bmatrix}
    #1
\end{bmatrix}^\top}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\lto}[0]{\leadsto\ }

\newcommand{\ulsmash}[1]{\underline{\smash{#1}}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}

\makeatletter
\newsavebox{\@brx}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother
\newcommand{\lla}{\llangle}
\newcommand{\rra}{\rrangle}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\crnr}[1]{\text{\textopencorner} #1 \text{\textcorner}}
\newcommand{\bnfsep}[0]{\ |\ }
\newcommand{\concsep}[0]{\ ||\ }

\newcommand{\axiom}[1]{\AxiomC{#1}}
\newcommand{\unary}[1]{\UnaryInfC{#1}}
\newcommand{\binary}[1]{\BinaryInfC{#1}}
\newcommand{\trinary}[1]{\TrinaryInfC{#1}}
\newcommand{\quaternary}[1]{\QuaternaryInfC{#1}}
\newcommand{\quinary}[1]{\QuinaryInfC{#1}}
\newcommand{\dproof}[0]{\DisplayProof}
\newcommand{\llabel}[1]{\LeftLabel{\scriptsize #1}}
\newcommand{\rlabel}[1]{\RightLabel{\scriptsize #1}}

\newcommand{\ttbs}{\char`\\}
\newcommand{\lrbt}[0]{\ \bullet\ }

% colours
\newcommand{\violet}[1]{\textcolor{violet}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\teal}[1]{\textcolor{teal}{#1}}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofmath}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% ER diagrams
\newcommand{\nattribute}[4]{
    \node[draw, state, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\mattribute}[4]{
    \node[draw, state, accepting, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\dattribute}[4]{
    \node[draw, state, dashed, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\entity}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 0.5)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -0.5)$) {};
    \draw
    ($(#1-c) + (-1, 0.5)$) -- ($(#1-c) + (1, 0.5)$) -- ($(#1-c) + (1, -0.5)$) -- ($(#1-c) + (-1, -0.5)$) -- cycle;
}
\newcommand{\relationship}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 1)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -1)$) {};
    \draw
    ($(#1-c) + (-1, 0)$) -- ($(#1-c) + (0, 1)$) -- ($(#1-c) + (1, 0)$) -- ($(#1-c) + (0, -1)$) -- cycle;
}

% AVL Trees
\newcommand{\avltri}[4]{
    \draw ($(#1)$) -- ($(#1) + #4*(0.5, -1)$) -- ($(#1) + #4*(-0.5, -1)$) -- cycle;
    \node at ($(#1) + #4*(0, -1) + (0, 0.5)$) {#3};
    \node at ($(#1) + #4*(0, -1) + (0, -0.5)$) {#2};
}

% RB Trees
\tikzset{rbtr/.style={inner sep=2pt, circle, draw=black, fill=red}}
\tikzset{rbtb/.style={inner sep=2pt, circle, draw=black, fill=black}}

% Samples
\tikzset{spos/.style={inner sep=2pt, circle, draw=black, fill=blue!20}}
\tikzset{sneg/.style={inner sep=2pt, circle, draw=black, fill=red!20}}

% Joins
\newcommand\ljoin{\stackrel{\mathclap{\normalfont\mbox{\tiny L}}}{\bowtie}}
\newcommand\rjoin{\stackrel{\mathclap{\normalfont\mbox{\tiny R}}}{\bowtie}}
\newcommand\ojoin{\stackrel{\mathclap{\normalfont\mbox{\tiny O}}}{\bowtie}}

\setcounter{MaxMatrixCols}{100}

% actual document
\begin{document}
    {\sc Computing $3^\text{rd}$ Year Notes} \hfill ~https://github.com/lin-e/imperial-revision~
    \rule{\textwidth}{0.1pt}
    \section*{CO317 - Graphics \hfill (60005)}
        \subsection*{Lecture 1 - Projections and Transformations}
            \subsubsection*{Two Dimensional Graphics}
                At the lowest level, in every operating system, graphics processing operates on the pixels in a window with primitives, such as;
                \begin{itemize}
                    \itemsep0em
                    \item ~SetPixel(int x, int y, int colour);~
                    \item ~DrawLine(int xs, int ys, int xf, int yf);~
                \end{itemize}
                However, we'd like to be able to draw scenes from a three-dimensional world and have it appear in two-dimensional graphics primitives.
            \subsubsection*{World Coordinate System}
                In order to achieve independence when drawing objects, we define a world coordinate system.
                For example, let our world be defined in meters, we can then allow a pixel to represent a millimetre.
                A viewing area is a window, and is defined as part of our 3D world.
                \textbf{Clipping} occurs when we attempt to draw outside (dashed) of the \violet{window};
                \begin{lstlisting}
                    SetWindow(30, 10, 70, 50)
                    DrawLine(40, 3, 90, 30)
                    DrawLine(50, 60, 60, 40)
                \end{lstlisting}
                \begin{center}
                    \begin{tikzpicture}[x=0.075cm, y=0.075cm]
                        \draw (0, 0) edge[->] (0, 55);
                        \draw (0, 0) edge[->] (75, 0);

                        \draw[violet] (30, 10) -- (30, 50) -- (70, 50) -- (70, 10) -- cycle;
                        \draw[dashed]
                        (0, 10) -- (30, 10)
                        (0, 50) -- (30, 50)
                        (30, 0) -- (30, 10)
                        (70, 0) -- (70, 10);

                        \draw[dashed]
                        (40, 3) -- (52.963, 10)
                        (70, 19.2) -- (90, 30);
                        \draw (52.963, 10) -- (70, 19.2);

                        \draw[dashed] (50, 60) -- (55, 50);
                        \draw (55, 50) -- (60, 40);

                        \node at (-10, 10) {10};
                        \node at (-10, 50) {50};
                        \node at (30, -10) {30};
                        \node at (70, -10) {70};
                    \end{tikzpicture}
                \end{center}
                However, this isn't as trivial to do in 3D, as it cannot simply be left to the operating system.
                While we can represent 3D objects as a series of 2D commands, it's inefficient and expensive for the OS to perform the clipping (therefore we should do this manually).
            \subsubsection*{Normalisation}
                A normalisation process is required to convert from device independent commands (where screen resolution isn't taken into account) to drawing commands using pixels.
                Consider a point in the world coordinate window $(X_w, Y_w)$, and its corresponding result on the viewport (pixel coordinates; $(X_v, Y_v)$);
                \begin{center}
                    \begin{tikzpicture}[x=0.66cm, y=0.66cm]
                        \draw[rounded corners] (0, 0) -- (16, 0) -- (16, 9) -- (0, 9) -- cycle;

                        \draw (2, 2) -- (6, 2) -- (6, 6) -- (2, 6) -- cycle;
                        \node[rbtb] at (3, 3.5) {};
                        \node at (4, 4) {$(X_v, Y_v)$};

                        \begin{scope}[shift={(-9, 3)}]
                            \draw (0, 0) -- (6, 0) -- (6, 6) -- (0, 6) -- cycle;
                            \node[rbtb] at (1.5, 2.25) {};
                            \node at (2.5, 2.75) {$(X_w, Y_w)$};
                        \end{scope}

                        \draw[dashed]
                        (-9, 3) -- (2, 2)
                        (-3, 3) -- (6, 2)
                        (-3, 9) -- (6, 6)
                        (-9, 9) -- (2, 6)
                        (-9, 3) -- (-9, 0)
                        (-3, 3) -- (-3, 0)
                        (2, 2) -- (2, 0)
                        (6, 2) -- (6, 0);

                        \node at (-9, -1) {$W_{xmin}$};
                        \node at (-3, -1) {$W_{xmax}$};
                        \node at (2, -1) {$V_{xmin}$};
                        \node at (6, -1) {$V_{xmax}$};
                    \end{tikzpicture}
                \end{center}
                The expressions are similar for $Y$;
                $$\frac{(X_w - W_{xmin})}{(W_{xmax} - W_{xmin})} = \frac{(X_v - V_{xmin})}{(V_{xmax} - V_{xmin})} \Rightarrow X_v = \frac{(X_w - W_{xmin})(V_{xmax} - V_{xmin})}{(W_{xmax} - W_{xmin})} + V_{xmin}$$
                This gives us the resulting pair of linear equations (intuitively), where the constants found from the known values $W_{xmin}, V_{xmax}$, etc. are used to define the normalisation;
                \begin{align*}
                    X_v & = AX_w + B \\
                    Y_v & = CY_w + D
                \end{align*}
            \subsubsection*{Polygon Rendering}
                Most graphics applications deal with very simple objects - flat / planar polyhedra, referred to as \textbf{faces} or \textbf{facets}.
                These are graphic primitives, and can be used to approximate any shape.
                Consider the following tetrahedron, consisting of four vertices;
                \begin{center}
                    \begin{tikzpicture}
                        \node[inner sep=2pt, circle, draw=black!50, fill=black!50] at (0, 0) {};
                        \node[rbtb] (n3) at (0, 2) {};
                        \node[rbtb] (n1) at (2, -1) {};
                        \node[rbtb] (n2) at (-2, -1) {};

                        \node[black!50] at (0.3, 0.3) {0};
                        \node at (0.3, 2.3) {3};
                        \node at (2.3, -0.7) {1};
                        \node at (-2.3, -0.7) {2};

                        \draw[black!50]
                        (0, 0) -- (0, 2)
                        (0, 0) -- (2, -1)
                        (0, 0) -- (-2, -1);

                        \draw
                        (0, 2) edge[dashed, ->, left] node{$z$} (0, 3)
                        (2, -1) edge[dashed, ->, below] node{$x$} (3, -1.5)
                        (-2, -1) edge[dashed, ->, below] node{$y$} (-3, -1.5)
                        (n3) -- (n1) -- (n2) -- (n3);
                    \end{tikzpicture}
                \end{center}
                For this, we need a mixture of different data, including numerical data about the actual 3D coordinates of the vertices, as well as topological data regarding what vertices are connected to what.
                This can be represented in the following tables;
                \begin{center}
                    \hfill
                    \begin{tabular}{c|c}
                        \multicolumn{2}{c}{vertex data} \\
                        \hline
                        index & location \\
                        \hline
                        $0$ & $(0, 0, 0)$ \\
                        $1$ & $(1, 0, 0)$ \\
                        $2$ & $(0, 1, 0)$ \\
                        $3$ & $(0, 0, 1)$
                    \end{tabular}
                    \hfill
                    \begin{tabular}{c|c}
                        \multicolumn{2}{c}{face data} \\
                        \hline
                        index & vertices \\
                        \hline
                        $0$ & 0 1 3 \\
                        $1$ & 0 2 1 \\
                        $2$ & 0 3 2 \\
                        $3$ & 1 2 3
                    \end{tabular}
                    \hfill \phantom{}
                \end{center}
                This separation allows for the vertices to move without affecting the faces.
            \subsubsection*{Projections}
                In order to draw a 3D wire frame, the points must first be converted into a 2D representation, via a \textbf{projection}, which can then be drawn with simple drawing primitives.
                Intuitively, we have an observer (a focal point) where all viewing rays converge.
                The observer is located between a projection surface $P$ and an object $V$.
                While it's possible to project onto any surface, we only consider linear projections onto a flat surface.
            \subsubsection*{Orthographic Projections}
                The simplest form of a projection is an \textbf{orthographic projection}.
                The assumptions made are that the viewpoint is located at $z = -\infty$, and the plane of projection is $z = 0$.
                With the viewing point being infinitely far away, the rays become parallel.
                This gives all projectors the same direction;
                $$\vec{d} = \begin{bmatrix}
                    0 \\ 0 \\ -1
                \end{bmatrix}$$
                This gives the following, with each projection line having the equation $\vec{P} = \vec{V} + \mu \vec{d}$;
                \begin{center}
                    \begin{tikzpicture}
                        \draw (-1, 1.5) -- (2.5, 0.5) -- (2.5, -3.5) -- (-1, -2.5) -- cycle;
                        \begin{scope}[shift={(0, 0)}]
                            \draw (0, 0) -- (1, 0) -- (1.5, -0.5) -- (0.5, -0.5) -- cycle;
                            \draw (0, -1.5) -- (1, -1.5) -- (1.5, -2) -- (0.5, -2) -- cycle;
                            \draw
                            (0, 0) -- (0, -1.5)
                            (1, 0) -- (1, -1.5)
                            (1.5, -0.5) -- (1.5, -2)
                            (0.5, -0.5) -- (0.5, -2);
                        \end{scope}
                        \begin{scope}[shift={(4, 2)}]
                            \draw (0, 0) -- (1, 0) -- (1.5, -0.5) -- (0.5, -0.5) -- cycle;
                            \draw (0, -1.5) -- (1, -1.5) -- (1.5, -2) -- (0.5, -2) -- cycle;
                            \draw
                            (0, 0) -- (0, -1.5)
                            (1, 0) -- (1, -1.5)
                            (1.5, -0.5) -- (1.5, -2)
                            (0.5, -0.5) -- (0.5, -2);
                        \end{scope}

                        \draw
                        (4, 2) edge[->] (-2, -1)
                        (5.5, 0) edge[->] (-0.5, -3);

                        \node[rbtb] at (4, 2) {};
                        \node[rbtb] at (5.5, 0) {};
                        \node[rbtb] at (0, 0) {};
                        \node[rbtb] at (1.5, -2) {};

                        \node at (3.5, 2.5) {$\vec{V_2}$};
                        \node at (6, -0.5) {$\vec{V_1}$};
                        \node at (-0.5, 0.5) {$\vec{P_2}$};
                        \node at (2, -2.5) {$\vec{P_1}$};
                    \end{tikzpicture}
                \end{center}
                By substituting in the direction $\vec{d}$ we have determined, it gives the following Cartesian equations for each component;
                \begin{align*}
                    P_x & = V_x + 0 \\
                    P_y & = V_y + 0 \\
                    P_z & = V_z - \mu \\
                \end{align*}
                However, since we have the projection plane $z = 0$, we also know that $P_z = 0$, therefore we don't need to solve for $\mu$.
                From this, we can determine the projected location is the 3D $x$ and $y$ components of the vertex;
                $$\vec{P} = \begin{bmatrix}
                    V_x \\ V_y \\ 0
                \end{bmatrix}$$
                Viewing the wireframe for a cube directly from a face would look like the following;
                \begin{center}
                    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
                        \draw (0, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- cycle;
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{Perspective Projection}
                While orthographic projections are fine when depth isn't a consideration (such as objects mostly being at the same distance from the viewer), it's insufficient for close work, where we want details to be realistic.
                The difference here is that we are no longer at an infinite distance (instead being at the origin), and the projection plane is $z = f$ (where $f$ stands for focal length);
                \begin{center}
                    \begin{tikzpicture}
                        \draw
                        (0, 0) edge[->] (10, 0)
                        (0, 0) edge[->] (0, 7);
                        \node at (-0.5, 7) {$y$};
                        \node at (10, -0.5) {$x$};
                        \node at (9, 4) {$z$};

                        \draw (2, 1) -- (2, 4) -- (6, 4) -- (6, 1) -- cycle;
                        \draw
                        (0, 0) -- (2, 1)
                        (2, 1) edge[dashed] (6, 3)
                        (6, 3) edge[->] (9, 4.5);

                        \draw (5, 7) -- (7, 6) -- (5.5, 5) -- cycle;
                        \node[rbtb] at (5, 7) {};
                        \node[rbtb] at (7, 6) {};
                        \node at (4.5, 7) {$\vec{V_1}$};
                        \node at (7.5, 6) {$\vec{V_2}$};

                        \draw (2.5, 3.5) -- (3.5, 3) -- (2.75, 2.5) -- cycle;
                        \node[rbtb] at (2.5, 3.5) {};
                        \node[rbtb] at (3.5, 3) {};
                        \node at (2, 3.5) {$\vec{P_1}$};
                        \node at (4, 3) {$\vec{P_2}$};

                        \draw[black!50]
                        (5, 7) -- (0, 0)
                        (7, 6) -- (0, 0);

                        \draw
                        (0, 0) edge[dashed] (0, -2)
                        (2, 1) edge[dashed] (2, -1)
                        (0, -1.5) edge[<->, below] node{$f$} (2, -0.5);
                    \end{tikzpicture}
                \end{center}
                This gives us the following equation (since all projectors must go through the origin);
                $$\vec{P} = \mu \vec{V}$$
                We can work out the value of $\mu$, let it be $\mu_p$ as follows;
                \begin{align*}
                    P_z & = f & \text{by projection plane} \\
                    \mu_p & = \frac{P_z}{V_z} \\
                    & = \frac{f}{V_z} \\
                    P_x & = \mu_p V_x \\
                    & = \frac{f V_x}{V_z} \\
                    P_y & = \mu_p V_y \\
                    & = \frac{f V_y}{V_z}
                \end{align*}
                Viewing the wireframe for a cube directly from a face would look like the following (note the difference to the orthographic projection);
                \begin{center}
                    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
                        \draw (0, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- cycle;
                        \draw (0.1, 0.1) -- (0.9, 0.1) -- (0.9, 0.9) -- (0.1, 0.9) -- cycle;
                        \draw
                        (0, 0) -- (0.1, 0.1)
                        (1, 0) -- (0.9, 0.1)
                        (1, 1) -- (0.9, 0.9)
                        (0, 1) -- (0.1, 0.9);
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{Transformations}
                Scenes are defined in a particular coordinate system, but we want to be able to draw a scene from any angle.
                To do so, it's easier to have the viewpoint at the origin, and the $z$-axis as the direction of view.
                As such, we need to be able to \textbf{transform} the coordinates of a scene.
                \begin{center}
                    \begin{tikzpicture}
                        \begin{scope}[shift={(0, 0)}]
                            \draw
                            (0, 0) edge[->, below] node{$x$} (5, 0)
                            (0, 0) edge[->, left] node{$y$} (0, 2)
                            (0, 0) edge[->, above] node{$z$} (2, 1);

                            \begin{scope}[shift={(2.5, 0.75)}]
                                \draw (0, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- cycle;
                                \draw
                                (0, 0) -- (0.5, 0.5)
                                (1, 0) -- (1.5, 0.5)
                                (1, 1) -- (1.5, 1.5)
                                (0, 1) -- (0.5, 1.5);
                                \draw (0.5, 0.5) -- (1.5, 0.5) -- (1.5, 1.5) -- (0.5, 1.5) -- cycle;
                            \end{scope}

                            \draw
                            (0, 0) edge[dashed, ->, below] node{$C_x$} (4, 0)
                            (4, 0) edge[dashed, ->, right] node{\ \ $C_z$} (6, 1)
                            (6, 1) edge[dashed, ->, right] node{$C_y$} (6, 3)
                            (6, 3) edge[->, above] node{$\vec{d}$} (5, 2.5);

                            \node at (6.5, 3) {$\vec{C}$};
                            \node at (-0.5, 0) {$\vec{O}$};
                        \end{scope}
                        \begin{scope}[shift={(8, 0)}]
                            \draw
                            (0, 0) edge[dashed] (5, 0)
                            (0, 0) edge[dashed] (0, 2)
                            (0, 0) edge[dashed] (2, 1);

                            \begin{scope}[shift={(2.5, 0.75)}]
                                \draw (0, 0) -- (1, 0) -- (1, 1) -- (0, 1) -- cycle;
                                \draw
                                (0, 0) -- (0.5, 0.5)
                                (1, 0) -- (1.5, 0.5)
                                (1, 1) -- (1.5, 1.5)
                                (0, 1) -- (0.5, 1.5);
                                \draw (0.5, 0.5) -- (1.5, 0.5) -- (1.5, 1.5) -- (0.5, 1.5) -- cycle;
                            \end{scope}

                            \draw
                            (6, 3) edge[->, below] node{$z$} (5, 2.5)
                            (6, 3) edge[->, right] node{$y$} (5.5, 4)
                            (6, 3) edge[->, below] node{$x$} (5.25, 3.5);

                            \node at (6.5, 3) {$\vec{O}$};
                        \end{scope}
                    \end{tikzpicture}
                \end{center}
                These are done by the application of transformation matrices.
                For example, a standard transformation to make an object twice as big from the origin;
                $$\begin{bmatrix}
                    x^\prime \\ y^\prime \\ z^\prime
                \end{bmatrix} = \begin{bmatrix}
                    2 & 0 & 0 \\
                    0 & 2 & 0 \\
                    0 & 0 & 2
                \end{bmatrix} \begin{bmatrix}
                    x \\ y \\ z
                \end{bmatrix}$$
            \subsubsection*{Translation}
                However, being restricted to matrix operations with $\mathbb{R}^{3 \times 3}$ means that we cannot represent translations (for example, a shift of two units on the $x$-axis, such that $x^\prime = x + 2$).
                The solution to this is to use 4D \textbf{homogenous coordinates}, where we assume the fourth dimension is fixed to 1.
                $$\begin{bmatrix}
                    x^\prime \\ y^\prime \\ z^\prime \\ 1
                \end{bmatrix} = \begin{bmatrix}
                    1 & 0 & 0 & 2 \\
                    0 & 1 & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1
                \end{bmatrix} \begin{bmatrix}
                    x \\ y \\ z \\ 1
                \end{bmatrix}$$
                Frequently the last ordinate is 1, however in general it is a scale factor;
                $$\underbrace{(p_x, p_y, p_z, s)}_\text{homogenous} \Leftrightarrow \underbrace{\left(\frac{p_x}{s}, \frac{p_y}{s}, \frac{p_z}{s}\right)}_\text{Cartesian}$$
            \subsubsection*{Affine Transformations}
                Affine transformations preserve parallel lines.
                Most of the transformations we require are affine, with the most important being scaling, rotation, and translation;
                \begin{itemize}
                    \itemsep0em
                    \item \textbf{scaling} \hfill by $(s_x, s_y, s_z)$
                        $$\begin{bmatrix}
                            s_x & 0 & 0 & 1 \\
                            0 & s_y & 0 & 1 \\
                            0 & 0 & s_z & 1 \\
                            0 & 0 & 0 & 1
                        \end{bmatrix} \begin{bmatrix}
                            p_x \\ p_y \\ p_z \\ 1
                        \end{bmatrix} = \begin{bmatrix}
                            s_x p_x \\
                            s_y p_y \\
                            s_z p_z \\
                            1
                        \end{bmatrix}$$
                    \item \textbf{rotation}
                        \smallskip

                        In order to define a rotation, we need both an axis and an angle, with the simplest rotations being about the Cartesian axes.
                        The following matrices are used for rotations of $\theta$ about each of the axes;
                        \begin{align*}
                            \mat{\mathcal{R}_x} & = \begin{bmatrix}
                                1 & 0 & 0 & 0 \\
                                0 & \cos \theta & -\sin \theta & 0 \\
                                0 & \sin \theta & \cos \theta & 0 \\
                                0 & 0 & 0 & 1
                            \end{bmatrix} \\
                            \mat{\mathcal{R}_y} & = \begin{bmatrix}
                                \cos \theta & 0 & \sin \theta & 0 \\
                                0 & 1 & 0 & 0 \\
                                -\sin \theta & 0 & \cos \theta & 0 \\
                                0 & 0 & 0 & 1
                            \end{bmatrix} \\
                            \mat{\mathcal{R}_z} & = \begin{bmatrix}
                                \cos \theta & -\sin \theta & 0 & 0 \\
                                \sin \theta & \cos \theta & 0 & 0 \\
                                0 & 0 & 1 & 0 \\
                                0 & 0 & 0 & 1
                            \end{bmatrix}
                        \end{align*}
                        It's important to note that \textbf{rotations have a direction}.
                        In this course, we use a left-handed coordinate system, where the rotation is anti-clockwise when looking along the axis of rotation (think about the origin being closer to you, and the axis going off to $\infty$ away from you).
                    \item \textbf{translation} \hfill by $(t_x, t_y, t_z)$
                        $$\begin{bmatrix}
                            1 & 0 & 0 & t_x \\
                            0 & 1 & 0 & t_y \\
                            0 & 0 & 1 & t_z \\
                            0 & 0 & 0 & 1
                        \end{bmatrix} \begin{bmatrix}
                            p_x \\ p_y \\ p_z \\ 1
                        \end{bmatrix} = \begin{bmatrix}
                            p_x + t_x \\
                            p_y + t_y \\
                            p_z + t_z \\
                            1
                        \end{bmatrix}$$
                \end{itemize}
                However, perspective projections are an example of a non-affine transformation, as it doesn't preserve parallels.
                Intuitively, it's not invertible (singular), as we cannot convert from a photograph to a 3D model.
                \medskip

                Note that we should be careful when we combine transformation.
                As matrix multiplication isn't commutative, we should read a sequence of matrices multiplied together from right to left, with the right-most matrix, before the vector, being the \textbf{first} transformation to be applied.
        \subsection*{Lecture 2 - Transformations for Animation}
            Recall the transformation in the previous lecture, which took way too long to draw, moving the origin to the view point.
            It consists of three steps, with the latter two being used to align the $z$-axis with the view direction;
            \begin{enumerate}[1.]
                \itemsep0em
                \item translation of the origin \hfill fairly trivial to do
                    $$\mat{\mathcal{A}} = \begin{bmatrix}
                        1 & 0 & 0 & -C_x \\
                        0 & 1 & 0 & -C_y \\
                        0 & 0 & 1 & -C_z \\
                        0 & 0 & 0 & 1
                    \end{bmatrix}$$
                \item rotation about $y$-axis
                    \smallskip

                    Consider the following, looking at the $x-z$ plane;
                    \begin{center}
                        \begin{tikzpicture}[x=0.75cm, y=0.75cm]
                            \draw
                            (0, 0) edge[->] (0, 6)
                            (0, 0) edge[->] (6, 0)
                            (0, 0) edge[very thick, ->] (3, 4)
                            (0, 0) edge[very thick, ->] (0, 5)
                            (0, 0) edge[dashed, <->, below] node{$d_x$} (3, 0)
                            (3, 0) edge[dashed, <->, right] node{$d_z$} (3, 4);

                            \draw (0, 0) ++(53:1) arc (53:90:1);
                            \node at (0.4, 1.25) {$\theta$};

                            \node at (2.5, 4) {$\vec{v}$};
                            \node at (6, -0.5) {$x$};
                            \node at (-0.5, 6) {$z$};
                        \end{tikzpicture}
                    \end{center}
                    This can be used to calculate the following (note that here we are using a right-handed system);
                    \begin{align*}
                        || \vec{v} || & = v \\
                        & = \sqrt{d_x^2 + d_z^2} \\
                        \cos \theta & = \frac{d_z}{v} \\
                        \sin \theta & = \frac{d_x}{v} \\
                        \mat{\mathcal{B}} & = \begin{bmatrix}
                            \cos \theta & 0 & -\sin \theta & 0 \\
                            0 & 1 & 0 & 0 \\
                            -\sin \theta & 0 & \cos \theta & 0 \\
                            0 & 0 & 0 & 1
                        \end{bmatrix} \\
                        & = \begin{bmatrix}
                            \frac{d_z}{v} & 0 & -\frac{d_x}{v} & 0 \\
                            0 & 1 & 0 & 0 \\
                            \frac{d_x}{v} & 0 & \frac{d_z}{v} & 0 \\
                            0 & 0 & 0 & 1
                        \end{bmatrix}
                    \end{align*}
                \item rotation about $x$-axis
                    \smallskip

                    This follows a similar process, note that we are now aligned along the $y-z$ plane (for clarity, the horizontal distance is $v$);
                    \begin{center}
                        \begin{tikzpicture}[x=0.75cm, y=0.75cm]
                            \draw
                            (0, 0) edge[->] (6, 0)
                            (0, 0) edge[->] (0, 5)
                            (0, 0) edge[very thick, ->, above] node{$| \vec{d} |$} (4, 3)
                            (0, 0) edge[very thick, ->] (5, 0)
                            (0, 0) edge[dashed, <->, below] node{$v = | \vec{v} |$} (4, 0)
                            (4, 0) edge[dashed, <->, right] node{$d_y$} (4, 3);

                            \draw (0, 0) ++(38:1) arc (38:0:1);
                            \node at (1.25, 0.4) {$\phi$};
                            \node at (6, -0.5) {$z$};
                            \node at (-0.5, 5) {$y$};
                        \end{tikzpicture}
                    \end{center}
                    Similarly, the matrix can be obtained as follows;
                    \begin{align*}
                        \cos \phi & = \frac{v}{| \vec{d} |} \\
                        \sin \phi & = \frac{d_y}{| \vec{d} |} \\
                        \mat{\mathcal{C}} & = \begin{bmatrix}
                            1 & 0 & 0 & 0 \\
                            0 & \cos \phi & -\sin \phi & 0 \\
                            0 & \sin \phi & \cos \phi & 0 \\
                            0 & 0 & 0 & 1
                        \end{bmatrix} \\
                        & = \begin{bmatrix}
                            1 & 0 & 0 & 0 \\
                            0 & \frac{v}{| \vec{d} |} & -\frac{d_y}{| \vec{d} |} & 0 \\
                            0 & \frac{d_y}{| \vec{d} |} & \frac{v}{| \vec{d} |} & 0 \\
                            0 & 0 & 0 & 1
                        \end{bmatrix}
                    \end{align*}
            \end{enumerate}
            From this, we are able to combine the matrices into the following;
            $$\mat{\mathcal{T}} = \mat{\mathcal{C}} \mat{\mathcal{B}} \mat{\mathcal{A}}$$
            For every point $\vec{P}$ in the scene, we can obtain $\vec{P_t} = \mat{\mathcal{T}}\vec{P}$, with the view in \textbf{canonical} form, allowing us to apply the standard perspective or orthographic projection.
            \subsubsection*{Rotation About a General Line}
                Rotation of a scene around a general line can be done as a combination of transformations.
                The idea is similar, with the following three steps;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item making the line of rotation one of the Cartesian axes
                        \smallskip

                        This uses the matrices derived before, rotating the general line to be aligned with the $z$-axis.
                    \item perform the rotation
                        \smallskip

                        Standard rotation around the $z$-axis defined previously.
                    \item restore line to original place
                        \smallskip

                        Inversion of the initial matrices to revert rotation.
                \end{enumerate}
                This gives us the following full matrix;
                $$\mat{\mathcal{T}} = \underbrace{\mat{\mathcal{A}^{-1}} \mat{\mathcal{B}^{-1}} \mat{\mathcal{C}^{-1}}}_3 \underbrace{\mat{\mathcal{R}_z}}_2 \underbrace{\mat{\mathcal{C}} \mat{\mathcal{B}} \mat{\mathcal{A}}}_1$$
            \subsubsection*{Projection Matrices}
                For the canonical / orthographic projection, the matrix simply drops the $z$ component;
                \begin{align*}
                    \mat{\mathcal{M}_O} & = \begin{bmatrix}
                        1 & 0 & 0 & 0 \\
                        0 & 1 & 0 & 0 \\
                        0 & 0 & 0 & 0 \\
                        0 & 0 & 0 & 1
                    \end{bmatrix} \\
                    \mat{\mathcal{M}_O} \begin{bmatrix}
                        x \\ y \\ z \\ 1
                    \end{bmatrix} & = \begin{bmatrix}
                        x \\ y \\ 0 \\ 1
                    \end{bmatrix}
                \end{align*}
                This is clearly non-invertible, as we are losing information about one of the axes.
                An effect of this is that we must do any effects in 3D \textbf{before} applying the projection matrix.
                \medskip

                The perspective projection matrix can also be done in a similar way;
                \begin{align*}
                    \mat{\mathcal{M}_p} & = \begin{bmatrix}
                        1 & 0 & 0 & 0 \\
                        0 & 1 & 0 & 0 \\
                        0 & 0 & 1 & 0 \\
                        0 & 0 & \frac{1}{f} & 0
                    \end{bmatrix} \\
                    \mat{\mathcal{M}_p} \begin{bmatrix}
                        x \\ y \\ z \\ 1
                    \end{bmatrix} & = \begin{bmatrix}
                        x \\ y \\ z \\ \frac{z}{f}
                    \end{bmatrix} \\
                    & \rightarrow \begin{bmatrix}
                        \frac{fx}{z} \\
                        \frac{fy}{z} \\
                        f \\
                        1
                    \end{bmatrix} & \text{using the fourth ordinate as a scale factor}
                \end{align*}
                Note that homogenous coordinates and vectors fall into one of two types;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item \textbf{position vectors}
                        \smallskip

                        These have a non-zero final ordinate ($s > 0$) and can be normalised to Cartesian form.
                        If two position vectors are added, we instead obtain the mid-point;
                        $$\begin{bmatrix}
                            X_a \\ Y_a \\ Z_a \\ 1
                        \end{bmatrix} + \begin{bmatrix}
                            X_b \\ Y_b \\ Z_b \\ 1
                        \end{bmatrix} = \begin{bmatrix}
                            X_a + X_b \\
                            Y_a + Y_b \\
                            Z_a + Z_b \\
                            2
                        \end{bmatrix} = \begin{bmatrix}
                            \frac{X_a + X_b}{2} \\
                            \frac{Y_a + Y_b}{2} \\
                            \frac{Z_a + Z_b}{2} \\
                            1
                        \end{bmatrix}$$
                        This has no real meaning in geometry, but is a useful observation.
                    \item \textbf{direction vectors}
                        \smallskip

                        These have a zero in the final ordinate, and have a direction and magnitude.
                        If two direction vectors are added, we obtain a direction vector (following the normal addition rule);
                        $$\begin{bmatrix}
                            x_i \\ y_i \\ z_i \\ 0
                        \end{bmatrix} + \begin{bmatrix}
                            x_j \\ y_j \\ z_j \\ 0
                        \end{bmatrix} = \begin{bmatrix}
                            x_i + x_j \\
                            y_i + y_j \\
                            z_i + z_j \\
                            0
                        \end{bmatrix}$$
                        However, if a direction vector is added to a position vector, we obtain another position vector;
                        $$\begin{bmatrix}
                            X \\ Y \\ Z \\ 1
                        \end{bmatrix} + \begin{bmatrix}
                            x \\ y \\ z \\ 0
                        \end{bmatrix} = \begin{bmatrix}
                            X + x \\
                            Y + y \\
                            Z + z \\
                            1
                        \end{bmatrix}$$
                \end{enumerate}
            \subsubsection*{Structure of a Transformation Matrix}
                Note that the bottom row of such a matrix is \textbf{always} 0 0 0 1.
                We can decompose the columns of a transformation matrix into three direction vectors and one position vector.
                The three direction vectors are the new axes and the position vector is the new origin.
                $$\underbrace{\begin{bmatrix}
                    q_x & r_x & s_x & C_x \\
                    q_y & r_y & s_y & C_y \\
                    q_z & r_z & s_z & C_z \\
                    0 & 0 & 0 & 1
                \end{bmatrix}}_\text{matrix} \rightarrow \underbrace{\begin{bmatrix}
                    q_x \\ q_y \\ q_z \\ 0
                \end{bmatrix} \begin{bmatrix}
                    r_x \\ r_y \\ r_z \\ 0
                \end{bmatrix} \begin{bmatrix}
                    s_x \\ s_y \\ s_z \\ 0
                \end{bmatrix}}_\text{direction vectors} \underbrace{\begin{bmatrix}
                    C_x \\ C_y \\ C_z \\ 1
                \end{bmatrix}}_\text{position vector}$$
                When applying this transformation to a direction vector, where the last ordinate is zero, no \textbf{translation} is applied.
                On the other hand, if it is a position vector, where the last ordinate is 1, all vectors will have the same displacement.
                \medskip

                The following results can be proved by observing changes to the standard basis vectors, and the origin after applying the matrix;
                \begin{itemize}
                    \itemsep0em
                    \item $\vec{q}$ \hfill transformed $x$-axis
                    \item $\vec{r}$ \hfill transformed $y$-axis
                    \item $\vec{s}$ \hfill transformed $z$-axis
                    \item $\vec{C}$ \hfill transformed origin
                \end{itemize}
            \subsubsection*{Dot Product}
                We can consider the dot product as a projection;
                $$\vec{P} \cdot \vec{u} = | \vec{P} | | \vec{u} | \cos \theta$$
                Visually, we can see the dot product as the following;
                \begin{center}
                    \begin{tikzpicture}
                        \draw
                        (-1, 0) edge[dashed] (5, 0)
                        (0, -1) edge[dashed] (0, 5)
                        (0, 0) edge[thick, ->, below] node{$\vec{u}$} (2, 0)
                        (0, 0) edge[thick, ->, left] node{$\vec{v}$} (0, 2)
                        (0, 0) edge[very thick, ->, above] node{$\vec{P}$} (4, 3)
                        (4, 3) edge[very thick, dashed] (0, 3)
                        (4, 3) edge[very thick, dashed] (4, 0);
                        \draw (0, 0) ++(38:1) arc (38:0:1);
                        \node at (1.25, 0.4) {$\theta$};
                        \draw[black!50]
                        (0, -0.5) edge[very thick, ->, below] node{$\vec{P} \cdot \vec{u}$} (4, -0.5)
                        (-0.5, 0) edge[very thick, ->, left] node{$\vec{P} \cdot \vec{v}$} (-0.5, 3);
                    \end{tikzpicture}
                \end{center}
                If $\vec{u}$ is along a co-ordinate axis, then $\vec{P} \cdot \vec{u}$ is the ordinate of $\vec{P}$ in the direction of $\vec{u}$.
                \medskip

                Consider changing to the new axes $\vec{u}, \vec{v}, \vec{w}$, and origin $\vec{C}$.
                We can call the first co-ordinate of $\vec{P}$ in the new system $\vec{P}_x^t$;
                \begin{align*}
                    \vec{P}_x^t & = (\vec{P} - \vec{C}) \cdot \vec{u} \\
                    & = \vec{P} \cdot \vec{u} - \vec{C} \cdot \vec{u}
                \end{align*}
                However, this can also be represented in matrix notation;
                $$\begin{bmatrix}
                    P_x^t \\
                    P_y^t \\
                    P_z^t \\
                    1
                \end{bmatrix} = \begin{bmatrix}
                    u_x & u_y & u_z & -\vec{C} \cdot \vec{u} \\
                    v_x & v_y & v_z & -\vec{C} \cdot \vec{v} \\
                    w_x & w_y & w_z & -\vec{C} \cdot \vec{w} \\
                    0 & 0 & 0 & 1
                \end{bmatrix} \begin{bmatrix}
                    P_x \\
                    P_y \\
                    P_z \\
                    1
                \end{bmatrix}$$
                Returning to the original problem, where we need to find a transformation matrix with a viewpoint $\vec{C}$ and direction $\vec{d}$.
                This can be done by first finding the vectors $\vec{u}, \vec{v}, \vec{w}$.
                Since $\vec{d}$ is the direction of the new axes, we can write (to get a unit vector);
                $$\vec{w} = \frac{\vec{d}}{| \vec{d} |}$$
                We also want to maintain an orthogonal basis, as well as all unit vectors.
                For the horizontal direction, we can write $\vec{u}$ in terms of some horizontal vector $\vec{p}$;
                \begin{align*}
                    \vec{u} & = \frac{\vec{p}}{| \vec{p} |} \\
                    p_y & = 0 & \text{ensure horizontal, no vertical component}
                \end{align*}
                Similarly, we want some vertical vector $\vec{q}$ to write $\vec{v}$;
                \begin{align*}
                    \vec{v} & = \frac{\vec{q}}{| \vec{q} |} \\
                    q_y & = 1 & \text{vertical, positive component}
                \end{align*}
                This gives us the following to solve;
                \begin{align*}
                    \vec{p} & = \begin{bmatrix}
                        p_x \\ 0 \\ p_z
                    \end{bmatrix} & \text{new horizontal} \\
                    \vec{q} & = \begin{bmatrix}
                        q_x \\ 1 \\ q_z
                    \end{bmatrix} & \text{new vertical}
                \end{align*}
                However, the view direction can also be written as the following (since we have the view direction, which happens to be the new $z$-axis as perpendicular to the remaining two vectors);
                $$\vec{d} = \vec{p} \times \vec{q}$$
                Using this, we can write $\vec{p}$ in terms of $\vec{q}$;
                \begin{align*}
                    \vec{d} & = \begin{bmatrix}
                        d_x \\ d_y \\ d_z
                    \end{bmatrix} \\
                    & = \vec{p} \times \vec{q} \\
                    & = \begin{vmatrix}
                        \vec{i} & \vec{j} & \vec{k} \\
                        p_x & 0 & p_z \\
                        q_x & 1 & q_z
                    \end{vmatrix} \\
                    & = -p_z \vec{i} + (p_z q_x - p_x q_z) \vec{j} + p_x \vec{k} \\
                    & = \begin{bmatrix}
                        -p_z \\
                        p_z q_x - p_x q_z \\
                        p_x
                    \end{bmatrix} & \Rightarrow \\
                    d_x & = -p_z \\
                    d_y & = p_z q_x - p_x q_z \\
                    d_z & = p_x & \Rightarrow \\
                    \vec{p} & = \begin{bmatrix}
                        d_z \\ 0 \\ -d_x
                    \end{bmatrix}
                \end{align*}
                However, since we know that the vectors $\vec{p}$ and $\vec{q}$ are orthogonal, we can say the following;
                \begin{align*}
                    \vec{p} \cdot \vec{q} & = 0 & \Rightarrow \\
                    p_x q_x + p_z q_z & = 0 \\
                    d_y & = p_z q_x - p_x q_z & \text{from above}
                \end{align*}
                Both of these equations can be fully written in terms of $\vec{d}$.
        \subsection*{Lecture 3 - Clipping and 3D Geometry}
            \textbf{Clipping} is the process of eliminating portions of objects outside the \textbf{viewing frustum} (boundaries of the image plane projected in 3D, consisting of a near and far clipping plane).
            This is useful to avoid degeneracy (by not drawing objects behind the camera), as well as improving efficiency by not processing objects which won't be visible.
            \medskip

            There are three points when we could clip;
            \begin{itemize}
                \itemsep0em
                \item before perspective transform (3D space) \hfill world co-ordinates
                \item after perspective transform \hfill homogeneous co-ordinates
                \item after perspective division \hfill screen space
            \end{itemize}
            The second option, in camera co-ordinates, is ideal.
            This is because the clipping planes are axis aligned, as we can discard anything further than the far plane or closer than the near plane.
            \subsubsection*{Halfspace}
                We can define any infinite line (for simplicity, in 2D) as a test;
                $$f(x, y) = 0 \text{ such as } \violet{x - y + 1 = 0}$$
                \begin{center}
                    \begin{tikzpicture}
                        \draw
                        (0, -1) edge[->] (0, 4)
                        (-2, 0) edge[->] (4, 0);
                        \node at (-0.5, 4) {$y$};
                        \node at (4, -0.5) {$x$};

                        \node at (2, 1) {\shortstack{halfspace\\$f(x, y) > 0$}};
                        \node at (-2, 2) {\shortstack{halfspace\\$f(x, y) < 0$}};

                        \draw[violet] (-2, -1) -- (3, 4);
                    \end{tikzpicture}
                \end{center}
                In 3D, the plane equation is $f(x, y, z) = Ax + By + Cz + D = 0$, which also divides space into two spaces, one where the test is positive, and one where it is negative.
                \medskip

                Note that we can define $\vec{H}$ as the normal vector of our plane, and also normalise it to avoid infinite solutions by scaling;
                \begin{align*}
                    \vec{H} & = \begin{bmatrix}
                        A \\ B \\ C \\ D
                    \end{bmatrix} \\
                    A^2 + B^2 + C^2 & = 1
                \end{align*}
                The distance is quite easily calculated as follows;
                $$d = \vec{H} \cdot \vec{P} = \vec{H}^\top\vec{P}$$
                This is a \textbf{signed} distance, where a positive value would denote inside, and a negative value would denote outside.
                \medskip

                Consider the \textbf{view frustum}, where we have 6 planes, and their normals oriented towards the interior of the frustum (where each plane has its own $\vec{H}$).
                If $\vec{H} \cdot \vec{P} < 0$ for \textbf{any} of the planes, then it is clipped, as it would be outside of the frustum.
        \subsection*{Lecture 4 - Graphics Pipelines and APIs}
            All graphics systems work according to some fundamental principles, we can define two conceptually related graphics pipelines;
            \begin{itemize}
                \itemsep0em
                \item \textbf{declarative} \hfill tell system what we want to render, not how
                    \smallskip

                    Relates to OOP.
                    For example, we can define a sphere which knows about its environment, and its location etc, and can draw itself with graphics primitives (essentially how to tessellate itself).
                    Virtual cameras, and scene descriptions (scene graphs) can also exist.
                    Every object may know about each other.
                \item \textbf{imperative} \hfill tell the system how to render something, but not what is being rendered
                    \smallskip

                    In contrast, the pipeline here now takes in a sequence of drawing commands, such as drawing a vertex at a given position.
                    As such, objects can be drawn independent from each other, allowing for a degree of parallelism.
            \end{itemize}
            It's important to note that we build declarative pipelines on top of an imperative model.
            For example, the sphere should know how to tessellate itself, and send the commands to the imperative backend.
            \begin{center}
                \begin{tikzpicture}[y=-1cm]
                    \begin{scope}[shift={(0, 0)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{modelling\\transformations}};
                    \end{scope}
                    \begin{scope}[shift={(0, 1.5)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{illumination\\(shading)}};
                    \end{scope}
                    \begin{scope}[shift={(0, 3)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{viewing transformation\\(perspective / orthographic)}};
                    \end{scope}
                    \begin{scope}[shift={(0, 4.5)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{clipping}};
                    \end{scope}
                    \begin{scope}[shift={(0, 6)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{projection\\(to screen space)}};
                    \end{scope}
                    \begin{scope}[shift={(0, 7.5)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{scan conversion\\(rasterization)}};
                    \end{scope}
                    \begin{scope}[shift={(0, 9)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {\shortstack{visibility / display}};
                    \end{scope}
                    \node (a) at (10, 0.5) {application};
                    \node (o) at (10, 9.5) {\shortstack{output: 2D image\\for framebuffer display}};
                    \draw
                    (3, 1) edge[->] (3, 1.5)
                    (3, 2.5) edge[->] (3, 3)
                    (3, 4) edge[->] (3, 4.5)
                    (3, 5.5) edge[->] (3, 6)
                    (3, 7) edge[->] (3, 7.5)
                    (3, 8.5) edge[->] (3, 9)
                    (a) edge[->, above] node{\shortstack{drawing\\commands}} (6, 0.5)
                    (6, 9.5) edge[->] (o);
                \end{tikzpicture}
            \end{center}
            The steps of the pipeline perform the following;
            \begin{itemize}
                \itemsep0em
                \item \textbf{modelling transformations}
                    \smallskip

                    As 3D models are defined in the own coordinate systems (might all be at the origin, etc.), modelling transformations orients the models within the world coordinates (as a common coordinate frame).
                    This can include scaling, rotation, and transformations.
                \item \textbf{illumination (shading)}
                    \smallskip

                    Approximate lighting model to give initial ideas for how the object may be illuminated.
                    The main illumination is done at this step, before clipping, in order to get accurate shadows (which may have been clipped).
                \item \textbf{viewing transformation}
                    \smallskip

                    The world space is mapped into camera space.
                    The viewing position is transformed to the origin, and the viewing direction is oriented along the $z$ axis (typically).
                \item \textbf{clipping}
                    \smallskip

                    Remove portions of the scene outside the view frustum.
                    Transformation is also performed to Normalised Device Coordinates (pictured below).
                    \begin{center}
                        \begin{tikzpicture}
                            \draw (0, 0) -- (4, 0) -- (5, -1) -- (1, -1) -- cycle;
                            \draw (0, -3) -- (4, -3) -- (5, -4) -- (1, -4) -- cycle;
                            \draw
                            (0, 0) -- (0, -3)
                            (4, 0) -- (4, -3)
                            (5, -1) -- (5, -4)
                            (1, -1) -- (1, -4);
                            \draw
                            (4.5, -2) edge[dotted, ->] (4.5, 0.5)
                            (4.5, -2) edge[dotted, ->] (1.5, -2)
                            (4.5, -2) edge[dotted, ->] (3, -0.5);
                            \node at (5, 0.5) {$y$};
                            \node at (2.5, -0.5) {$x$};
                            \node at (1.5, -2.5) {$z$};
                        \end{tikzpicture}
                    \end{center}
                \item \textbf{projection}
                    \smallskip

                    The objects are projected into the 2D imaging plane screen space (see below);
                    \begin{center}
                        \begin{tikzpicture}
                            \draw (0, 0) -- (4, 0) -- (5, -1) -- (1, -1) -- cycle;
                            \draw (0, -3) -- (4, -3) -- (5, -4) -- (1, -4) -- cycle;
                            \draw
                            (0, 0) -- (0, -3)
                            (4, 0) -- (4, -3)
                            (5, -1) -- (5, -4)
                            (1, -1) -- (1, -4);
                            \draw
                            (5, -4) edge[dotted, ->] (5, 0.5)
                            (5, -4) edge[dotted, ->] (0.5, 0.5)
                            (5, -4) edge[dotted, ->] (-1, -4);
                            \node at (5.5, 0.5) {$y$};
                            \node at (0, 0.5) {$x$};
                            \node at (-1, -3.5) {$z$};
                            \node at (5.5, -4.5) {$O$};
                            \foreach \y in {0,...,8} {
                                \draw (0, -0.3 * \y - 0.3) -- (1, -0.3 * \y - 1.3);
                            }
                            \foreach \x in {0,...,5} {
                                \draw (0.1412 * \x + 0.1412, -0.1412 * \x - 3.1412) -- (0.1412 * \x + 0.1412, -0.1412 * \x - 0.1412);
                            }
                        \end{tikzpicture}
                    \end{center}
                \item \textbf{rasterization}
                    \smallskip

                    Converts objects into pixels, and interpolates values inside objects.
                    Due to hardware support, it's more efficient to just rasterize everything.
                \item \textbf{visibility / display}
                    \smallskip

                    Handles occlusions and transparency blending, as well as determining which objects are closest (and hence visible).
            \end{itemize}
            The majority of real-time graphics is based on the rasterization of graphic primitives (points, lines, triangles, etc).
            This is typically implemented in hardware (GPU), and is controlled through an API such as OpenGL.
            Certain parts of the pipeline are programmable, such as with GLSL (shaders).
            \medskip

            A \textbf{vertex} is a point in space defining geometry and a \textbf{fragment} is a sample produced during rasterization (multiple of which are merged into pixels).
            The high level view of the pipeline is as follows;
            \begin{center}
                \begin{tikzpicture}[y=-1cm]
                    \begin{scope}[shift={(0, 0)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {application};
                    \end{scope}
                    \begin{scope}[shift={(0, 2)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {geometry};
                    \end{scope}
                    \begin{scope}[shift={(0, 4)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {rasterization};
                    \end{scope}
                    \begin{scope}[shift={(0, 6)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {frame buffer};
                    \end{scope}
                    \begin{scope}[shift={(0, 8)}]
                        \draw (0, 0) -- (6, 0) -- (6, 1) -- (0, 1) -- cycle;
                        \node at (3, 0.5) {display};
                    \end{scope}
                    \draw
                    (3, 1) edge[->, right] node{commands} (3, 2)
                    (3, 3) edge[->, right] node{primitives} (3, 4)
                    (3, 5) edge[->, right] node{fragments} (3, 6)
                    (3, 7) edge[->, right] node{scan-out} (3, 8);
                \end{tikzpicture}
            \end{center}
            It's important to draw a distinction in which stage we're working.
            When we have geometry processing and write shaders to do something with our vertices, we are at a vertex stage (everything lives in 3D coordinates).
            \subsubsection*{Application Stage}
                At the application stage, we typically generate a database of the scene (loaded from disks), and perform simulations (physics).
                Input events are also handled here.
                In this stage, objects are just vertex coordinates, and how they are connected.
                \medskip

                The lecture now goes over the graphics pipeline in \textbf{OpenGL 3.2}.
                It's important to note that many fixed functions (including tessellation primitive generation, rasterization and interpolation) are implemented in hardware, for performance.
            \subsubsection*{Geometry Stage}
                \begin{center}
                    \begin{tikzpicture}[x=0.75cm, y=0.75cm]
                        \draw (0, 0) -- (4, 0) -- (4, -2) -- (0, -2) -- cycle;
                        \draw (6, 0) -- (10, 0) -- (10, -2) -- (6, -2) -- cycle;
                        \draw (12, 0) -- (16, 0) -- (16, -2) -- (12, -2) -- cycle;
                        \draw (18, 0) -- (22, 0) -- (22, -2) -- (18, -2) -- cycle;
                        \node at (2, -1) {\shortstack{vertex\\processing}};
                        \node at (8, -1) {\shortstack{clipping}};
                        \node at (14, -1) {\shortstack{projection}};
                        \node at (20, -1) {\shortstack{viewport\\transform}};
                        \draw[
                            thick,
                            decoration={
                                brace,
                                mirror,
                                raise=5
                            },
                            decorate
                        ] (0, -2) -- (4, -2) node[pos=0.5, anchor=north, yshift=-5.55] {programmable};
                        \draw[
                            thick,
                            decoration={
                                brace,
                                mirror,
                                raise=5
                            },
                            decorate
                        ] (6, -2) -- (22, -2) node[pos=0.5, anchor=north, yshift=-5.55] {fixed function (hardware)};
                        \draw
                        (4, -1) edge[->] (6, -1)
                        (10, -1) edge[->] (12, -1)
                        (16, -1) edge[->] (18, -1);
                    \end{tikzpicture}
                \end{center}
                In the vertex processing stage, the input vertex stream (composed of arbitrary vertex attributes such as position and colour) is transformed into a stream of vertices mapped onto the screen by the vertex shader.
                The following is the vertex post-processing pipeline (we can pre-multiply matrices if we don't need to do anything between the stages - typically we want to do stuff before the \textbf{projection matrix} however);
                \begin{center}
                    \begin{tikzpicture}
                        \node (ivc) at (-0.5, 0) {\shortstack{input vertex\\coordinates}};
                        \node[draw] (mm) at (3, 0) {\shortstack{model\\matrix}};
                        \node[draw] (dm) at (6, 0) {\shortstack{draw\\matrix}};
                        \node[draw] (pm) at (9, 0) {\shortstack{projection\\matrix}};
                        \node (ovc) at (12.5, 0) {\shortstack{output vertex\\coordinates}};
                        \node[draw] (mvm) at (4.5, -2) {\shortstack{model view\\matrix}};
                        \node[draw] (mvpm) at (6, -4) {\shortstack{model view projection\\matrix}};
                        \draw
                        (ivc) edge[->] (mm)
                        (mm) edge[->] (dm)
                        (dm) edge[->] (pm)
                        (pm) edge[->] (ovc)
                        (1.5, 0) -- (1.5, -4)
                        (1.5, -2) edge[->] (mvm)
                        (mvm) -- (7.5, -2) -- (7.5, 0)
                        (1.5, -4) edge[->] (mvpm)
                        (mvpm) -- (10.5, -4) -- (10.5, 0);
                        \node at (1.5, 1) {\shortstack{object\\space}};
                        \node at (4.5, 1) {\shortstack{world\\space}};
                        \node at (7.5, 1) {\shortstack{view\\space}};
                        \node at (10.5, 1) {\shortstack{clip\\space}};
                    \end{tikzpicture}
                \end{center}
                The \textbf{geometry shader} is an optional stage between the vertex and fragment shader; it has full knowledge of the primitive it is working on (unlike the vertex shader).
                It can also generate primitives dynamically (such as procedural geometry in growing plants).
                Note that this is limited by the GPU.
            \subsubsection*{Rasterization Stage}
                \begin{center}
                    \begin{tikzpicture}[x=0.75cm, y=0.75cm]
                        \draw (0, 0) -- (4, 0) -- (4, -2) -- (0, -2) -- cycle;
                        \draw (6, 0) -- (10, 0) -- (10, -2) -- (6, -2) -- cycle;
                        \draw (12, 0) -- (16, 0) -- (16, -2) -- (12, -2) -- cycle;
                        \draw (18, 0) -- (22, 0) -- (22, -2) -- (18, -2) -- cycle;
                        \node at (2, -1) {\shortstack{primitive\\assembly}};
                        \node at (8, -1) {\shortstack{primitive\\traversal}};
                        \node at (14, -1) {\shortstack{fragment\\shading}};
                        \node at (20, -1) {\shortstack{fragment\\merging}};
                        \draw[
                            thick,
                            decoration={
                                brace,
                                mirror,
                                raise=5
                            },
                            decorate
                        ] (0, -2) -- (10, -2) node[pos=0.5, anchor=north, yshift=-5.55] {fixed function};
                        \draw[
                            thick,
                            decoration={
                                brace,
                                mirror,
                                raise=5
                            },
                            decorate
                        ] (12, -2) -- (16, -2) node[pos=0.5, anchor=north, yshift=-5.55] {programmable};
                        \draw[
                            thick,
                            decoration={
                                brace,
                                mirror,
                                raise=5
                            },
                            decorate
                        ] (18, -2) -- (22, -2) node[pos=0.5, anchor=north, yshift=-5.55] {fixed function};
                        \draw
                        (4, -1) edge[->] (6, -1)
                        (10, -1) edge[->] (12, -1)
                        (16, -1) edge[->] (18, -1);
                    \end{tikzpicture}
                \end{center}
                A lot of merging can be performed at the fragment shading stage.
                Also note that in graphics, we let $(0, 0)$ denote the \textbf{lower left} corner of the window, and we refer to the lower left corner of a pixel.
                For example, the pixel centre (sample location) would be at $(2.5, 1.5)$;
                \begin{center}
                    \begin{tikzpicture}
                        \draw
                        (0, 0) -- (0, 4)
                        (0, 0) -- (4, 0);
                        \draw[fill=black!20, very thick] (2, 1) -- (3, 1) -- (3, 2) -- (2, 2) -- cycle;
                        \node at (2.5, 1.5) {\shortstack{pixel\\$(2, 1)$}};
                        \foreach \i in {0,...,3} {
                            \draw (\i, -0.2) -- (\i, 0);
                            \draw (-0.2, \i) -- (0, \i);
                            \node at (\i, -0.5) {\i};
                            \node at (-0.5, \i) {\i};
                        }
                        \draw[dotted]
                        (2, 0) -- (2, 1)
                        (0, 1) -- (2, 1);
                    \end{tikzpicture}
                \end{center}
                In the fragment shading step, given the interpolated vertex attributes (output by the vertex shader), the fragment shader computes colour values for each fragment, by applying textures, performing lighting calculations, etc.
                The fragment merging step follows the following pipeline;
                \begin{center}
                    \begin{tikzpicture}
                        \node (sf) at (-1.5, 1) {\shortstack{shaded\\fragment}};
                        \begin{scope}[shift={(0, 0)}]
                            \draw (0, 0) -- (3, 0) -- (3, 2) -- (0, 2) -- cycle;
                            \node at (1.5, 1) {\shortstack{pixel\\ownership\\test}};
                        \end{scope}
                        \begin{scope}[shift={(4, 0)}]
                            \draw (0, 0) -- (3, 0) -- (3, 2) -- (0, 2) -- cycle;
                            \node at (1.5, 1) {\shortstack{scissor\\test}};
                        \end{scope}
                        \begin{scope}[shift={(8, 0)}]
                            \draw (0, 0) -- (3, 0) -- (3, 2) -- (0, 2) -- cycle;
                            \node at (1.5, 1) {\shortstack{stencil\\test}};
                        \end{scope}
                        \begin{scope}[shift={(12, 0)}]
                            \draw (0, 0) -- (3, 0) -- (3, 2) -- (0, 2) -- cycle;
                            \node at (1.5, 1) {\shortstack{depth\\test}};
                        \end{scope}
                        \begin{scope}[shift={(4, -3)}]
                            \draw (0, 0) -- (3, 0) -- (3, 2) -- (0, 2) -- cycle;
                            \node at (1.5, 1) {\shortstack{blending}};
                        \end{scope}
                        \begin{scope}[shift={(8, 3)}]
                            \draw[fill=black!20] (0, 0) -- (3, 0) -- (3, 1) -- (0, 1) -- cycle;
                            \node at (1.5, 0.5) {stencil buffer};
                        \end{scope}
                        \begin{scope}[shift={(12, 3)}]
                            \draw[fill=black!20] (0, 0) -- (3, 0) -- (3, 1) -- (0, 1) -- cycle;
                            \node at (1.5, 0.5) {depth buffer};
                        \end{scope}
                        \begin{scope}[shift={(8, -2.5)}]
                            \draw[fill=black!20] (0, 0) -- (3, 0) -- (3, 1) -- (0, 1) -- cycle;
                            \node at (1.5, 0.5) {frame buffer};
                        \end{scope}
                        \draw
                        (sf) edge[->] (0, 1)
                        (3, 1) edge[->] (4, 1)
                        (7, 1) edge[->] (8, 1)
                        (11, 1) edge[->] (12, 1)
                        (15, 1) -- (15.5, 1) -- (15.5, -0.5) -- (3.5, -0.5) -- (3.5, -2) edge[->] (4, -2)
                        (7, -2) edge[->] (8, -2)
                        (9.5, -2.5) -- (9.5, -3.5) -- (5.5, -3.5) edge[->] (5.5, -3)
                        (9.5, 2) edge[<->] (9.5, 3)
                        (13.5, 2) edge[<->] (13.5, 3);
                    \end{tikzpicture}
                \end{center}
                At this point, we have everything in the frame buffer, generally in the RGBA format, ready for the display stage.
            \subsubsection*{Considerations with Pipeline}
                It's important to keep in mind that the size of the pipeline grows.
                While we may start with a few million vertices in a complex scene, the rasterizer may lead to billions of fragments / pixel candidates.
                Another note is that the vertex and fragment processing stages are highly parallel.
                Instead of iterating over the incoming list of vertices, we write programs that work on an individual vertex, for the GPU to perform in parallel (which is the power of GPU programming) - a similar concept applies for the fragment processing stage.
            \subsubsection*{Architectural Overview}
                It's important to note that graphics hardware is a shared resource.
                The user mode driver (UMD) prepares command buffers for the hardware (and also provides a unified interface for different hardware), which is then submitted to the hardware by the kernel mode driver (KMD).
                The graphics kernel subsystem schedules hardware access.
                \medskip

                The lecture continues with a list of graphics APIs.
        \subsection*{Lecture 5 - Shading Languages}
            \subsubsection*{OpenGL}
                OpenGL is a low-level ``immediate mode'' graphics API specification (and not a library).
                It has a platform independent interface, with a platform dependent implementation.
                It defines an abstract rendering device, which can be operated by a set of functions, and therefore we don't need to care about what the actual hardware is.
                It also uses a \textbf{state machine} for high efficiency.
                In order to write a program, we need to do the following;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item set up a \textbf{render window} (OS dependent, usually use a library such as \textit{glut}, \textit{Qt}, etc.)
                    \item setup viewport, model transformation, and file I/O (including shaders and textures)
                    \item frame generation (define what happens in every frame)
                \end{enumerate}
                \textbf{Contexts} are abstract graphics devices, which usually do not communicate with each other; each representing one instance of OpenGL.
                There is only one \textbf{current} context per thread.
                We may have multiple OpenGL windows in a single application and they are independent contexts.
                A \textbf{resource} is something that is read from (some sort of data).
                They act as sources of inputs (such as texture images), and sinks for outputs (such as buffers).
                \medskip

                The overall concept uses \textbf{object models}, where objects have unique names (unsigned integer handle).
                Commands work on targets, which has an object \textbf{bound} to the target.
                When a name is bound to a target, the object it identifies becomes current for that target.
                Exceptions exist such as shader objects and program objects, where commands work directly on object names.
                We can consider targets as analogous to types, and commands analogous to methods (drawing analogies to OOP).
            \subsubsection*{Buffer Objects}
                A buffer object stores an array of unformatted memory allocated by the OpenGL context (the GPU) - and they are regular OpenGL objects.
                In order to set up the internal state, it must be bound to the context;
                \begin{lstlisting}
                    void glBindBuffer(enum target, uint bufferName)
                \end{lstlisting}
                To put immutable data on it, the command ~void glBufferStorage(...);~ is used, whereas ~void glBufferData(...);~ is used for mutable data.
                An example is as follows;
                \begin{lstlisting}
                    GLuint my_buffer;

                    // request an unused buffer object name
                    glGenBuffers(1, &my_buffer);

                    // bind name as GL_ARRAY_BUFFER
                    // bound for the first time => creates
                    glBindBuffer(GL_ARRAY_BUFFER, my_buffer);

                    // put some data into my_buffer
                    glBufferStorage(GL_ARRAY_BUFFER, ...);

                    // "unbind" buffer
                    glBindBuffer(GL_ARRAY_BUFFER, 0);

                    // bind it again
                    glBindBuffer(GL_ARRAY_BUFFER, my_buffer);
                    // use it

                    // example of drawing (type, startIdx, number of elements)
                    glDrawArrays(GL_TRIANGLES, 0, 33);

                    // delete buffer object, free resources, release buffer object name
                    glDeleteBuffers(1, &my_buffer);
                \end{lstlisting}
            \subsubsection*{Primitive Types}
                The primitive types available to us are;
                \begin{itemize}
                    \itemsep0em
                    \item ~GL\_POINTS~
                        \begin{center}
                            \begin{tikzpicture}
                                \node[rbtb] at (0, 0) {};
                                \node[rbtb] at (1, -0.2) {};
                                \node[rbtb] at (-0.2, -0.4) {};
                                \node[rbtb] at (1.2, -1) {};
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_LINES~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (1, 1);
                                \draw (1, 0.7) -- (1.8, -0.1);
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_LINE\_STRIP~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (-1, 1) -- (-1.5, 0.3) -- (2, 0.5) -- (1, 1.1) -- (1.5, -0.1) -- (-0.2, -0.5);
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_LINE\_LOOP~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (2, 0.5) -- (1, 1.1) -- (1.5, -0.1) -- (-0.2, -0.5) -- cycle;
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_POLYGON~
                        \begin{center}
                            \begin{tikzpicture}
                                \node[
                                    regular polygon,
                                    regular polygon sides=6,
                                    draw,
                                    inner sep=0.5cm,
                                ] (hexagon) {};
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_TRIANGLE\_STRIP~
                        \begin{center}
                            \begin{tikzpicture}
                                \node (a) at (0, 0) {0};
                                \node (b) at (2, 0.5) {1};
                                \node (c) at (1.5, 1.5) {2};
                                \node (d) at (4, 0) {3};
                                \node (e) at (5, 1.3) {4};
                                \draw
                                (a) -- (b) -- (c) -- (a)
                                (b) -- (d) -- (e) -- (c) -- (d);
                            \end{tikzpicture}
                        \end{center}
                        It's important to note that here we alternate between identifying vertices; starting with a counter clockwise ordering, then clockwise, and so on.
                        For example, the first triangle will be 0, 1, 2, then the second triangle is 1, 2, 3, and then the third triangle is 2, 3, 4.
                        This allows vertices to be shared, and is therefore more memory efficient.
                    \item ~GL\_TRIANGLES~
                        \begin{center}
                            \begin{tikzpicture}
                                \node (a) at (0, 0) {0};
                                \node (b) at (1, -1) {1};
                                \node (c) at (0.5, 1) {2};
                                \draw (a) -- (b) -- (c) -- (a);
                            \end{tikzpicture}
                        \end{center}
                        It's important to note that here we identify vertices counter clockwise (the triangle is 0, 1, 2).
                    \item ~GL\_TRIANGLE\_FAN~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (0.1, 1) -- (1.5, 1.2) -- (2, 0.3) -- (2.6, 0.1) -- (2.1, -0.3) -- cycle;
                                \draw
                                (0, 0) -- (1.5, 1.2)
                                (0, 0) -- (2, 0.3)
                                (0, 0) -- (2.6, 0.1);
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_QUADS~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (1, -0.3) -- (0.7, -0.8) -- (-0.2, -0.5) -- cycle;
                                \draw (0.5, -1.5) -- (1.3, -1.4) -- (1.1, -1.8) -- (0, -2.2) -- cycle;
                            \end{tikzpicture}
                        \end{center}
                    \item ~GL\_QUAD\_STRIP~
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (2, 0.2) -- (1.8, -0.8) -- (1.7, -1.8) -- (2, -2.4) -- (1, -2.7) -- (0.3, -1.5) -- (0.6, -0.9) -- cycle;
                                \draw
                                (1.8, -0.8) -- (0.6, -0.9)
                                (1.7, -1.8) -- (0.3, -1.5);
                            \end{tikzpicture}
                        \end{center}
                \end{itemize}
                A draw call, which isn't used after OpenGL 4, is done as follows;
                \begin{lstlisting}
                    glBegin(GL_TRIANGLE_STRIP); // primitive type
                    glColor3f(0.0, 1.0, 0.0); // colour state
                    glVertex3f(1.0, 0.0, 0.0); // vertex index
                    ...
                    glEnd();
                \end{lstlisting}
                The more efficient method of doing it is to do the following (using buffer objects) for continuous groups of vertices;
                \begin{lstlisting}
                    glDrawArrays(GL_TRIANGLES, 0, num_vertices);
                \end{lstlisting}
            \subsubsection*{Shaders}
                A shader is a piece of code that can be put in the graphics pipeline.
                To create a vertex or fragment shader, the following has to be done (anything that's not `filled in' will default to fixed functions);
                \begin{center}
                    \begin{tikzpicture}
                        \begin{scope}[shift={(0, 0)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {\shortstack{~glCreateShader~\\~(GL\_FRAGMENT\_SHADER)~}};
                        \end{scope}
                        \begin{scope}[shift={(0, -2)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glShaderSource(...)~};
                        \end{scope}
                        \begin{scope}[shift={(0, -4)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glCompileShader(...)~};
                        \end{scope}
                        \begin{scope}[shift={(0, -6)}]
                            \draw[fill=black!20] (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glAttachShader(...)~};
                        \end{scope}
                        \begin{scope}[shift={(6, 0)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {\shortstack{~glCreateShader~\\~(GL\_VERTEX\_SHADER)~}};
                        \end{scope}
                        \begin{scope}[shift={(6, -2)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glShaderSource(...)~};
                        \end{scope}
                        \begin{scope}[shift={(6, -4)}]
                            \draw (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glCompileShader(...)~};
                        \end{scope}
                        \begin{scope}[shift={(6, -6)}]
                            \draw[fill=black!20] (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glAttachShader(...)~};
                        \end{scope}
                        \begin{scope}[shift={(12, -6)}]
                            \draw[fill=black!20] (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glCreateProgram()~};
                        \end{scope}
                        \begin{scope}[shift={(0, -8)}]
                            \draw[fill=black!20] (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glLinkProgram(...)~};
                        \end{scope}
                        \begin{scope}[shift={(12, -8)}]
                            \draw[fill=black!20] (0, 0) -- (5, 0) -- (5, 1) -- (0, 1) -- cycle;
                            \node at (2.5, 0.5) {~glUseProgram(...)~};
                        \end{scope}
                        \draw
                        (12, -5.5) edge[->] (11, -5.5)
                        (6, -5.5) edge[->] (5, -5.5)
                        (5, -7.5) edge[dotted, ->] (12, -7.5)
                        (2.5, 0) edge[->] (2.5, -1)
                        (2.5, -2) edge[->] (2.5, -3)
                        (2.5, -4) edge[->] (2.5, -5)
                        (2.5, -6) edge[->] (2.5, -7)
                        (8.5, 0) edge[->] (8.5, -1)
                        (8.5, -2) edge[->] (8.5, -3)
                        (8.5, -4) edge[->] (8.5, -5);
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{GLSL}
                We have the following types available, initialised with C++ style constructors (~vec3 a = vec3(1.0, 2.0, 3.0);~);
                \begin{itemize}
                    \itemsep0em
                    \item \textbf{scalar types} \hfill ~float~, ~int~, ~bool~
                    \item \textbf{vector types} \hfill ~vec2~, ~vec3~, ~vec4~, ~ivec2~, ~ivec3~, ~ivec4~, ~bvec2~, ~bvec3~, ~bvec4~
                    \item \textbf{matrix types} \hfill ~mat2~, ~mat3~, ~mat4~
                    \item \textbf{texture sampling} \hfill ~sampler1D~, ~sampler2D~, ~sampler3D~, ~samplerCube~
                        \smallskip

                        Specific piece of hardware that does memory access very efficiently.
                \end{itemize}
                The standard C/C++ arithmetic and logic operators hold, as well as operators being overloaded for matrix and vector operations;
                \begin{lstlisting}
                    mat4 m;
                    vec4 a, b, c;

                    b = a*m;
                    c = m*a;
                \end{lstlisting}
                Vectors can be accessed via index (~[]~), ~xyzw~, ~rgba~, or ~stpq~, therefore;
                \begin{lstlisting}
                    vec3 v;
                    v[1] == v.y == v.g == v.t
                \end{lstlisting}
                Swizzling is the following (not really mentioned in detail) - asking for objects in a different order;
                \begin{lstlisting}
                    vec3 a, b;
                    a.xy = b.yx;
                \end{lstlisting}
                ~in~ and ~out ~ copy vertex attributes and other variables to / from shaders (they need to match the next step of the pipeline), whereas ~uniform~ denotes a variable from the application;
                \begin{lstlisting}
                    in vec2 tex_coord;
                    out vec4 colour;

                    uniform float time;
                    uniform vec4 rotation;
                \end{lstlisting}
                We are also given some functions;
                \begin{itemize}
                    \itemsep0em
                    \item \textbf{arithmetic} \hfill e.g. ~sqrt~, ~power~, ~abs~
                    \item \textbf{trigonometric} \hfill e.g. ~sin~, ~asin~
                    \item \textbf{graphical} \hfill e.g. ~length~, ~reflect~
                    \item users can also define functions
                \end{itemize}
                Built-in variables include ~gl\_Position~ which denotes the output position from the vertex shader, and ~gl\_FragColor~, denoting the output colour from the fragment shader.
                This is only for ES, WebGL, and older versions of GLSL (present versions use an out variable).
                \medskip

                The anatomy of a GLSL shader is as follows;
                \begin{lstlisting}
                    #version 400

                    uniform mat4 some_uniform // set by application (configuration values e.g. MVP Matrix)

                    // optional flexible register configuration between shaders (location stuff)
                    layout(location = 0) in vec3 some_input;
                    layout(location = 1) in vec4 another_input;

                    out vec4 some_output; // output definition for next shader stage

                    void main() {

                    }
                \end{lstlisting}
                An example of a fragment shader is as follows;
                \begin{lstlisting}
                    #version 400

                    uniform vec4 ambient;
                    uniform vec4 diffuse;
                    uniform vec4 specular;
                    uniform float shininess;

                    uniform vec4 lightPosition_camSpace; // light position in camera space

                    in fragmentData {
                        vec4 position_camSpace;
                        vec3 normal_camSpace;
                        vec2 textureCoordinate;
                        vec4 color;
                    } frag;

                    out vec4 fragColor;

                    void main(void) {
                        fragColor = frag.color;
                    }
                \end{lstlisting}
        \subsection*{Lecture 6 - Illumination, Shading, and Colour I}
            With very basic illumination, the result is a flat image with a single colour (and we cannot infer a shape).
            We want to give the impression that light acts in a more complex way.
            In local illumination, we focus on how \textbf{one} object interacts with the light sources; we do not consider how objects interact with other objects (such as reflections).
            \subsubsection*{Physics of Shading}
                The light we want to model is whatever is reflected from our object.
                In this lecture, we only consider the brightness at each point.
                Illumination is dependent on various environmental factors, including the properties of the light source;
                \begin{itemize}
                    \itemsep0em
                    \item intensity of emitted light
                    \item distance to the point on the surface (light spreads out)
                \end{itemize}
                As well as object (surface) properties;
                \begin{itemize}
                    \itemsep0em
                    \item surface normal vector
                    \item object position relative to light source
                    \item reflectivity / albedo (ability to absorb light energy) of the surface
                \end{itemize}
            \subsubsection*{Radiometry}
                \begin{align*}
                    e_\lambda & = \frac{hc}{\lambda} & \text{energy of a photon} \\
                    h & \approx 6.63 \times 10^{-34} Js & \text{Planck constant} \\
                    c & \approx 3 \times 10^8 ms^{-1} & \text{speed of light} \\
                    Q & = \summation{i = 1}{n} \frac{hc}{\lambda_i} & \text{radiant energy of $n$ photons} \\
                    \Phi & = \dif{Q}{t} & \text{radiation / electromagnetic / radiant flux (in Watts)}
                \end{align*}
                Radiant flux is the number of photons we have available to reflect at any one time.
                \textbf{Radiance} is defined as the radiant flux per unit solid angle per unit projected area; the number of photons per time at a small area in a particular direction (units are watts per meter$^2$ steradian);
                \begin{center}
                    \begin{tikzpicture}[x=1.25cm, y=1.25cm]
                        \draw
                        (0, 0) edge[->] (0, 2)
                        (0, 0) edge[->] (2, 0)
                        (0, 0) edge[->] (-1.4, -1.4);
                        \draw (-0.3, 0.2) -- (0.7, 0.2) -- (0.2, -0.3) -- (-0.8, -0.3) -- cycle;
                        \begin{scope}[rotate={50}]
                            \draw (0, 0) edge[->] (2.5, 0);
                            \draw (0, 0) -- (2.2, 0.1);
                            \draw (0, 0) -- (2.2, -0.1);
                            \draw (2.2, 0) ellipse (0.04 and 0.1);
                        \end{scope}
                        \node at (0.3, 2) {$z$};
                        \node at (2, -0.3) {$y$};
                        \node at (-1.1, -1.4) {$x$};
                        \node at (0.5, -0.3) {$\mathrm{d}A$};
                        \node at (1.9, 1.9) {$L$};
                        \node at (1.55, 1.4) {$\mathrm{d}\omega$};
                        \draw[<->] (0, 0) ++(50:1) arc (50:90:1);
                        \node at (0.45, 1.2) {$\theta$};
                        \node at (6, 0) {$L(\omega) = \dfrac{\mathrm{d}^2 \Phi}{\cos \theta \mathrm{d} A \mathrm{d} \omega}$};
                    \end{tikzpicture}
                \end{center}
                \textbf{Irradiance} is how much light arrives from any other surface on another surface.
                It is the differential flux falling onto differential area (in Watts per meter$^2$).
                $$E = \dif{\Phi}{A}$$
                It can be seen as a density of incident flux falling onto a surface, and can be obtained by integrating the radiance over the solid angle.
            \subsubsection*{Reflection and Reflectance}
                The actual property we want to model is reflection.
                We want to work out how much is reflected to the viewer.
                \textbf{Reflection} is the process by which electromagnetic flux incident on a surface leaves the surface without a change in frequency (fluorescence), and \textbf{reflectance} is a fraction of the incident flux that is reflected.
                We do not consider absorption, transmission nor diffraction.
                \medskip

                We want to find out how much is reflected when $E_i$ reaches an infinitely small patch of surface.
                To model this, we need the Bidirectional Reflectance Distribution Function (BRDF) (also seen in \textbf{CO316}) - the units are steradian$^{-1}$;
                $$f_r(\theta_i, \phi_i, \theta_r, \phi_r) = \dif{L_r(\theta_r, \phi_r)}{E_i(\theta_i, \phi_i)}$$
                In this case, $L_r$ is the viewer, and $E_i$ the light source.
                \medskip

                Given our surface is well behaved and generally flat, we can simplify it by stating that a rotation along the surface normal does not change the reflectance;
                $$f_r(\theta_i, \theta_r, \phi_r - \phi_i) = f_r(\theta_i, \theta_r, \phi_d) = \dif{L_r(\theta_r, \phi_d)}{(\theta_i, \phi_d)}$$
                However, this isn't true for surfaces with strongly oriented nanostructures (such as \textit{vantablack}, hair, fur, velvet).
                The properties of BRDFs are as follows;
                \begin{itemize}
                    \itemsep0em
                    \item non-negative
                        $$f_r(\theta_i, \phi_i, \theta_r, \phi_r) \geq 0$$
                    \item energy conservation \hfill we never have more light come out than comes in
                        $$\forall \theta_i, \phi_i\ \defint{\Omega}{}{f_r(\theta_i, \phi_i, \theta_r, \phi_r)}{\mu(\theta_r, \phi_r)} \leq 1$$
                    \item reciprocity
                        $$f_r(\theta_i, \phi_i, \theta_r, \phi_r) = f_r(\theta_r, \phi_r, \theta_i, \phi_i)$$
                \end{itemize}
                In our case, we only consider the discrete version to compute reflected radiance (with $n$ point light sources)- note that $\Phi_{s, j}$ denotes radiant flux, and $d_j$ is the distance;
                $$L_r(\omega_r) = \summation{j = 1}{n} f_r(\omega_{i, j}, \omega_r) E_j = \summation{j = 1}{n} f_r(\omega_{i, j}, \omega_r) \cos \theta_j \frac{\Phi_{s, j}}{4 \pi d_j^2} $$
                Some cases;
                \begin{itemize}
                    \itemsep0em
                    \item \textbf{ideal diffuse reflectance} \hfill depends on light source position and surface normal
                        \smallskip

                        In this case we define BRDF as a constant.
                        The only dependence is the position of our light, and how that is related to the normal vector of our surface.
                        At a microscopic level, an ideal diffuse surface is very rough (such as chalk, clay, or some paints).
                        \begin{center}
                            \begin{tikzpicture}
                                \draw[blue!50!black] (0, 0) edge[below] node{rough surface} (6, 0);
                                \draw[red!50!black] (1.25, 2) edge[->] (3, 0);
                                \draw[dashed, blue!50]
                                (4, 0) arc(0:180:1) -- cycle
                                (3, 0) edge[->] +(0:1)
                                (3, 0) edge[->] +(15:1)
                                (3, 0) edge[->] +(30:1)
                                (3, 0) edge[->] +(45:1)
                                (3, 0) edge[->] +(60:1)
                                (3, 0) edge[->] +(75:1)
                                (3, 0) edge[->] +(90:1)
                                (3, 0) edge[->] +(105:1)
                                (3, 0) edge[->] +(120:1)
                                (3, 0) edge[->] +(135:1)
                                (3, 0) edge[->] +(150:1)
                                (3, 0) edge[->] +(165:1)
                                (3, 0) edge[->] +(180:1);
                            \end{tikzpicture}
                        \end{center}
                        This has a constant BRDF value;
                        \begin{align*}
                            L_r(\omega_r) & = \defint{\Omega}{}{f_r{\omega_i, \omega_r}}{E_i{\omega_i}} \\
                            & = f_r \defint{\Omega}{}{}{E_i{\omega_i}} \\
                            & = f_r E_i \\
                            \mathrm{d}B & = \mathrm{d}A \cos \theta_i
                        \end{align*}
                        Using the following, we can see that the reflection is maximal when it is parallel to the normal, and minimal when it is perpendicular;
                        \begin{center}
                            \begin{tikzpicture}
                                \begin{scope}[shift={(2, 0)}, rotate={-30}]
                                    \draw (0, 1.75) edge[<->] (0.5, 1.75);
                                    \draw (0, 0) -- (0.5, 0) -- (0.5, 2) -- (0, 2) -- cycle;
                                    \draw (0, 0) edge[dashed, ->] (0, 3);
                                \end{scope}
                                \node at (3.8, 2.7) {$\vec{l}$};
                                \draw[white, fill=white] (0, 0) -- (4, 0) -- (4, -1) -- (0, -1) -- cycle;
                                \draw (0, 0) edge[below] node{surface} (4, 0);
                                \draw (2, 0) edge[->] (2, 2);
                                \node at (2, 2.25) {$\vec{n}$};
                                \draw[<->] (2, 0) ++(60:1) arc (60:90:1);
                                \node at (2.3, 1.3) {$\theta_i$};
                                \begin{scope}[shift={(0.1, 0.2)}]
                                    \draw (2, 0) edge[<->] (2.577, 0);
                                \end{scope}
                                \node at (3.1, 0.2) {$\mathrm{d}A$};
                                \node at (3.8, 1.15) {$\mathrm{d}B$};
                            \end{tikzpicture}
                        \end{center}
                        These reflectors reflect light according to \textbf{Lambert's cosine law}; the more parallel the light is to the normal, the higher the strength of the outgoing light.
                        This is physically incorrect, but it is an approximation, and gives a basic shading.
                        From a single point light source \textbf{to} direction $\vec{l}$, on a a surface with diffuse reflection coefficient $k_d$ (the colour of the surface in the simplest case) and surface normal $\vec{n}$;
                        $$L(\omega_r) = k_d (\vec{n} \cdot \vec{l}) \frac{\Phi_s}{4 \pi d^2}$$
                        The direction \textbf{vectors must be normalised}.
                        Note that from this point on, using $\vec{n} \cdot \vec{l}$ denotes $\max(\vec{n} \cdot \vec{l}, 0)$; ensuring that the result is at least 0.
                    \item \textbf{ideal specular reflectance} \hfill depends on light source position, surface normal, and viewpoint position
                        \smallskip

                        In contrast to diffuse, reflection is \textbf{only} at mirror angle, and is view dependent.
                        Nanostructures of the surface are usually oriented in the same direction as the surface (such as polished metals or mirrors).
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (3, 0) ++(48.8:1) arc (48.8:132.2:1);
                                \draw[blue!50!black] (0, 0) edge[below] node{smooth surface} (6, 0);
                                \draw[red!50!black] (1.25, 2) edge[<-] (3, 0);
                                \draw[blue!50] (4.75, 2) edge[<-] (3, 0);
                                \draw[dashed] (3, 1.5) -- (3, 0);

                                \node at (3, 1.75) {$\vec{n}$};
                                \node at (2.5, 1.25) {$\theta$};
                                \node at (3.5, 1.25) {$\theta$};
                            \end{tikzpicture}
                        \end{center}
                        This uses a special case of Snell's law, where the incoming ray, the surface normal, and reflected ray are all on a common plane;
                        \begin{align*}
                            n_l \sin \theta_l & = n_r \sin \theta_r \\
                            n_l & = n_r  \\
                            \theta_l & = \theta_r
                        \end{align*}
                        What we want to do is figure out how our viewpoint is related to the reflectance direction.
                    \item \textbf{non-ideal reflectors}
                        \smallskip

                        In the real world, materials are neither ideal mirror reflectors following Snell's law, nor ideal diffuse surfaces.
                        A simple empirical model expects most of the light reflected to travel in the direction of the ideal ray; however due to surface nanostructures some of the light can be expected to be reflected slightly offset from the ideal.
                        As we move further out (in the angular sense) from the reflected ray, we expect to see less light reflected.
                        \begin{center}
                            \hfill
                            \begin{tikzpicture}
                                \draw[blue!50!black] (0, 0) edge[below] node{slightly specular surface} (6, 0);
                                \draw[red!50!black] (1.25, 2) edge[->] (3, 0);
                                \draw[dashed, blue!50]
                                (3, 0) edge[->] +(0:1)
                                (3, 0) edge[->] +(15:1.125)
                                (3, 0) edge[->] +(30:1.25)
                                (3, 0) edge[->] +(45:1.5)
                                (3, 0) edge[->] +(60:1.25)
                                (3, 0) edge[->] +(75:1.125)
                                (3, 0) edge[->] +(90:1)
                                (3, 0) edge[->] +(105:1)
                                (3, 0) edge[->] +(120:1)
                                (3, 0) edge[->] +(135:1)
                                (3, 0) edge[->] +(150:1)
                                (3, 0) edge[->] +(165:1)
                                (3, 0) edge[->] +(180:1);
                            \end{tikzpicture}
                            \hfill
                            \begin{tikzpicture}
                                \draw[blue!50!black] (0, 0) edge[below] node{highly specular surface} (6, 0);
                                \draw[red!50!black] (1.25, 2) edge[->] (3, 0);
                                \draw[dashed, blue!50]
                                (3, 0) edge[->] +(0:1)
                                (3, 0) edge[->] +(15:1.1)
                                (3, 0) edge[->] +(30:1.5)
                                (3, 0) edge[->] +(45:2)
                                (3, 0) edge[->] +(60:1.5)
                                (3, 0) edge[->] +(75:1.1)
                                (3, 0) edge[->] +(90:1)
                                (3, 0) edge[->] +(105:0.8)
                                (3, 0) edge[->] +(120:0.8)
                                (3, 0) edge[->] +(135:0.8)
                                (3, 0) edge[->] +(150:0.8)
                                (3, 0) edge[->] +(165:0.8)
                                (3, 0) edge[->] +(180:0.8);
                            \end{tikzpicture}
                            \hfill \phantom{}
                        \end{center}
                        In the case of the slightly shiny surface, there is slightly higher intensity in the reflected direction, however in the highly shiny surface, there is high intensity in the reflected direction.
                        \medskip

                        The \textbf{Phong} model states that the closer the viewer direction $\alpha$ is to the ideal reflection direction, the brighter the light should appear.
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (3, 0) ++(63.4:1) arc (63.4:116.6:1);
                                \draw (0, 0) edge[below] node{smooth surface} (6, 0);
                                \draw (2, 2) edge[<-] (3, 0);
                                \draw (4, 2) edge[<-] (3, 0);
                                \draw (1, 1) edge[<-] (3, 0);
                                \draw (3, 0) ++(116.6:1.5) arc (116.6:153.4:1.5);
                                \draw (3, 1.5) edge[<-] (3, 0);

                                \node at (0.75, 1) {$\vec{v}$};
                                \node at (3, 1.75) {$\vec{n}$};
                                \node at (1.75, 2) {$\vec{r}$};
                                \node at (4.25, 2) {$\vec{l}$};
                                \node at (2.75, 1.25) {$\theta$};
                                \node at (3.25, 1.25) {$\theta$};
                                \node at (1.75, 1.3) {$\alpha$};
                            \end{tikzpicture}
                        \end{center}
                        Therefore we have the following, where $k_s$ is the specular reflection coefficient, and $q$ the specular reflection exponent;
                        $$L(\omega_r) = k_s (\cos \alpha)^q \frac{\Phi_s}{4 \pi d^2} = k_s (\vec{v} \cdot \vec{r})^q \frac{\Phi_s}{4 \pi d^2}$$
                        A higher $q$ leads to a more focused light (a shiner surface), and $k_s$ is the surface property we want to manipulate.
                        In order to obtain $\vec{r}$, we can calculate the following;
                        \begin{align*}
                            \vec{r} + \vec{l} & = 2 \cos \theta \vec{n} & \Rightarrow \\
                            \vec{r} & = 2(\vec{n} \cdot \vec{l}) \vec{n} - \vec{l} \\
                            L(\omega_r) & = k_s (\vec{v} \cdot (2(\vec{n} \cdot \vec{l}) \vec{n} - \vec{l}))^q \frac{\Phi_s}{4 \pi d^2}
                        \end{align*}
                        The \textbf{Blinn-Phong} variation uses the halfway vector $\vec{h}$ between $\vec{l}$ and $\vec{v}$;
                        \begin{align*}
                            \vec{h} & = \frac{\vec{l} + \vec{v}}{|| \vec{l} + \vec{v} ||} \\
                            L(\omega_r) & = k_s (\cos \beta)^q \frac{\Phi_s}{4 \pi d^2} \\
                            & = k_s (\vec{n} \cdot \vec{h})^q \frac{\Phi_s}{4 \pi d^2}
                        \end{align*}
                    \item \textbf{ambient}
                        \smallskip

                        This represents the reflection of all indirect illumination (it is a hack).
                        This avoids the complexity of global illumination;
                        $$L(\omega_r) = k_a$$
                \end{itemize}
                The Phong model is a sum of three components; the \teal{ambient}, the \violet{diffuse} reflection, and the \blue{specular} reflection.
                $$L(\omega_r) = \teal{k_a} + (\violet{k_d (\vec{n} \cdot \vec{l})} + \blue{k_s (\vec{v} \cdot \vec{r})^q}) \frac{\Phi_s}{4 \pi d^2}$$
            \subsubsection*{Note on Inverse Square Law}
                Light falls off according to an inverse square law, hence the $d^2$ term.
                However, it may not produce the best results, and we can instead often use $(d + s)$ in place, where $s$ is a heuristic constant.
            \subsubsection*{Shading}
                The three levels at which shading can be applied in polygon based systems, providing increasing realism at the cost of computation, are;
                \begin{itemize}
                    \itemsep0em
                    \item \textbf{flat shading}
                        \smallskip

                        This can be done wherever.
                        Each polygon is shaded uniformly over is surface, and computed by taking a point in the centre and at the surface normal (consider a light source at infinity).
                        Normally, only the diffuse and ambient components are used
                    \item \textbf{Gouraud shading}
                        \smallskip

                        Interpolates colour across triangles.
                        This is fast, and supported by most GPUs, but cannot accurately model specular components (since we don't have normal vectors at each point on a polygon).
                    \item \textbf{Phong shading} \hfill fragment stage
                        \smallskip

                        Interpolates normals across triangles; more accurate modelling of specular components, but slower.
                \end{itemize}
                \textbf{Interpolation shading} is a more accurate way to render a shaded polygon, by computing an independent shade at each point;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item compute a shade value at each vertex
                    \item interpolate to find shade value at the boundary \hfill $L = \frac{d_1 L_3 + d_2 L_1}{d_1 + d_2}$
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (2, 3) -- (3, -1) -- cycle;
                                \node[rbtb] at (0, 0) {};
                                \node[rbtb] at (2, 3) {};
                                \node[rbtb] at (3, -1) {};
                                \node[rbtb] at (2.5, 1) {};
                                \node at (2.5, 3) {$L_1$};
                                \node at (0, -0.5) {$L_2$};
                                \node at (3.5, -1) {$L_3$};
                                \node at (3, 1) {$L$};
                                \node at (2.75, 2) {$d_1$};
                                \node at (3.25, 0) {$d_2$};
                            \end{tikzpicture}
                        \end{center}
                    \item interpolate to find shade values in the middle \hfill $L = \frac{d_1 L_B + d_2 L_A}{d_1 + d_2}$
                        \begin{center}
                            \begin{tikzpicture}
                                \draw (0, 0) -- (2, 3) -- (3, -1) -- cycle;
                                \node[rbtb] at (0, 0) {};
                                \node[rbtb] at (2, 3) {};
                                \node[rbtb] at (3, -1) {};
                                \node[rbtb] at (2.5, 1) {};
                                \node[rbtb] at (2/3, 1) {};
                                \node at (2.5, 3) {$L_1$};
                                \node at (0, -0.5) {$L_2$};
                                \node at (3.5, -1) {$L_3$};
                                \node at (3, 1) {$L_B$};
                                \node at (2/3 - 0.5, 1) {$L_A$};
                                \node[rbtb] at (1.5, 1) {};
                                \draw (2/3, 1) -- (2.5, 1);
                                \node at (1.08333, 0.5) {$d_1$};
                                \node at (2, 1.5) {$d_2$};
                            \end{tikzpicture}
                        \end{center}
                \end{enumerate}
        \subsection*{Lecture 7 - Illumination, Shading, and Colour II}
            Colours are energy distributions.
            Lasers are light sources that contain a single / narrow band of wavelengths.
            Light is made up of a mixture of many wavelengths, with an energy distribution.
            This lecture starts with a lot about colour, similar to \textbf{CO316}.
            The \textbf{tri-stimulus colour theory} states receptor performance implies that colours do not have a unique energy distribution, and more importantly colours which are a distributed over all wavelengths can be matched by mixing red, green, and blue.
            \subsubsection*{Colour Matching}
                Given any colour light source, we can try to match it with a mixture of three light sources (with $R, G, B$ being pure light sources, and $r, g, b$ being their respective intensities);
                $$X = rR + gG + bB$$
                However, not all colours can be matched with a given set of light sources - we cannot model anything that will take out colour.
                \textbf{Subtractive matching} allows us to add light to the colour we are trying to match, for example;
                $$X + r = g + b$$
                Printed documents cannot emit light, and are examples of subtractive matching (as opposed to mixing light emitters such as screens, which is additive matching).
            \subsubsection*{CIE Diagram}
                The CIE diagram was devised as a standard normalised representation of colours.
                Consider normalising the ranges between 0 and 1.
                The colours can be normalised such that the components sum to 1;
                \begin{align*}
                    x & = \frac{r}{r + g + b} \\
                    y & = \frac{g}{r + g + b} \\
                    z & = \frac{b}{r + g + b} \\
                    & = 1 - x - y
                \end{align*}
                This has the following representation, where we have the hypothetical sources as follows;
                \begin{center}
                    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
                        \draw
                        (0, -0.2) edge[->] (0, 1.2)
                        (-0.2, 0) edge[->] (1.2, 0)
                        (0, 1) edge[dashed] (1, 0);
                        \node[inner sep=2pt, circle, draw=black, fill=red] at (1, 0) {};
                        \node[inner sep=2pt, circle, draw=black, fill=green] at (0, 1) {};
                        \node[inner sep=2pt, circle, draw=black, fill=blue] at (0, 0) {};
                        \node at (-0.25, 1.2) {$y$};
                        \node at (1.2, -0.25) {$x$};
                    \end{tikzpicture}
                \end{center}
                However, the actual visible colours are a subset of this, done through manual testing.
                The pure colours (coherent $\lambda$) are around the edge of the diagram.
                In addition, the shape must be convex, since any blend would produce a colour in the visible region.
                When the three colours are components are equal, the colour is white ($x = y \approx 0.33$).
                Pure colours are fully saturated (colours on the edge of the horseshoe), and a line from the pure colour $P$ going through the white point $W$ will cross over on the other side at a \textbf{complement colour} $C$.
            \subsubsection*{Conversion}
                Converting from RGB (monitor's representation) to CIE is done with the following;
                $$\begin{bmatrix}
                    x \\ y \\ z
                \end{bmatrix} = \begin{bmatrix}
                    0.628 & 0.268 & 0.150 \\
                    0.346 & 0.588 & 0.070 \\
                    0.026 & 0.144 & 0.780
                \end{bmatrix} \begin{bmatrix}
                    R \\ G \\ B
                \end{bmatrix}$$
                A conversion between RGB and HSV is done as follows;
                \begin{align*}
                    V & = \max(r, g, b) \\
                    S & = \frac{\max(r, g, b) - \min(r, g, b)}{\max(r, g, b)} \\
                    H & = \begin{cases}
                        \text{undefined} & r = g = b \\
                        120 \cdot \frac{g - b}{(r - b) + (g - b)} & (r > b) \land (g > b) \\
                        120 + 120 \cdot \frac{b - r}{(g - r) + (b - r)} & (g > r) \land (b > r) \\
                        240 + 120 \cdot \frac{r - g}{(r - g) + (b - g)} & (r > g) \land (b > g)
                    \end{cases}
                \end{align*}
            \subsubsection*{Transparency}
                In addition, we can model transparency with an $\alpha$ channel;
                \begin{itemize}
                    \itemsep0em
                    \item transparent \hfill $\alpha = 0$
                    \item semi-transparent \hfill $0 < \alpha < 1$
                    \item opaque \hfill $\alpha = 1$
                \end{itemize}
        \subsection*{Lecture 8 - Texture Mapping}
\end{document}