\documentclass[a4paper, 12pt]{article}
% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{lstautogobble}
\usepackage{hyperref}
\usepackage{multirow}
\usetikzlibrary{arrows, shapes.gates.logic.US, circuits.logic.US, calc, automata, positioning}

% shorthand for verbatim
\catcode`~=\active
\def~#1~{\texttt{#1}}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\newcommand{\dollar}{\mbox{\textdollar}} %
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\displaystyle{\lim_{#1 \to #2}}}
\newcommand{\summation}[3]{\sum\limits_{#1}^{#2} #3}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}
\newcommand{\ulsmash}[1]{\underline{\smash{#1}}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}

\newcommand{\unaryproof}[2]{\AxiomC{#1} \UnaryInfC{#2} \DisplayProof}
\newcommand{\binaryproof}[3]{\AxiomC{#1} \AxiomC{#2} \BinaryInfC{#3} \DisplayProof}
\newcommand{\trinaryproof}[4]{\AxiomC{#1} \AxiomC{#2} \AxiomC{#3} \TrinaryInfC{#4} \DisplayProof}

% no indent
\setlength\parindent{0pt}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofmath}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% reasoning er diagrams
\newcommand{\nattribute}[4]{
    \node[draw, state, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\mattribute}[4]{
    \node[draw, state, accepting, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\dattribute}[4]{
    \node[draw, state, dashed, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\entity}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 0.5)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -0.5)$) {};
    \draw
    ($(#1-c) + (-1, 0.5)$) -- ($(#1-c) + (1, 0.5)$) -- ($(#1-c) + (1, -0.5)$) -- ($(#1-c) + (-1, -0.5)$) -- cycle;
}
\newcommand{\relationship}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 1)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -1)$) {};
    \draw
    ($(#1-c) + (-1, 0)$) -- ($(#1-c) + (0, 1)$) -- ($(#1-c) + (1, 0)$) -- ($(#1-c) + (0, -1)$) -- cycle;
}

% actual document
\begin{document}
    \section*{CO130 - Databases}
        \subsection*{Prelude}
            The content discussed here is part of CO130 - Databases (Computing MEng); taught by Thomas Heinis, in Imperial College London during the academic year 2018/19. The notes are written for my personal use, and have no guarantee of being correct (although I hope it is, for my own sake).
        \subsection*{Material Order}
            These notes are primarily based off the slides on CATe. This is the order in which they are uploaded (and I'd assume the order in which they are taught).
            \begin{enumerate}[1.]
                \itemsep0em
                \item \textit{Introduction.pdf}
                \item \textit{ER Modelling.pdf}
                \item \textit{ER to RM.pdf}
                \item \textit{Relational Algebra.pdf}
                \item \textit{Tutorial ER.pdf}
                \item \textit{Tutorial Translation.pdf}
                \item \textit{Relational Algebra.pdf}
                \item \textit{Functional Dependencies.pdf}
                \item \textit{Tutorial Relational Algebra.pdf}
                \item \textit{Normalisation.pdf}
                \item \textit{SQL.pdf}
                \item \textit{Data Definition.pdf}
                \item \textit{Data Manipulation.pdf}
                \item \textit{Advanced SQL.pdf}
                \item \textit{Functional Dependency Tutorial.pdf}
                \item \textit{Transactions.pdf}
                \item \textit{SQL Tutorial.pdf}
                \item \textit{Storage.pdf}
                \item \textit{Indexing.pdf}
                \item \textit{NoSQL.pdf}
                \item \textit{MapReduce.pdf}
            \end{enumerate}
        \subsection*{Introduction}
            We use databases as it's more organised; hence it's easier to model and manage. It's more efficient, as it's fast to search, and update, and integration allows us to minimise data duplication. Concurrent (and therefore multi-user) access allows multiple people to access the database at the same time (will require some techniques).
            \medskip

            \textbf{Transactions} are sequences of database actions that execute in a coherent, and reliable way - the classical properties are \textbf{ACID}. Consider the two transactions ~T1~: $A = A - 100; B = B + 100$, and ~T2~: $B = B - 100; A = A + 100$, we can observe ACID properties as follows;
            \begin{itemize}
                \itemsep0em
                \item \textbf{atomicity} \hfill if one part of a transaction fails, the entire transaction fails
                    \subitem on completion of ~T1~, either $A^\prime = A - 100$, and $B^\prime = B + 100$, or $A^\prime = A$, and $B^\prime = B$, where the former is a successful transaction, and the latter is in the case of a failure.
                \item \textbf{consistency} \hfill transactions don't leave the database in an inconsistent state
                    \subitem the sum of the balances must remain the same, such that $A^\prime + B^\prime = A + B$; we can also have more constraints such as keeping balances positive, or limiting the amount a transfer can do at once
                \item \textbf{isolation} \hfill transactions run as if no other transactions are running (may need to wait)
                    \subitem given the two concurrent transactions ~T1~, and ~T2~, one has to be completed before the other can start
                \item \textbf{durability} \hfill results of successful transactions aren't lost on system failure
                    \subitem the new values, $A^\prime$, and $B^\prime$ must persist if the transaction completes, even if the system fails (disk failure etc.)
            \end{itemize}
            A \textbf{Database Management System (DMBS)} creates new databases via a \textbf{Data Definition Language (DDL)}, which specifies the structure (\textbf{schema}). It also queries, and manipulates through a \textbf{Data Manipulation Language (DML)}. Examples of this include \textit{PostgreSQL}, \textit{MySQL}, \textit{SQLite}, and can also fall under \textit{NoSQL}, however SQL remains as the most widespread technology (as of writing this).
            \medskip

            It lets us define, query, and manipulate databases with a high-level declarative language (\textbf{Structured Query Language}). It's standardised by the ISO, but each DBMS implements its own variation of the standards, which may be costly if it's complex.
            \subsubsection*{Relational Model}
                Consider the following model, represented as a table;
                \begin{center}
                    \begin{tabular}{|c|c|c|c|c|}
                        \hline
                        heading & ~title:string~ & ~year:int~ & ~length:int~ & ~genre:string~ \\
                        \hline
                        \hline
                        \multirow{3}{*}{body} & Gone with the Wind & 1939 & 231 & Drama \\
                        \cline{2-5}
                        & Star Wars & 1977 & 124 & Science Fiction \\
                        \cline{2-5}
                        & Wayne's World & 1992 & 95 & Comedy \\
                        \hline
                    \end{tabular}
                \end{center}
                We have the columns be the attribute, with the top row being the heading, and the rest being the body. The attributes are in the format ~name:type~. The rows (of the body) are referred to as tuples. A relation is the heading as well as the body (the entire table). The heading is an \textbf{unordered set} of attributes, and an attribute is the name as well as the type (typically indivisible types). The body is an unordered set of tuples, and a tuple is the set of attribute values. The schema is for the entire relation is the name of the relation, and the heading, in this case, we'd have; ~movies(title:string, year:int, length:int, genre:string)~, and a database is a collection of relations. A schema for a database is the schemas for all relations.
                \medskip

                In mathematics, with a set of sets; $S_1, S_2, ..., S_n$, a relation $R$ is a set of tuples $T_1, T_2, ..., T_n$, where $T_k \in S_k$, therefore $R \subset S_1 \times S_2 \times ... \times S_n$. As the idea of relations stems from set theory, it's important to note that the order in which we represent the attributes, and tuples in unimportant. In the Relational model we have \textbf{attributed} tuples, rather than \textbf{ordered}; $R$ is the set of tuples ($A_1:S_1=T_1, ..., A_n:S_n=T_n$), with $T_k \in S_k$. It's important to note that relations aren't 2-dimensional tables, even though it's more convenient to draw it on paper. We should instead consider them as a set of $n$-dimensional values, such that we have (~title:string~=StarWars, ~year:int~=1997, ~length:int~=127, ~genre:string~=ScienceFiction), as a 4-dimensional movie value.
        \subsection*{Entity Relationship Modelling}
            When a new database is being developed, it's important to try and model the real-world situation, instead of trying to refine it into an implementation, such as a relational model. In Entity-Relationship modelling, we try to create a diagram which represents the information needed for the database (the Entity Relationship Diagram). As there is no universally accepting notation for ER diagrams, we will use the following notation;
            \begin{center}
                \begin{tabularx}{\textwidth}{|c|X|c|}
                    \hline
                    type & description & shape \\
                    \hline
                    \hline
                    entity sets & a set of distinguishable entries that share the same set of properties, can be physical (a room etc.), an event (flight, sale, etc.) - they normally correspond to nouns & rectangle \\
                    \hline
                    relationship sets & captures how \textbf{two or more} entity sets are related (e.g. owns, tutors), we can also have more than one relationship set between entity sets, and they can also have a relationship set on the same entity - they sometimes correspond to verbs & diamonds \\
                    \hline
                    attributes & properties of an entity; relationship sets can also have attributes, and primary keys are underlined & small circles \\
                    \hline
                \end{tabularx}
                \vspace{-1.5\baselineskip}
            \end{center}
            The movie example is represented below. Note that I've also extended it to contain different types of complex attributes. You can see that the address field is subdivided into number, and postcode, we have a multi-valued attribute in phones, and a derived attribute in age (can be calculated from date of birth)
            \begin{center}
                \begin{tikzpicture}
                    \entity{actor}{0, 0}{actor}
                    \entity{studio}{0, -3}{studio}
                    \relationship{actsin}{4, 0}{acts in}
                    \relationship{owns}{4, -3}{owns}
                    \entity{movie}{8, -1.5}{movie}
                    \nattribute{nactor}{-2, 0.25}{left}{\ulsmash{name}}
                    \nattribute{aactor}{-2, -0.25}{left}{address}
                    \mattribute{phones}{-0.75, 1}{above}{phones}
                    \dattribute{age}{0.75, 1}{above}{age}
                    \nattribute{nstudio}{-2, -2.75}{left}{\ulsmash{name}}
                    \nattribute{astudio}{-2, -3.25}{left}{address}
                    \nattribute{mtitle}{10, -1.25}{right}{\ulsmash{title}}
                    \nattribute{myear}{10, -1.75}{right}{\ulsmash{year}}
                    \nattribute{mgenre}{7.25, -2.5}{below}{genre}
                    \nattribute{mlength}{8.75, -2.5}{below}{length}
                    \nattribute{anumber}{-5, 0}{left}{number}
                    \nattribute{apostcode}{-5, -0.5}{left}{postcode}
                    \draw
                    (nactor) -- (actor-l)
                    (aactor) -- (actor-l)
                    (phones) -- (actor-u)
                    (age) edge[dashed] (actor-u)
                    (nstudio) -- (studio-l)
                    (astudio) -- (studio-l)
                    (actor-r) -- (actsin-l)
                    (studio-r) -- (owns-l)
                    (actsin-r) -- (movie-l)
                    (owns-r) -- (movie-l)
                    (movie-r) -- (mtitle)
                    (movie-r) -- (myear)
                    (movie-d) -- (mgenre)
                    (movie-d) -- (mlength)
                    (anumber) -- (-3.75, -0.25)
                    (apostcode) -- (-3.75, -0.25);
                \end{tikzpicture}
            \end{center}
            \subsubsection*{Cardinality Constraints}
                A relationship between two entity sets can be seen as one of the following (using the car example, where a person can drive $N$ cars, and a car can be driven by $M$ people);
                \begin{itemize}
                    \itemsep0em
                    \item one-to-one \hfill $M = 1, N = 1$
                    \item one-to-many \hfill $M = 1$
                    \item many-to-many \hfill no restrictions
                \end{itemize}
                \begin{center}
                    \begin{tikzpicture}
                        \entity{p}{0, 0}{person}
                        \relationship{d}{4, 0}{drive}
                        \entity{c}{8, 0}{car}
                        \draw
                        (p-r) edge[above] node{$M$} (d-l)
                        (d-r) edge[above] node{$N$} (c-l);
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{Participation}
                Using the same example, we can force participation, which means that all entities must participate in a relationship, with a double line. The example below, with the cars, suggests that everyone drives at least 1 car, and car can have at most 1 driver (note that it doesn't mean that every car has a driver).
                \begin{center}
                    \begin{tikzpicture}
                        \entity{p}{0, 0}{person}
                        \relationship{d}{4, 0}{drive}
                        \entity{c}{8, 0}{car}
                        \draw
                        (p-r) edge[double, above] node{1} (d-l)
                        (d-r) edge[above] node{$N$} (c-l);
                    \end{tikzpicture}
                \end{center}
                Sometimes, instead of using double lines, E-R notation may allow explicit bounds. The below diagram suggests that staff work in exactly 1 branch, and that each branch must have at least 3 members of staff;
                \begin{center}
                    \begin{tikzpicture}
                        \entity{p}{0, 0}{staff}
                        \relationship{d}{4, 0}{works}
                        \entity{c}{8, 0}{branch}
                        \draw
                        (p-r) edge[above] node{$3..N$} (d-l)
                        (d-r) edge[above] node{$1..1$} (c-l);
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{Fan, and Chasm Traps}
                See the diagrams in \textit{ER Modelling.pdf} for examples.
                \medskip

                We need to ensure that we do not allow ambiguous paths between entities. For example, if we say ~staff~ works for ~faculty~ which operates ~department~, if some member of staff works for Engineering, which operates both Computing, and EE, we can't follow a path from the staff member to their department. This can be solved by having the staff work for the department, which is operated by some faculty.
                \medskip

                If we can't follow a path between two entities, we may need to add another relation between them to specify the relationship.
            \subsubsection*{Weak Entities}
                Entities which cannot be uniquely identified by their own attributes are called \textbf{weak} entities, in contrast to \textbf{strong} entities which have primary keys. A weak entity has to be defined by a string entity. Weak entities are drawn as a double rectangle, and the relationship to the strong entity is drawn as a double diamond. The key for a weak entity is formed by combining the primary key of the strong entity with attributes of the weak entity (denoted by a dashed underline). For example, a room in a building is a \textbf{weak} entity, with a room number, and can be uniquely identified with the name of the building combined with the room number.
        \subsection*{ER to RM}
            Keys are used to join information when we do queries. The primary key is the unique identifier of a tuple, and a foreign key is the primary key of \textbf{another} table.
            \medskip

            Once we have an Entity Relationship Model, we can then map it to a relational schema. The schemas can then be refined with functional dependencies, and implemented with relational languages. A high level data model isn't the only concern for database design (considered a simpler aspect).
            \medskip

            If we consider a strong entity set, with simple attributes, we can easily create a table from it (see the example, ~movie~, drawn above).
            \begin{lstlisting}
                -- movie($\ulsmash{~title~}$, $\ulsmash{~year~}$, length, genre)

                CREATE TABLE movie (
                    title VARCHAR(120),
                    year INT,
                    length INT,
                    genre CHAR(20),

                    PRIMARY KEY (title, year)
                )
            \end{lstlisting}
            Composite attributes are also fairly easy to represent, since we just flatten it, therefore store each of the sub-attributes as their own field - consider the actor example (note that if the primary key is composite, we mark all the sub-attributes as primary keys). This example also shows how multi-valued attributes are stored - we create their own relation, and link back to the entity set with a foreign key constraint;
            \begin{lstlisting}
                -- actor($\ulsmash{~name~}$, number, postcode)
                -- actor_phones($\ulsmash{~actorName~}$, $\ulsmash{~phoneID~}$, $\textit{~other attributes~}$)

                CREATE TABLE actor (
                    name VARCHAR(60),
                    number INT,
                    postcode VARCHAR(10),
                    PRIMARY KEY (name)
                )

                CREATE TABLE actor_phones (
                    actorName VARCHAR(60),
                    phoneID VARCHAR(10),
                    ...
                    PRIMARY KEY (actorName, phoneID),
                    FORIEGN KEY (actorName) REFERENCES actor.name
                )
            \end{lstlisting}
            The relational model doesn't allow us to specify derived attributes, and we're therefore expected to calculate them with queries.
            \medskip

            We can also consider how many-to-many relationships can be represented (using the car example again). The first example is when a car can be driven by many people, and a person can drive many cars;
            \begin{lstlisting}
                -- person($\ulsmash{~ID~}$, $\textit{~other attributes~}$)
                -- car($\ulsmash{~regno~}$, $\textit{~other attributes~}$)
                -- drive($\ulsmash{~personID~}$, $\ulsmash{~regno~}$, $\textit{~other attributes~}$)

                CREATE TABLE drive (
                    personID VARCHAR(10),
                    regno VARCHAR(12),
                    ...
                    PRIMARY KEY (personID, regno),
                    FORIEGN KEY (personID) REFERENCES person.ID ON DELETE CASCADE,
                    FORIEGN KEY (regno) REFERENCES car.regno ON DELETE CASCADE
                )
            \end{lstlisting}
            However, it's easier to represent a one-to-many relationship, as we can simply include the primary key of the "one" relation as a foreign key in the many (where a car can be driven by 1 person, and a person can drive many cars). The representation for a one-to-one is similar, but the foreign key can be in either one, which is up to the designer;
            \begin{lstlisting}
                -- person($\ulsmash{~ID~}$, $\textit{~other attributes~}$)
                -- car($\ulsmash{~regno~}$, personID, $\textit{~other attributes~}$)

                CREATE TABLE car (
                    regno VARCHAR(12),
                    personID VARCHAR(10),
                    ...
                    PRIMARY KEY (regno),
                    FORIEGN KEY (personID) REFERENCES person.ID
                )
            \end{lstlisting}
            In a weak entity, we include the primary key of the strong relation as a foreign key, but also use it as part of the composite primary key for the weak entity. A delete cascade is also used, and finally the we use ~not null~ to ensure total participation;
            \begin{lstlisting}
                -- building($\ulsmash{~name~}$, $\textit{~other attributes~}$)
                -- room($\ulsmash{~no~}$, $\ulsmash{~buildingname~}$, $\textit{~other attributes~}$)

                CREATE TABLE room (
                    no VARCHAR(120),
                    buildingname VARCHAR(50) NOT NULL,
                    ...
                    PRIMARY KEY (no, buildingname),
                    FOREIGN KEY (buildingname) REFERENCES building.name ON DELETE CASCADE
                )
            \end{lstlisting}
            A multiway relationship can be mapped as several binary relationships, or we can generalise it to have the primary key consist of the relationship be composed of the primary keys of the many entity sets, and have the primary keys of the one entities be attributes. For roles, we map each role as a foreign key attribute in the entity set;
            \begin{lstlisting}
                -- movie($\ulsmash{~ID~}$, $\textit{~other attributes~}$)
                -- sequelof($\ulsmash{~originalID~}$, $\ulsmash{~sequelID~}$, $\textit{~other attributes~}$)

                CREATE TABLE sequelof (
                    originalID INT,
                    sequelID int,
                    ...
                    PRIMARY KEY (orignalID, sequelID),
                    FOREIGN KEY originalID REFERENCES movie.ID,
                    FOREIGN KEY sequelID REFERENCES movie.ID
                )
            \end{lstlisting}
            \subsubsection*{Extended Models}
                Newer models extend the classic model by supporting features from \textbf{object-oriented design}. We can look at how E-R models handle specialisation, or generalisation with \textbf{is-a hierarchies}. For example, we can specify that a ~cartoon~ \textbf{is-a} ~movie~, which means that it inherits all the attributes of movie, but can have more attributes. and relations. Once this extends on multiple levels, we begin to form a hierarchy.
        \subsection*{Relational Algebra}
            We can use \textbf{relational algebra} to construct new relations from existing ones, the operators include selection, projection, intersection, union, difference, and product. Consider the examples below, ~a~, ~b~, and ~c~ are all integers. Intersection, union, and difference will be omitted, since those are fairly self-explanatory.
            \begin{center}
                \begin{tabular}{|cccccc|ccc|ccc|ccc|}
                    \hline
                    \multicolumn{6}{|c|}{$R$} & \multicolumn{3}{c|}{$\pi_{~a,c,e~}(R)$} & \multicolumn{3}{c|}{$S$} & \multicolumn{3}{c|}{$\sigma_{~a>3|b<5~}(S)$} \\
                    \hline
                    ~a~ & ~b~ & ~c~ & ~d~ & ~e~ & ~f~ & ~a~ & ~c~ & ~e~ & ~a~ & ~b~ & ~c~ & ~a~ & ~b~ & ~c~ \\
                    \hline
                    1 & 2 & 3 & 4 & 5 & 6 & 1 & 3 & 5 & 3 & 2 & 3 & 3 & 2 & 3 \\
                    1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 1 & 7 & 8 & 2 & 2 \\
                    2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 8 & 2 & 2 & & & \\
                    1 & 2 & 3 & 4 & 5 & 8 & & & & 1 & 2 & 9 & & & \\
                    \hline
                \end{tabular}
            \end{center}
            The syntax in use here for projection is $\pi_{~attributes~}(T)$, and likewise for selection it's $\sigma_{~condition~}(T)$. The former returns a relation with only the listed attributes, and the only takes rows which satisfy the given condition. Neither will return duplicate rows. Here is an example of a Cartesian product;
            \begin{center}
                \begin{tabular}{|cc|ccc|ccccc|}
                    \hline
                    \multicolumn{2}{|c|}{$R$} & \multicolumn{3}{c|}{$S$} & \multicolumn{5}{c|}{$R \times S$} \\
                    \hline
                    ~a~ & ~b~ & ~c~ & ~d~ & ~e~ & ~a~ & ~b~ & ~c~ & ~d~ & ~e~ \\
                    \hline
                    1 & 2 & 1 & 2 & 3 & 1 & 2 & 1 & 2 & 3 \\
                    3 & 4 & 4 & 5 & 6 & 1 & 2 & 4 & 5 & 6 \\
                    & & 7 & 8 & 9 & 1 & 2 & 7 & 8 & 9 \\
                    & & & & & 3 & 4 & 1 & 2 & 3 \\
                    & & & & & 3 & 4 & 4 & 5 & 6 \\
                    & & & & & 3 & 4 & 7 & 8 & 9 \\
                    \hline
                \end{tabular}
            \end{center}
            We can take a natural join, where the resulting relation contains all the tuples that have matching attributes in $R$, and $S$. This is less common, and we'd typically use something closer to $R \bowtie_{R.~b~ = S.~b~} S$. Note that in this case, they are the same, since that's the only attribute that overlaps;
            \begin{center}
                \begin{tabular}{|cc|ccc|cccc|}
                    \hline
                    \multicolumn{2}{|c|}{$R$} & \multicolumn{3}{c|}{$S$} & \multicolumn{4}{c|}{$R \bowtie S$} \\
                    \hline
                    ~a~ & ~b~ & ~b~ & ~c~ & ~d~ & ~a~ & ~b~ & ~c~ & ~d~ \\
                    \hline
                    1 & 2 & 1 & 2 & 3 & 1 & 2 & 5 & 6 \\
                    1 & 3 & 2 & 5 & 6 & 3 & 4 & 8 & 9 \\
                    3 & 4 & 4 & 8 & 9 & 3 & 4 & 9 & 9 \\
                    & & 4 & 9 & 9 & & & & \\
                    \hline
                \end{tabular}
            \end{center}
            Attributes can also be renamed with the notation $\rho_{~new/old~, ...}(R)$ notation, which is fairly self-explanatory.
        \subsection*{Functional Dependencies}
            Relational database schemas should be normalised, which helps reduce redundancy, and avoids update, and deletion anomalies. The basis for normalisation is the concept of \textbf{functional dependency}, and \textbf{keys}. Consider the following example, which can experience update anomalies;
            \begin{center}
                \begin{tabular}{|l|l|l|l|l|}
                    \hline
                    producer & city & product no. & price & quantity \\
                    \hline
                    \hline
                    3 & London & 52 & 65 & 4 \\
                    22 & Birmingham & 10 & 15 & 5 \\
                    22 & Birmingham & 12 & 4 & 11 \\
                    3 & London & 44 & 43 & 32 \\
                    3 & London & 43 & 3 & 27 \\
                    \hline
                \end{tabular}
            \end{center}
            If an existing producer changes address, and tuples aren't updated, then it leads to incoherence (as the data would now be invalid). If a new tuple / row is inserted, and the producer already exists, but with an older address, we will once again have incoherence. If a producer doesn't have any open orders, say rows 1, and 5 didn't exist, then data about producer 3 would be lost. The price of the product doesn't depend on the producer, and the location of the producer doesn't have anything to do with the product. There is also redundant data, since the address is duplicated. Ideally, the data should be stored like this;
            \begin{center}
                \begin{minipage}[t]{0.4\textwidth}
                    \begin{tabular}{|l|l|l|}
                        \hline
                        \multicolumn{3}{|l|}{Open Orders} \\
                        \hline
                        producer no. & product no. & quantity \\
                        \hline
                        \hline
                        3 & 52 & 4 \\
                        22 & 10 & 5 \\
                        22 & 12 & 11 \\
                        3 & 44 & 32 \\
                        3 & 43 & 27 \\
                        \hline
                    \end{tabular}
                \end{minipage}
                \begin{minipage}[t]{0.3\textwidth}
                    \begin{tabular}{|l|l|}
                        \hline
                        \multicolumn{2}{|l|}{Producer} \\
                        \hline
                        producer no. & city \\
                        \hline
                        \hline
                        3 & London \\
                        22 & Birmingham \\
                        & \\
                        & \\
                        & \\
                        \hline
                    \end{tabular}
                \end{minipage}
                \begin{minipage}[t]{0.21\textwidth}
                    \begin{tabular}{|l|l|}
                        \hline
                        \multicolumn{2}{|l|}{Product} \\
                        \hline
                        product no. & price \\
                        \hline
                        \hline
                        52 & 65 \\
                        10 & 15 \\
                        12 & 4 \\
                        44 & 43 \\
                        43 & 3 \\
                        \hline
                    \end{tabular}
                \end{minipage}
            \end{center}
            A functional dependency is a constraint that if two tuples of a relation $R$ agree on a set of attributes $A_1, A_2, ..., A_n$, then they must also agree on the set of attributes $B_1, B_2, ..., B_m$. This can be written as $A_1, A_2, ..., A_n \rightarrow B_1, B_2, ..., B_m$, and therefore the $B$ set is functionally dependant on the $A$ set, or the $A$ set functionally determines the $B$ set. Therefore, for any set of values $A$, then there is only one set of values $B$. The normal forms a designer can use are defined in terms of their functional dependencies. This can be summarised by the following examples;
            \begin{center}
                \begin{tabular}{|c|c|c|}
                    \hline
                    functional dependency & for all tuple pairs, $x$, $y$, if & then assert \\
                    \hline
                    $A \rightarrow K$ & $x.A = y.A$ & $x.K = y.K$ \\
                    \hline
                    $A, B \rightarrow K$ & $x.A = y.A$ & $x.K = y.K$ \\
                    & $x.B = y.B$ & \\
                    \hline
                    $A \rightarrow K, L$ & $x.A = y.A$ & $x.K = y.K$ \\
                    & & $x.L = y.L$ \\
                    \hline
                    $A, B \rightarrow K, L$ & $x.A = y.A$ & $x.K = y.K$ \\
                    & $x.B = y.B$ & $x.L = y.L$ \\
                    \hline
                \end{tabular}
            \end{center}
            Note that if we have two functional dependencies, $A, B \rightarrow K$, and $A, B \rightarrow L$, it's trivial to combine them as $A, B \rightarrow K, L$ (or to split them). If we have the functional dependency $A, B, C, D, E \rightarrow A, C, X, Y, Z$, we can remove all the attributes on the right hand side, that are on the left hand side, such that the aforementioned FD reduces to $A, B, C, D, E \rightarrow X, Y, Z$. A \textbf{trivial} FD is one where all the attributes on the RHS are on the LHS.
            \subsubsection*{Keys}
                If we have some set of attributes $A_1, A_2, ..., A_n$, functionally determine all the remaining attributes of the relation, then the set $A$ is a \textbf{superkey}. This also implies that two tuples cannot have the same superkey values, due to the uniqueness property. Let there be a set of all attributes in the relation, $K$, and the superkey set $S$. Therefore we can state $S \rightarrow \{ x \in K\ |\ x \notin S \}$. A single relation may have more than one superkey, and superkeys can contain attributes that aren't strictly required. Generally, we are interested in superkeys where there isn't a subset of the superkey (hence the smallest superkey, by the irreducibility property), and this minimal superkey is referred to as the \textbf{candidate key}. If we have more than one candidate key, we can choose one of them to act as the primary key. A candidate key is also often referred to as just a \textbf{key}.
            \subsubsection*{Closure}
                The set of all attributes functionally determined by a set $L$, under a set of dependencies $F$, the closure of $L$, denoted as $L^+$. If $L^+$ contains all the attributes of $R$, then it follows that $L$ is a superkey of $R$. If $\text{RHS} \subseteq \text{LHS}^+$, then $\text{LHS} \rightarrow \text{RHS}$ holds.
                \medskip

                In order to compute the closure of a set of attributes, $L$, under a set of FDs given in the form $\text{LHS} \rightarrow \text{RHS}$, we keep adding all the LHSs which exist as a subset of $L$, and add the RHS to $L$. We repeat this until we can no longer add anymore RHSs. The final value is referred to as $L^+$. Given the starting value of $L = \{A, B\}$, and the following FD set;
                \begin{enumerate}[(1)]
                    \itemsep0em
                    \item $A, B \rightarrow C$
                    \item $B, C \rightarrow A, D$
                    \item $D \rightarrow E$
                    \item $C, F \rightarrow B$
                \end{enumerate}
                Starting with (1), both $A$, and $B$ are in $L$, so we can add $C$. Now that $C$ is in $L$, and $B$ was already there, we can add $D$ (no need to add $A$) from (2). Since we have $D$ in $L$, we can add $E$. There is nothing else we can do, since $F$ is not in $L$. Hence the value of $L^+ = \{A, B, C, D, E\}$.
            \subsubsection*{Armstrong's Axioms}
                This is a sound (doesn't generate incorrect FDs), and compete (allows us to derive all valid FDs) axiomisation of FDs. Given attributes $A, B, C, ...$, and sets of attributes $\alpha, \beta, \gamma$, we have the following axioms;
                \begin{itemize}
                    \itemsep0em
                    \item reflexivity (trivial FDs) \hfill $\alpha \rightarrow \beta$ always holds if $\beta \subseteq \alpha$
                    \item augmentation \hfill if $\alpha \rightarrow \beta$, then it follows $\alpha \gamma \rightarrow \beta \gamma$
                    \item transitivity \hfill if $\alpha \rightarrow \beta$, and $\beta \rightarrow \gamma$, then $\alpha \rightarrow \gamma$
                    \item (derived) union \hfill if $\alpha \rightarrow \beta$, and $\alpha \rightarrow \gamma$, then $\alpha \rightarrow \beta \gamma$
                    \item (derived) decomposition \hfill if $\alpha \rightarrow \beta \gamma$, then $\alpha \rightarrow \beta$, and $\alpha \rightarrow \gamma$
                    \item (derived) pseudotransitivity \hfill if $\alpha \rightarrow \beta$, and $\delta \beta \rightarrow \gamma$, then $\delta \alpha \rightarrow \gamma$
                \end{itemize}
            \subsubsection*{Closure, and Covers}
                Similar to attributes, we can find the closure of a FD set, which is the set of all FDs that can be inferred, denoted as $F^+$. This can be approached by applying Armstrong's axioms. We start by initialising $F^+$ to the set $F$. By applying reflexivity, and augmentation, we can add new FDs to $F^+$. Transitivity can then be applied to suitable FDs, and adding the derived ones to $F^+$. This is repeated until no more changes occur.
                \medskip

                We can say two FD sets $F_1$, and $F_2$ are equivalent if they each imply the other - if any relation instance satisfying $F_1$ also satisfies $F_2$, they are said to be covers of each other. A cover is canonical / minimal / irreducible if each LHS is unique, and no FD can be deleted from the cover, and still maintain an equivalent FD set. Additionally, no attributes can be deleted from any FD set, and still have an equivalent set. Therefore, the canonical cover has no redundant dependencies, nor attributes.
                \medskip

                The method for testing whether some attribute, $X$, is extraneous depends on whether it's on the LHS, or RHS. For an attribute $X$ on the LHS, we can say $X$ is extraneous if $\text{RHS} \subseteq \{\text{LHS} - X\}^+$ under the FD set - note that here we are referring to closure on attributes, not FDs. On the other hand (no pun intended, I'm so depressed), an attribute $X$ on the RHS is extraneous if $X \in \text{LHS}^+$ under the FD set, where $X$ is removed from the RHS of all the FDs in the set.
                \medskip

                To compute a canonical cover $F$ for an FD set, we can use the following algorithm;
                \begin{lstlisting}
                    let $F$ := FD set
                    do
                        replace dependencies of $\alpha \rightarrow \beta$ and $\alpha \rightarrow \gamma$, with $\alpha \rightarrow \beta \gamma$
                        remove all extraneous attributes one at a time
                    until $F$ doesn't change
                \end{lstlisting}
        \subsection*{Normalisation}
            As previously mentioned, in the previous section, normalisation reduces data duplication, and anomalies. One of the approaches taken to develop a normalised schema is to start with a few big relations, and then decompose them into a suitable normal form. The ones we'll look at are \textbf{Boyce-Codd Normal Form (BCNF)}, and \textbf{Third Normal Form (3NF)}. Consider the following example, which is just a "big" relation;
            \begin{center}
                \begin{tabular}{|c|c|c|c|c|c|}
                    \hline
                    ~title~ & ~year~ & ~length~ & ~genre~ & ~studio~ & ~actor~ \\
                    \hline
                    \hline
                    Star Wars & 1977 & 124 & Science Fiction & Fox & Carrie Fisher \\
                    \hline
                    Star Wars & 1977 & 124 & Science Fiction & Fox & Mark Hamill \\
                    \hline
                    Star Wars & 1977 & 124 & Science Fiction & Fox & Harrison Ford \\
                    \hline
                    Gone with the Wind & 1939 & 231 & Drama & MGM & Vivien Leigh \\
                    \hline
                    Wayne's World & 1992 & 95 & Comedy & Paramount & Dana Carvey \\
                    \hline
                    Wayne's World & 1992 & 95 & Comedy & Paramount & Mile Myers \\
                    \hline
                \end{tabular}
            \end{center}
            You'll notice straight away that there is a huge amount of redundant, repeated data, which is present in multiple rows. Updating the ~length~ of Star Wars would require 3 updates (for the relation to remain consistent), which is error prone. Inserting a new actor for a movie would require duplicating a fair bit of data, and would require checks to maintain consistency. Finally, deleting Vivien Leigh would delete the entire row, which deletes information about the movie.
            \subsubsection*{Decomposition}
                Given a relation $R(A_1, A_2, ..., A_n)$, we can decompose it into two projected relations $S$, and $T$, such that $\text{attr}(R) = \text{attr}(S) \cup \text{attr}(T)$. This also means that $S = \pi_{\text{attr}(S)}(R)$, and similar for $T$.
                \medskip

                When we decompose a relation, it's crucial for us to ensure we can recover the original relation by joining the decomposed relations, and also preserve the FDs of the original relation. Note that the latter isn't always possible with BCNF.
                \medskip

                Given $R$ decomposed into $S$, and $T$, the decomposition is \textbf{lossless} if at least one of the following FDs hold in the closure of FD set of $R$;
                \begin{itemize}
                    \itemsep0em
                    \item $\text{attr}(S) \cap \text{attr}(T) \rightarrow \text{attr}(S)$
                    \item $\text{attr}(S) \cap \text{attr}(T) \rightarrow \text{attr}(T)$
                    \item this means the common attributes of $S$, and $T$ form a superkey of either of the decomposed relations
                \end{itemize}
                If we're able to check the FDs of $R$ without joining the decomposed sets, then the decomposition is \textbf{dependency preserving}.
                \medskip

                Consider the following example, on $R(A, B, C)$, with the FD set $\{A \rightarrow B, B \rightarrow C\}$;
                \begin{center}
                    \vspace{-\baselineskip}
                    \begin{tabularx}{\textwidth}{|l|l|X|}
                        \hline
                        decomposition & lossless? & dependency preserving? \\
                        \hline
                        $S(A, B)$ & $B \rightarrow A, B$ doesn't hold & yes, $A \rightarrow B$ is checked with $S$, and $B \rightarrow C$ with $T$ \\
                        $T(B, C)$ & $B \rightarrow B, C$ holds $\therefore$ lossless & \\
                        \hline
                        $S(A, B)$ & $A \rightarrow A, B$ holds $\therefore$ lossless & no, $B \rightarrow C$ cannot be checked without joining \\
                        $T(A, C)$ & $A \rightarrow A, C$ holds also & \\
                        \hline
                    \end{tabularx}
                    \vspace{-2\baselineskip}
                \end{center}
            \subsubsection*{Boyce-Codd Normal Form}
                \textbf{A relation $R$ is in BCNF, if and only if, for all non-trivial FDs (including derived FDs) of the relation, the LHS of every FD is a superkey (i.e. contains a key)}
                \bigskip

                For example, if we have the FD $~title~, ~year~ \rightarrow ~length~, ~genre~, ~studio~$, it's not in BCNF, as ~title~, ~year~ doesn't functionally determine ~actor~.
                \medskip

                In order to convert something into BCNF, we first initialise a set of relations with just $R$. While the set contains relations that violate the rules of BCNF, take one of them, let it be $V$. Let us take some non-trivial FD for $V$, of the form $\text{LHS} \rightarrow \text{RHS}$; fulfilling the conditions $\text{LHS} \cap \text{RHS} = \emptyset$ (therefore we may need to check a derived FD for decomposed relations), and $\text{LHS} \rightarrow \text{attr}(V)$ does not hold for the FD$^+$ of $R$ (therefore, LHS is not a superkey of $R$). Now remove $V$ from the set of relations. Add a new relation $R_k(\text{LHS} \cup \text{RHS})$, and another relation $R_l(\text{attr}(V) - \text{RHS})$ to the set of decompositions. This process is then recursively applied to the child relations. Consider the following example;
                \medskip

                $R(A, B, C, D, E, F, G, H, I, J, K)$, and the following FDs;
                \begin{itemize}
                    \itemsep0em
                    \item $A \rightarrow B, C, D$
                    \item $H, I \rightarrow J$
                    \item $A, E, F, G \rightarrow H, I, K$
                \end{itemize}
                \begin{center}
                    \begin{tikzpicture}
                        \node[draw] (o) at (0, 0) {$R(A, B, C, D, E, F, G, H, I, J, K)$};
                        \node[draw] (ol) at (-3, -1.75) {$R_1(A, B, C, D)$};
                        \node[draw] (or) at (3, -1.75) {$R_2(A, E, F, G, H, I, J, K)$};
                        \node[draw] (orl) at (1, -3.5) {$R_{2A}(H, I, J)$};
                        \node[draw] (orr) at (5, -3.5) {$R_{2B}(A, E, F, G, H, I, K)$};
                        \draw
                        (o) edge[->, left] node{$A \rightarrow B, C, D\ $} (ol)
                        (o) edge[->] (or)
                        (or) edge[->, left] node{$H, I \rightarrow J\ $} (orl)
                        (or) edge[->] (orr);
                    \end{tikzpicture}
                \end{center}
                Honestly, just practice this.
            \subsubsection*{Recovering Data}
                When we decompose into BCNF, it's crucial that we're able to recover the original relation by joining the decomposed ones. As long as the FDs hold for the original relation, it will always be possible. However; if the FDs don't hold, we'd end up with false data; as the join would generate tuples that don't exist in the original relation.
            \subsubsection*{Dependency Preservation}
                As previosuly mentioned, we know that BCNF doesn't always preserve dependencies, which can be shown here. Let there be a relation $R(A, B, C)$, and the FD set; $\{\{A, B\} \rightarrow C, C \rightarrow B\}$. We wouldn't be able to check $A, B \rightarrow C$ without the RDBMS joining the relations.
                \begin{center}
                    \begin{tikzpicture}
                        \node[draw] (o) at (0, 0) {$R(A, B, C)$};
                        \node[draw] (ol) at (-2, -1.75) {$R_1(B, C)$};
                        \node[draw] (or) at (2, -1.75) {$R_2(A, C)$};
                        \draw
                        (o) edge[->, left] node{$C \rightarrow B\ $} (ol)
                        (o) edge[->] (or);
                    \end{tikzpicture}
                \end{center}
            \subsubsection*{Third Normal Form}
                \textbf{A relation $R$ is in 3NF, if and only if, the LHS of every nontrivial FD is a superkey (same as BCNF test), or if every attribute on the RHS of a FD is prime (if it is a member of any key of the relation)}
                \bigskip

                When a BCNF decomposition doesn't preserve the original FDs, we can either "live with" the violating dependencies, or use a weaker normal form which preserves FDs, but has redundancy. With \textbf{3NF}, there always exists a dependency preserving, lossless decomposition.
                \medskip

                In order to decompose a relation $R$, and a set of FDs $F$ for $R$, we can generate a set of decomposed relations $D$. We first need to find $C$, a canonical cover for $F$, such that it's a minimal FD set for $R$. Initialise $D$ to be $\emptyset$. For every canonical FD, in the form $\text{LHS} \rightarrow \text{RHS}$, we add a new relation $(\text{LHS} \cup \text{RHS})$ to $D$. Now, for every relation in $D$, if it is a subset of another relation in $D$, we remove it. Finally, if none of the relations in $D$ include a key for $R$, we add a new relation to $D$, which contains a key.
                \medskip

                Consider the following relation $R(A, B, C, D, E, F, G, H, I)$, a set of keys $\{\{A, B\}, \{A, D\}, \{B, D\}\}$ with the following FD set (and its canonical cover on the right);
                \begin{itemize}
                    \itemsep0em
                    \item $A, B \rightarrow D, E$ \hfill $A, B \rightarrow D$
                    \item $A \rightarrow I$ \hfill $A \rightarrow I$
                    \item $B \rightarrow C, F, G, H$ \hfill $B \rightarrow C, F, G$
                    \item $G \rightarrow H$ \hfill $G \rightarrow H$
                    \item $A, D \rightarrow B, C, E, F, G, H$ \hfill $A, D \rightarrow B$
                    \item $B, D \rightarrow A, I, E$ \hfill $B, D \rightarrow A, E$
                \end{itemize}
                \begin{center}
                    \begin{tikzpicture}
                        \node[draw] (r) at (0, 0) {$R(A, B, C, D, E, F, G, H, I)$};
                        \node[draw] (r1) at (-6, -1.75) {$R_1(A, B, D)$};
                        \node[draw] (r2) at (-3, -1.75) {$R_2(A, I)$};
                        \node[draw] (r3) at (0, -1.75) {$R_3(B, C, F, G)$};
                        \node[draw] (r4) at (3, -1.75) {$R_4(G, H)$};
                        \node[draw] (r5) at (6, -1.75) {$R_5(A, B, D, E)$};
                        \node[] () at (-6, -2.5) {dropped, as $R_1 \subseteq R_5$};
                        \draw
                        (r) edge[->] (r1)
                        (r) edge[->] (r2)
                        (r) edge[->] (r3)
                        (r) edge[->] (r4)
                        (r) edge[->] (r5);
                    \end{tikzpicture}
                \end{center}
        \subsection*{SQL}
            \textbf{Structured Query Language} is the most common language for relational databases, with use in more than 99\% of applications. It supports schema creation, modification, data insertion, retrieval, updates, deletion, and a lot more. Translating from the relational algebra we previously done, to SQL, can be done with the table below;
            \begin{center}
                \begin{tabularx}{\textwidth}{|c|c|X|}
                    \hline
                    relational algebra & SQL & comments\\
                    \hline
                    \hline
                    $R \cup S$ & $R ~ UNION ~ S$ & \\
                    $R \cap S$ & $R ~ INTERSECT ~ S$ & \\
                    $R - S$ & $R ~ EXCEPT ~ S$ & \\
                    $\pi_~attributes~(R)$ & $~SELECT attributes FROM ~ R$ & \\
                    $\sigma_~condition~(R)$ & $~FROM ~ R ~ WHERE condition~$ & \\
                    $R \times S$ & $R, S$ or $R ~ CROSS JOIN ~ S$ & \\
                    $R \bowtie S$ & $R ~ NATURAL JOIN ~ S$ & \\
                    $R \bowtie_~condition~ S$ & $R ~ JOIN ~ S ~  ON condition~$ & \\
                    relation & table & persistent relations stored on disk \\
                    relational expression & views & based on other relations, not normally stored \\
                    tuple & row & also called a record \\
                    attribute & column & also called a field \\
                    domain & type & includes ~char~, ~int~, ~float~, ~date~, ~time~, etc. \\
                    \hline
                \end{tabularx}
                \vspace{-2\baselineskip}
            \end{center}
            However, SQL differs from the theory we've studied so far, as it is based on multi-sets, and therefore can contain duplicate rows / tuples. It's still best practice to avoid them. Not all attributes need to be filled in, and therefore can be left ~null~, once again this should be avoided; because of this, booleans are three-valued (true, false, and unknown). Most implementations have a wide range of types, and therefore numbers have multiple types - arithmetic opertors are usually available. Strings can either be a fixed length, and padded with spaces, or varying length. The concatenation operator used in SQL is ~||~, and we can use pattern matching, with ~\_~ denoting any character, and ~\%~ matching zero, or more characters. We can store bits, bytes, and large binary objects (blobs) to hold images, movies, and other files.
            \medskip

            With booleans, we have additional comparison operators such as ~BETWEEN~, ~NOT BETWEEN~, ~IN~, and ~NOT IN~, all of which should be fairly self-explanatory. The truth values for 3VL (three valued logic) can be computed with the following mapping;
            \begin{itemize}
                \itemsep0em
                \item 1 - true
                \item $\frac{1}{2}$ - unknown
                \item 0 - false
                \item $x$ ~AND~ $y$ = min($x, y$)
                \item $x$ ~OR~ $y$ = max($x, y$)
                \item ~NOT~ $x$ = $1 - x$
            \end{itemize}
            \medskip

            It's also important to remember that any arithmetic which uses a ~null~, will result in ~null~. Any comparisons that use ~null~ will result in unknown.
            \subsubsection*{Queries}
                In order to save space, all comments will be done inline, in the SQL code listing below;
                \begin{lstlisting}
                    -- movie(title, year, length, genre, studio, producer)
                    -- casting(title, year, name)

                    -- note that the results of a selection is still a relation, and therefore we can use it as a subquery in other expressions
                    SELECT title, length/60 AS hours -- projected attributes (and a rename)
                    FROM movie -- the relation
                    WHERE studio='fox' AND year > 1990 -- the condition
                    ORDER BY year DESC, title ASC -- sorts first by year
                    -- note that we're using attributes which aren't in the projection, the order of operations is FROM, WHERE, ORDER, SELECT
                    -- note that we can also prefix the fields, to make it more readable
                \end{lstlisting}
                In order to join two relations, we can use a ~JOIN~;
                \begin{lstlisting}
                    SELECT title, year, name
                    FROM movie JOIN casting ON (movie.producer=casting.name)
                    -- we can do a theta join with an ON, and a condition

                    SELECT title
                    FROM movie JOIN casting USING (title, year)
                    -- note that this is the same as ON (movie.title=casting.title AND movie.year=casting.year)

                    SELECT c1.name, c2.name
                    FROM casting AS c1 JOIN casting c2 -- note how we can omit AS for redability
                    ON c1.address = c2.address AND
                       c1.name < c2.name
                    -- we can do a self join, but we have to name the relation, these are called correlation names
                \end{lstlisting}
                We can also consider the different types of joins, either natural (by mathcing attributes), or theta (by condition);
                \begin{itemize}
                    \itemsep0em
                    \item inner join \hfill returns tuples when there is at least one match in both sides
                    \item left outer join (~LOJ~) \hfill similar to inner join, but will include all tuples from the left relation
                    \item right outer join (~ROJ~) \hfill similar to inner, but includes all tuples from the right relation
                    \item full outer join (~FOJ~) \hfill similar to inner, but includes all unmatched tuples
                \end{itemize}
                \begin{center}
                    \begin{tabular}{|c|c|c||c|c|c||c|c|c|c||c|c|c|c||c|c|c|c|}
                        \hline
                        \multicolumn{3}{|c||}{$L$} & \multicolumn{3}{c||}{$R$} & \multicolumn{4}{c||}{$L$ ~LOJ~ $R$} & \multicolumn{4}{c||}{$L$ ~ROJ~ $R$} & \multicolumn{4}{c|}{$L$ ~FOJ~ $R$} \\
                        \hline
                        ~a~ & ~b~ & ~c~ & ~a~ & ~b~ & ~c~ & ~a~ & ~b~ & ~c~ & ~d~ & ~a~ & ~b~ & ~c~ & ~d~ & ~a~ & ~b~ & ~c~ & ~d~ \\
                        \hline
                        \hline
                        1 & 2 & 3 & 2 & 3 & A & 1 & 2 & 3 & A & 1 & 2 & 3 & A & 1 & 2 & 3 & A \\
                        \hline
                        4 & 5 & 6 & 2 & 3 & B & 1 & 2 & 3 & B & 1 & 2 & 3 & B & 1 & 2 & 3 & B \\
                        \hline
                        7 & 8 & 9 & 6 & 8 & C & 4 & 5 & 6 & N & N & 6 & 8 & C & 4 & 5 & 6 & N \\
                        \hline
                        & & & & & & 7 & 8 & 9 & N & & & & & 7 & 8 & 9 & N \\
                        \hline
                        & & & & & & & & & & & & & & N & 6 & 8 & C \\
                        \hline
                    \end{tabular}
                \end{center}
                \begin{lstlisting}
                    SELECT DISTINCT title, year, name -- selects only unique tuples
                    FROM movie LEFT OUTER JOIN casting ON
                        movie.producer=casting.name AND movie.year=casting.year
                \end{lstlisting}
                We also have a set of aggregation functions, which can be used to calculate a single value, for example;
                \begin{lstlisting}
                    SELECT department
                           COUNT(*) as professors,
                           SUM(salary) as totalsalary,
                           AVG(salary) as averagesalary,
                           MIN(age) as youngest,
                           MAX(age) as oldest
                    FROM employee
                    WHERE position='Professor'
                    GROUP BY department
                    HAVING COUNT(*) >= 10
                    ORDER BY totalsalary DESC
                \end{lstlisting}
                This creates a tuple for each department; the results are then sorted in descending order by total salary. Any non-aggregates used in the projection, or the ~HAVING~ filter \textbf{must} be included in the ~GROUP BY~ list. Only departments with at least 10 professors are listed.
            \subsubsection*{Subqueries}
                A powerful feature of ~SELECT~s is that we can also use them as subqueries in expresisons, by wrapping them in brackets. The types supported by SQL are;
                \begin{itemize}
                    \itemsep0em
                    \item scalar subquery
                        \subitem a subquery that produces a single value, normally uses an aggregate function
                        \begin{lstlisting}
                            SELECT title,
                                (SELECT count(name)
                                 FROM casting
                                 WHERE casting.title=movie.title) AS numactors
                            FROM movie
                            -- note how the outer query is related to the subquery; this is an example of a correlated subquery that has to be evaulated for each outer tuple

                            SELECT title, count(name) as numactors
                            FROM movie JOIN casting USING (title)
                            GROUP BY title
                            -- this is equivalent, and is clearer
                        \end{lstlisting}
                    \item set subquery
                        \subitem creates a set of distinct values (a single column), typically used for set membership with ~(NOT) IN~, or set comparisons with ~ALL~ or ~SOME~
                        \begin{lstlisting}
                            SELECT title
                            FROM movie
                            WHERE studio IN (SELECT name
                                             FROM studio
                                             WHERE address LIKE 'C%')
                            SELECT name
                            FROM casting
                            WHERE (title, year) NOT IN (SELECT title, year
                                                        FROM movie
                                                        WHERE genre='sf')
                            -- note how we're able to match on tuple values
                            SELECT title
                            FROM movie m1
                            WHERE year < SOME(SELECT year
                                              FROM movie m2
                                              WHERE m2.title=m1.title)
                            -- the keywords ALL, and SOME can be used with any comparator

                            SELECT name
                            FROM employee
                            WHERE salary <> ALL(SELECT salary
                                                FROM employee
                                                WHERE position='Professor'
                        \end{lstlisting}
                    \item relation subquery
                        \subitem produces a relation, which is typically used as an operand, used with operators ~(NOT) EXISTS~ to check if it's empty, or operators ~(NOT) UNIQUE~ to test for duplicate tuples
                        \begin{lstlisting}
                            SELECT title
                            FROM movie m1
                            WHERE NOT EXISTS(SELECT *
                                             FROM movie m2
                                             WHERE m2.title=m1.title AND m1.year<>m2.year)
                        \end{lstlisting}
                \end{itemize}
        \subsection*{SQL Data Definition}
            SQL's DDL is concerned with schema creation, as well as the specification of any constraints. This course mainly focuses on base relations (which are stored tables), and lightly touches on derived relations (views). The constraints we deal with in SQL include type, primary / foreign key constraints, uniqueness, checking a value exists (not null), check constraints, as well as assertions.
            \subsubsection*{Creating a Relation}
                Given some relation ~movie(\ulsmash{title}, \ulsmash{year}, length, genre, ISAN)~, the following SQL instruction will create the table;
                \begin{lstlisting}
                    CREATE TABLE movie (
                        title VARCHAR(120),
                        year INT DEFAULT 2011,
                        length INT NOT NULL DEFAULT 0,
                        genre CHAR(20) NOT NULL,
                        ISAN CHAR(24) NOT NULL,
                        PRIMARY KEY (title, year),
                        UNIQUE (ISAN)
                    )
                    -- this table can be deleted with 'DROP TABLE movie'
                    -- please sanitise your inputs (https://xkcd.com/327/)
                \end{lstlisting}
                We can then modify the schema, with the ~ALTER TABLE~ command, for example (leads to the modified schema ~movie(\ulsmash{title}, \ulsmash{year}, genre, studio, ISAN)~);
                \begin{lstlisting}
                    ALTER TABLE movie ADD studio CHAR(16) DEFAULT '';
                    ALTER TABLE movie DROP length;
                \end{lstlisting}
                Note that we've also assigned a value that is unique, hence no other tuple can have the same ~ISAN~ value (if a command were to attempt to violate this constraint, such as via ~UPDATE~, or ~INSERT~, it would fail). Adding a constraint to prevent the assignment of nulls is also shown above.
            \subsubsection*{Primary Key}
                Each relation should be given a primary (candidate) key, which determines the other attributes, and uniquely identifies each tuple. This is also used to enforce foreign key constraints. The constraints on a primary key are as follows; the ~NULL~ is not permitted in a primary key, and the whole primary key (in the case of composite keys) has to be unique to the tuple. For example, the following would fail, since we haven't given a value to year (hence it's ~NULL~);
                \begin{lstlisting}
                    INSERT INTO movie (title, genre) VALUES ('Up', 'cartoon');
                \end{lstlisting}
            \subsubsection*{Check Constraints}
                In order to prevent the repetition of code, I'll simply leave ~...~ where the original code (from the first declaration of the table) is. While giving types to the attributes, and ensuring that they aren't nulls allow us to limit the values we store, we need ~CHECK~ constraints to define predicates that must be satisfied on the insertion, or update of a tuple. While the first two are probably the most common types of check (where it's a simple expression on a single attribute), we can have arbitrary expressions that may involve other queries;
                \begin{lstlisting}
                    CREATE TABLE MOVIE (
                        ...
                        CHECK (year BETWEEN 1900 AND 2020),
                        CHECK (genre IN ('sf', 'comedy', 'drama', 'western')),
                        CONSTRAINT validISAN CHECK (ISAN in (SELECT no FROM ISANcatalog))
                    )

                    CREATE ASSERTION nopoorbosses CHECK (
                        NOT EXISTS (
                            SELECT s.name
                            FROM studio s JOIN movieboss m ON (s.boss=m.name)
                            WHERE m.networth < 314159265 -- some large number
                        )
                    )
                \end{lstlisting}
                You'll note that we can also name our constraints, which not only allows us to modify them with ~ALTER TABLE~, but also clarfifies errors when they are violated. There's also an assertion, but they are difficult to efficiently implement, despite being a powerful feature.
            \subsubsection*{Foreign Key Constraints}
                One method of ensuring referntial integrity is to apply constraints on foreign keys, which specify that the value of some set of attributes in a table must reference (match) primary key values of another relation, in this case, we're dealing with the schema ~casting(title, year, name)~;
                \begin{lstlisting}
                    ...

                    CREATE TABLE casting (
                        title VARCHAR(120),
                        year INT,
                        name VARCHAR(60),
                        FOREIGN KEY (title, year) REFERENCES movie (title, year) ON UPDATE CASCADE ON DELETE CASCADE
                    )
                \end{lstlisting}
                Another important factor in maintaining referential integrity is to cascade updates, whether it being a field update, or a deletion. Any update to the referenced attribute will cascade down to the foriegn key. If the referenced tuple (a ~movie~ in this case) is deleted, then the entry referencing tuple is also deleted (a ~casting~ here). Instead of cascading updates, or deletions, we can set use other policies to update the referencing tuple (although this will lead to unmatched tuples). In our case, if the referenced tuple is deleted, the referencing fields are set to null, and if it's updated, then the fields are set to the default values;
                \begin{lstlisting}
                    CREATE TABLE casting (
                        title VARCHAR(120) DEFAULT '',
                        year INT DEFAULT 2011,
                        name VARCHAR(60),
                        FOREIGN KEY (title, year) REFERENCES movie (title, year) ON UPDATE SET DEFAULT ON DELETE SET NULL
                    )
                \end{lstlisting}
            \subsubsection*{Views}
                Views are temporary relations that can be defined with a query. For example, given the same schemas previously used, this can then be queried as if it were a stored relation;
                \begin{lstlisting}
                    CREATE VIEW comedies AS
                    SELECT title, year
                    FROM movie
                    WHERE genre='comedy';

                    CREATE VIEW actorGenre(actorname, moviegenre) AS
                    SELECT DISTINCT name, genre
                    FROM movie JOIN CASTING USING (title, year);

                    SELECT * FROM comedies WHERE year=2010;
                \end{lstlisting}
            \subsubsection*{Indexing}
                If we were to have a large database of movies, it could be quite slow to check. As such, we can make copies, which are automatically updated by the RDBMS. Once again, it leads to a trade-off between space and time.
                \begin{lstlisting}
                    CREATE INDEX yearindex ON movies (YEAR);
                \end{lstlisting}
        \subsection*{Data Manipulation, and Advanced SQL}
            \subsubsection*{Insertion}
                When we run a query to insert items into a table, missing values are set to ~NULL~ (unless the schema doesn't allow that), or are set to a default value (if one is specified). If it fails any constraints, such as uniqueness, then an error is given, and the tuple is not added to the table, and any associated transaction is rolledback. We're also able to insert values using a subquery, for example, the second command adds studios which are present in the movie relation (which aren't present in the studios relation) to the studio relation. An insertion subquery will be fully evaluated before the insertion occurs to prevent any anomalies.
                \begin{lstlisting}
                    INSERT INTO movie (title, year, genre)
                    VALUES ('True Grit', 2010, 'Western'),
                        ('The Kings Speech', 2010, 'Drama')

                    INSERT INTO studio (name)
                    SELECT DISTINCT studio FROM movies m
                    WHERE m.studio NOT IN (SELECT s.name FROM studio s)
                \end{lstlisting}
            \subsubsection*{Deletion}
                We're also able to delete from a relation. It's extremely important to state a ~condition~, otherwise the entire relation will be cleared.
                \begin{lstlisting}
                    DELETE FROM movie
                    WHERE length > 180 OR
                          (title, year) IN (SELECT title, year
                                            FROM casting
                                            WHERE name='Keanu Reeves')
                \end{lstlisting}
            \subsubsection*{Updating}
                We're able to update tuples that satisfy a condition as follows. Similar to insertion, the transaction is aborted if it violates any constraints;
                \begin{lstlisting}
                    UPDATE employee
                    SET salary = CASE
                        WHEN salary <= 70000 THEN salary * 1.02
                        WHEN salary <= 80000 THEN salary * 1.03
                        ELSE salary * 1.04
                        END,
                        lastpayincrease = current_date
                    WHERE position='Professor'
                \end{lstlisting}
            \subsubsection*{Advanced Operations}
                This was its own set of slides, but it's actually not that long, so it's just a list now.
                \begin{itemize}
                    \itemsep0em
                    \item ~LIMIT~ clause \hfill used to specify (limit) the number of records to return
                        \begin{lstlisting}
                            SELECT columns
                            FROM table
                            LIMIT number;

                            SELECT * FROM persons LIMIT 2; -- only gets the first two rows
                        \end{lstlisting}
                    \item ~LIKE~ operator \hfill used in a ~WHERE~ clause to serarch for specific patterns in a column
                        \begin{lstlisting}
                            SELECT columns
                            FROM table
                            WHERE column LIKE pattern;

                            SELECT * FROM persons WHERE city LIKE 'S%'; -- only gets people from cities starting in 'S'
                            -- % is used to substitute zero, or more characters
                            -- _ is used to substitute exactly one character
                        \end{lstlisting}
                    \item ~AUTO\_INCREMENT~ \hfill allows a unique number to be generated when new records are added
                        \begin{lstlisting}
                            CREATE TABLE persons (
                                p_id INT NOT NULL AUTO_INCREMENT,
                                lastName VARCHAR(255) NOT NULL,
                                firstName VARCHAR(255),
                                address VARCHAR(255),
                                city VARCHAR(255),
                                PRIMARY KEY (P_Id)
                            )
                        \end{lstlisting}
                \end{itemize}
        \subsection*{Transactions}
\end{document}