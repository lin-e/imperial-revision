\documentclass[a4paper, 12pt]{article}
% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{lstautogobble}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\displaystyle{\lim_{#1 \to #2}}}
\newcommand{\summation}[3]{\sum\limits_{#1}^{#2} #3}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}

\newcommand{\unaryproof}[2]{\AxiomC{#1} \UnaryInfC{#2} \DisplayProof}
\newcommand{\binaryproof}[3]{\AxiomC{#1} \AxiomC{#2} \BinaryInfC{#3} \DisplayProof}
\newcommand{\trinaryproof}[4]{\AxiomC{#1} \AxiomC{#2} \AxiomC{#3} \TrinaryInfC{#4} \DisplayProof}

% no indent
\setlength\parindent{0pt}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofeq}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% actual document
\begin{document}
    \section*{CO141 - Reasoning About Programs}
        \subsection*{Prelude}
            The content discussed here is part of CO141 - Reasoning About Programs (Computing MEng); taught by Sophia Drossopoulou, and Mark Wheelhouse, in Imperial College London during the academic year 2018/19. The notes are written for my personal use, and have no guarantee of being correct (although I hope it is, for my own sake). This should be used in conjunction with the (extremely detailed) notes.
        \subsection*{Material Order}
            These notes are primarily based off the notes on CATe, as they cover the lecture slides in great detail. This is the order in which they are uploaded (and I'd assume the order in which they are taught).
            \begin{enumerate}[1.]
                \itemsep0em
                \item \textit{Introduction and Motivation (full notes).pdf}
                \item \textit{Stylised Proofs (full notes).pdf}
                \item \textit{Induction over natural numbers (full notes).pdf}
                \item \textit{Induction over Haskell data structures (full notes).pdf}
                \item \textit{Induction over recursive relations and functions (full notes).pdf}
                \item \textit{Java - Program Specifications (full notes).pdf}
                \item \textit{Java - Conditional Branches (full notes).pdf}
                \item \textit{Java - Method Calls (full notes).pdf}
                \item \textit{Java - Recursion (full notes).pdf}
                \item \textit{Java - Iteration Informal (full notes).pdf}
                \item \textit{Java Reasoning - summary.pdf}
                \item \textit{Loop case study.pdf}
                \item \textit{Java - Iteration Formal (full notes).pdf}
                \item \textit{Case Studies - overview (full notes).pdf}
                \item \textit{Case Studies - Dutch Flag Problem (full notes).pdf}
                \item \textit{Quicksort (full notes).pdf}
            \end{enumerate}
        \subsection*{Introduction}
            This module will cover Proof by Induction from first principles, and shows how a recursive definition can implicitly introduce an inductive principle, how the inductive principle introduces a proof schema, and how the schema can be used to prove a property of a inductively defined set, relation or function. This will go into more detail regarding valid uses of quantifiers, when we're able to use the induction hypothesis, how auxiliary lemmas can help, as well as what cases we will need to strengthen properties to prove weaker ones.
        \subsection*{Binding Conventions}
            The binding conventions in this module are the same as the ones used in \textbf{CO140 - Logic}; with the addition of $\forall x$, and $\exists x$ before $\neg$.
        \subsection*{Formalising a Proof}
            For this section, we'll work on one example proof, with the given facts;
            \begin{enumerate}[(1)]
                \itemsep0em
                \item a person is happy if all their children are rich
                \item someone is a supervillain if at least one of their parents is a supervillain
                \item all supervillains are rich
            \end{enumerate}
            We want to show that "all supervillains are happy".
            \subsubsection*{Proof in Natural Language}
                The given argument is that "All of a supervillain's children must therefore also be supervillains; and as all supervillains are rich, all the children of a supervillain are rich. Therefore, any supervillain is happy". However; we've made a few assumptions in this proof - we assume that a supervillain is always a person, and that a supervillain has children (as well as the fact that parent, and child aren't formally defined to be related concepts).
                \medskip

                Therefore, we need to generalise statement (1) OR add an additional assumption (4);
                \begin{enumerate}[(1)]
                    \itemsep0em
                    \item \textbf{someone} is happy if all their children are happy
                    \setcounter{enumi}{3}
                    \item a supervillain is also a person
                \end{enumerate}
            \subsubsection*{Formal Argument}
                \begin{reasoning}
                    \prooftext{Given:}
                    \proofline{1}{\forall x [\text{person}(x) \land \forall y [\text{childof}(y, x) \rightarrow \text{rich}(y)] \rightarrow \text{happy}(x)]}{}
                    \proofline{2}{\forall x [\exists y [\text{childof}(x, y) \land \text{supervillain}(y)] \rightarrow \text{supervillain}(x)]}{}
                    \proofline{3}{\forall x [\text{supervillain}(x) \rightarrow \text{rich}(x)]}{}
                    \proofline{4}{\forall x [\text{supervillain}(x) \rightarrow \text{person}(x)]}{}
                    \prooftext{To show:}
                    \proofline{\alpha}{\forall x [\text{supervillain}(x) \rightarrow \text{happy}(x)]}{}
                    \prooftext{(Stylised) Proof:}
                    \proofarbitrary{G}
                    \proofline{\text{a}1}{\text{supervillain}(G)}{}
                    \proofline{5}{\text{person}(G) \land \forall y [\text{childof}(y, G) \rightarrow \text{rich}(y)] \rightarrow \text{happy}(G)}{from (1)}
                    \proofline{6}{\text{person}(G)}{from (a1), and (4)}
                    \proofarbitrary{E}
                    \proofline{\text{a}2}{\text{childof}(E, G)}{}
                    \proofline{7}{\text{supervillain}(E)}{from (a1), (a2), and (2)}
                    \proofline{8}{\text{rich}(E)}{from (3), and (7)}
                    \proofline{9}{\forall y [\text{childof}(y, G) \rightarrow \text{rich}(y)]}{from (a2), (8), and arbitrary $E$}
                    \proofline{10}{\text{happy}(G)}{from (5), (6), and (9)}
                    \proofline{\alpha}{}{from (a1), (10), and arb. $G$}
                \end{reasoning}
                While this can be proven fairly easily, and with great confidence, via first-order natural deduction, the proof is often tedious, and the intuition might be lost. On the other hand, stylised proofs have an explicit structure, few errors (compared to free-form) - although errors are still possible.
                \medskip

                Our goal for our proofs are that they should only prove valid statements, are easy to read / check, and are able to highlight intuition behind arguments. The rules for a stylised proof are as follows;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item write out, and name each given formula
                    \item write out, and name each goal formula
                    \item plan out proof, and name intermediate results
                    \item justify each step
                    \item size of each step can vary as appropriate
                \end{enumerate}
                Planning, and justifying the the steps follow extremely similar rules to natural deduction - the rules for proving $P$ are as follows;
                \begin{itemize}
                    \itemsep0em
                    \item $P = Q \land R$ \hfill prove both $Q$, and $R$ ($\land$I)
                    \item $P = Q \lor R$ \hfill prove either $Q$, or $R$ ($\lor$I)
                    \item $P = Q \rightarrow R$ \hfill prove $R$ from assuming $Q$ ($\rightarrow$I)
                    \item $P = \neg Q$ \hfill prove $\bot$ from assuming $Q$ ($\neg$I)
                    \item $P = \forall x [Q(x)]$ \hfill show $Q(c)$ from arbitrary $c$ ($\forall$I)
                    \item $P = \exists x [Q(x)]$ \hfill find some $c$, and show $Q(c)$ ($\exists$I)
                    \item $P$ \hfill prove $\bot$ from assuming $\neg P$ (PC)
                \end{itemize}
                On the other hand, if we have proven $P$, we can do the following;
                \begin{itemize}
                    \itemsep0em
                    \item $P = Q \land R$ \hfill both $Q$, and $R$ hold ($\land$E)
                    \item $P = Q \lor R$ \hfill case analysis ($\lor$I)
                    \item $P = Q \land (Q \rightarrow R)$ \hfill $R$ holds ($\rightarrow$E)
                    \item $P = \forall x [Q(x)]$ \hfill $Q(c)$ holds for any $c$ ($\forall$E)
                    \item $P = \exists x [Q(x)]$ \hfill $Q(c)$ holds for some $c$ ($\exists$E)
                    \item $P = \bot$ \hfill anything holds ($\bot$E)
                    \item $P = \neg Q$ \hfill $Q \rightarrow \bot$ holds ($\neg$E)
                    \item $P$ \hfill use a lemma, or any logical equivalence
                \end{itemize}
            \subsubsection*{Another Example}
                \begin{reasoning}
                    \prooftext{Facts in Natural Language:}
                    \proofline{\text{i}}{\text{a dragon is happy if all of its children can fly}}{}
                    \proofline{\text{ii}}{\text{all green dragons can fly}}{}
                    \proofline{\text{iii}}{\text{something is green if at least one of its parents is green}}{}
                    \proofline{\text{iv}}{\text{all the children of a dragon are also dragons}}{}
                    \proofline{\text{v}}{\text{if $y$ is a child of $x$, then $x$ is a parent of $y$}}{}
                    \prooftext{Given:}
                    \proofline{1}{\forall x [\text{dragon}(x) \land \forall y [\text{childof}(x, y) \rightarrow \text{fly}(y)] \rightarrow \text{happy(x)}]}{from (i)}
                    \proofline{2}{\forall x [\text{green}(x) \land \text{dragon}(x) \rightarrow \text{fly}(x)]}{from (ii)}
                    \proofline{3}{\forall x [\exists y [\text{parent of}(y, x) \land \text{green}(y)] \rightarrow \text{green}(y)]}{from (iii)}
                    \proofline{4}{\forall x [\forall y [\text{childof}(x, y) \land \text{dragon}(y) \rightarrow \text{dragon}(x)]]}{from (iv)}
                    \proofline{5}{\forall x [\forall y [\text{childof}(y, x) \rightarrow \text{parentof}(x, y)]]}{from (v)}
                    \prooftext{To show:}
                    \proofline{\alpha}{\forall x [\text{dragon}(x) \rightarrow (\text{green}(x) \rightarrow \text{happy}(x))]}{}
                    \proofline{\times}{\forall x [\text{dragon}(x) \land \text{green}(x) \rightarrow \text{happy}(x)]}{(note - equivalent)}
                    \prooftext{Proof:}
                    \proofarbitrary{S}
                    \proofline{\text{a}1}{\text{dragon}(S)}{}
                    \proofline{\text{a}2}{\text{green}(S)}{}
                    \proofline{6}{\forall x \forall y [\text{parentof}(y, x) \land \text{green}(y) \rightarrow \text{green}(x)]}{from (3)}
                    \proofline{7}{\forall x \forall y [\text{childof}(x, y) \land \text{green(y)} \rightarrow \text{green}(x)]}{from (5), and (6)}
                    \proofline{8}{\forall x [\text{childof}(x, S) \rightarrow \text{green}(x)]}{from (a2), and (7)}
                    \proofline{9}{\forall x [\text{childof}(x, S) \rightarrow \text{dragon}(x)]}{from (a1), and (4)}
                    \proofline{10}{\forall x [\text{childof}(x, S) \rightarrow \text{green}(x) \land \text{dragon}(x)]}{from (8), and (9)}
                    \proofline{11}{\forall x [\text{childof}(x, S) \rightarrow \text{fly}(x)]}{from (2), and (10)}
                    \proofline{12}{\text{happy}(S)}{from (a1), (1), and (11)}
                    \proofline{\alpha}{}{from (a1), (a2), (12), and arb. $S$}
                \end{reasoning}
                Steps (6), (7), and (10) in particular require more justification; the justification of (7) requires us to prove something else, which can be done trivially with ND. Therefore only (6) will be proven;
                \begin{reasoning}
                    \prooftext{Given:}
                    \proofline{1}{\forall x [\exists y [P(x, y)] \rightarrow Q(x)]}{}
                    \prooftext{To show:}
                    \proofline{\alpha}{\forall x \forall y [P(x, y) \rightarrow Q(x)]}{}
                    \prooftext{Proof:}
                    \proofarbitrary{c_1}
                    \proofarbitrary{c_2}
                    \proofline{\text{a}1}{P(c_1, c_2)}{}
                    \proofline{2}{\exists y [P(c_1, y)] \rightarrow Q(c_1)}{from (1), where $x = c_1$}
                    \proofline{3}{\exists y [P(c_1, y)]}{from (a1), where $c_2 = y$}
                    \proofline{4}{Q(c_1)}{from (2), and (3)}
                    \proofline{\alpha}{}{from (a1), (4), and arbitrary $c_1$, $c_2$}
                \end{reasoning}
                Note that (7) requires us to prove $\forall u \forall v [R(v, y) \rightarrow Q(u, v)] \land \forall w \forall z [Q(z, w) \land S(z) \rightarrow S(w)] \rightarrow \forall x \forall y [R(x, y) \land S(y)\rightarrow S(x)]$, which isn't actually as difficult as it looks (only 16 lines in steps in ND). On the other hand, the proof for (10) requires $(A \rightarrow B) \land (A \rightarrow C) \rightarrow (A \rightarrow B \land C)$ - assume $A$, and you get both $B$, and $C$ very quickly.
        \subsection*{Induction over Natural Numbers}
            The notation used here is as follows; $\forall x : S [P(x)]$, where $S$ is an \textbf{enumerable} set and $P \subseteq S$. Note that the notes use $\forall x : S.P(x)$, but I'm choosing to use the same notation as used in \textbf{CO140}, just to maintain consistency. The notation $P \subseteq S$ means that $P$ is a property of elements in the set $S$. $\text{pos} \subset \mathbb{Z}$. The natural numbers, sequences, strings, or recursively defined data structures are enumerable sets, whereas $\mathbb{R}$ is not an enumerable set. These are some examples of enumerable sets;
            \begin{itemize}
                \itemsep0em
                \item $\forall n : \mathbb{N} [7^n + 5 \text{ is divisible by 3}]$
                \item $\forall \texttt{xs}:\texttt{[a]}\forall \texttt{ys}:\texttt{[a]}[\texttt{length(xs ++ ys)} = \texttt{length(xs)} + \texttt{length(ys)}]$
            \end{itemize}
            \subsubsection*{Mathematical Induction Principle}
                For any $P \subseteq \mathbb{N}$: $P(0) \land \forall k : \mathbb{N}[P(k) \rightarrow P(k + 1)] \rightarrow \forall n : \mathbb{N}[P(n)]$
                \medskip

                This mirrors the definition in \textbf{CO142 - Discrete Structures}, by using Peano's axiom. Given a unary predicate $P$, and $P(0)$ is true, and for all natural numbers $k$, if $P(k)$ is true, then it follows that $P(\text{Succ}(k))$ is true. Then it follows that $P(n)$ is true for every natural number $n \in \mathbb{N}$.
            \subsubsection*{Example - Sum of Natural Numbers}
                We want to prove $P(n)$, where $P(n) \triangleq \summation{i = 0}{n}{i} = \frac{n(n + 1)}{2}$ - a formula which we should be used to seeing.
                \smallskip

                We need to formally write this as;
                \medskip

                $\textcolor{blue}{\summation{i = 0}{0}{i} = \frac{0(0 + 1)}{2}} \land \textcolor{red}{\forall k : \mathbb{N} [\summation{i = 0}{k}{i} = \frac{k(k + 1)}{2} \rightarrow \summation{i = 0}{k + 1}{i} = \frac{(k + 1)((k + 1) + 1)}{2}]} \rightarrow \textcolor{violet}{\forall n : \mathbb{N} [\summation{i = 0}{n}{i} = \frac{n(n + 1)}{2}]}$
                \bigskip

                Remember that our aim is to create proofs that can be checked by others. This means justifying each step; writing what we know (givens), and what we aim to prove. All the steps should be explicit, but the granularity can vary depending on the confidence of the step. Intermediate results should be named, so that they can be used later, and variables that we are applying the induction principle on should be stated.

                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\summation{i = 0}{0}{i} = \frac{0(0 + 1)}{2}$}
                    \proofeq{\summation{i = 0}{0}{i}}{0}{by definition of $\sum$}
                    \proofeq{}{\frac{0(1)}{2}}{by arithmetic}
                    \proofeq{}{\frac{0(0 + 1)}{2}}{by arithmetic}
                    \proofis
                    \prooftext{Take arbitrary $k : \mathbb{N}$}
                    \prooftext{Inductive hypothesis: $\summation{i = 0}{k}{i} = \frac{k(k + 1)}{2}$}
                    \prooftext{To show: $\summation{i = 0}{k+1}{i} = \frac{(k + 1)((k + 1) + 1)}{2}$}
                    \proofeq{\summation{i = 0}{k + 1}{i}}{\summation{i = 0}{k}{i} + (k + 1)}{by definition of $\sum$}
                    \proofeq{}{\frac{k(k + 1)}{2} + (k + 1)}{\textcolor{blue}{by inductive hypothesis}}
                    \proofeq{}{\frac{k^2 + 3k + 2}{2}}{by arithmetic}
                    \proofeq{}{\frac{(k + 1)(k + 2)}{2}}{by arithmetic}
                    \proofeq{}{\frac{(k + 1)((k + 1) + 1)}{2}}{by arithmetic}
                \end{reasoning}
            \subsubsection*{Example - $7^n + 5$ is divisible by 3}
                We want to prove $P(n)$, where $P(n) \triangleq 7^n + 5 \text{ is divisible by 3}$. However, this isn't exactly a very formal defined, so we will rewrite it as $P(n) \triangleq \exists m : \mathbb{N}[7^n + 5 = 3m]$
                \smallskip

                We need to formally write this as;
                \medskip

                $\textcolor{blue}{\exists m : \mathbb{N} [7^0 + 5 = 3m]} \land \textcolor{red}{\forall k : \mathbb{N} [\exists m : \mathbb{N}[7^k + 5 = 3m] \rightarrow \exists m^\prime : \mathbb{N} [7^{k + 1} + 5 = 3m^\prime]]} \rightarrow \\ \textcolor{violet}{\forall n : \mathbb{N} [\exists m : \mathbb{N} [7^n + 5 = 3m]]}$

                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\exists m : \mathbb{N}[7^0 + 5 = 3m]$}
                    \proofeq{7^0 + 5}{1 + 5}{by arithmetic}
                    \proofeq{}{6}{by arithmetic}
                    \proofeq{}{3 \cdot 2}{by arithmetic}
                    \prooftherefore{\exists m : \mathbb{N}[7^0 + 5 = 3m]}
                    \proofis
                    \prooftext{Take arbitrary $k : \mathbb{N}$}
                    \prooftext{Inductive hypothesis: $\exists m : \mathbb{N} [7^k + 5 = 3m]$}
                    \proofline{1}{7^k + 5 = 3 \cdot m_1}{by inductive hypothesis, for some $m_1 : \mathbb{N}$}
                    \prooftext{To show: $\exists m^\prime : \mathbb{N} [7^{k + 1} + 5 = 3m^\prime]$}
                    \proofeq{7^{k + 1} + 5}{7 \cdot 7^k + 5}{by arithmetic}
                    \proofeq{}{(6 + 1) \cdot 7^k + 5}{by arithmetic}
                    \proofeq{}{(6 \cdot 7^k + 7^k) + 5}{by arithmetic}
                    \proofeq{}{3 \cdot (2 \cdot 7^k) + (7^k + 5)}{by arithmetic}
                    \proofeq{}{3 \cdot (2 \cdot 7^k) + 3 \cdot m_1}{by (1)}
                    \proofeq{}{3 \cdot [2 \cdot 7^k + m_1]}{by arithmetic}
                    \prooftherefore{\exists m^\prime : \mathbb{N} [7^{k + 1} + 5 = 3m^\prime]}
                \end{reasoning}
            \subsubsection*{New Technique}
                Consider the Haskell program defined as;
                \begin{lstlisting}
                    f :: Int -> Ratio Int
                    f 1 = 1/2
                    f n = 1/(n * (n + 1)) + f (n - 1)
                \end{lstlisting}
                And, we want to prove $\forall n \geq 1 [\texttt{f } n = \frac{n}{n + 1}]$. However, we cannot directly apply the mathematic induction principle on this, since the conclusion has a different form, and it's not defined for \texttt{f} 0 - hence we have no base case. Instead, we can do one of the following approaches;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item prove $\forall n : \mathbb{N} [\textcolor{blue}{n \geq 1 \rightarrow} \texttt{ f } n = \frac{n}{n + 1}]$
                    \item prove $\forall n : \mathbb{N} [\texttt{f } (n \textcolor{blue}{+ 1}) = \frac{n \textcolor{blue}{+ 1}}{n \textcolor{blue}{+ 2}}]$
                    \item apply the mathematical induction technique
                \end{enumerate}
                For practice, we will do the first approach; first we must formally write this out as;
                \medskip

                $\textcolor{blue}{0 \geq 1 \rightarrow \texttt{ f } 0 = \frac{0}{0 + 1}} \land \textcolor{red}{\forall k : \mathbb{N} [(k \geq 1 \rightarrow \texttt{ f } k = \frac{k}{k + 1}) \rightarrow ((k + 1) \geq 1 \rightarrow \texttt{ f } (k + 1) = \frac{k + 1}{k + 2})]} \rightarrow \\ \textcolor{violet}{\forall n : \mathbb{N} [n \geq 1 \rightarrow \texttt{ f } n = \frac{n}{n + 1}]}$

                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $0 \geq 1 \rightarrow \texttt{ f } 0 = \frac{0}{0 + 1}$}
                    \prooftext{This holds trivially, as we know $0 \geq 1$ is false, and anything follows from a falsity}
                    \proofis
                    \prooftext{Take arbitrary $k : \mathbb{N}$}
                    \prooftext{Inductive hypothesis: $k \geq 1 \rightarrow \texttt{ f } k = \frac{k}{k + 1}$}
                    \prooftext{To show: $(k + 1) \geq 1 \rightarrow \texttt{ f } (k + 1) = \frac{k + 1}{k + 2}$}
                    \proofline{1.0}{k = 0}{by case}
                    \proofline{1.1}{k + 1 = 1}{by arithmetic}
                    \proofline{1.2}{\texttt{f} (k + 1) = \frac{1}{2}}{by def. of \texttt{f}, and (1.1)}
                    \proofline{1.3}{\frac{k + 1}{k + 2} = \frac{1}{2}}{by (1.1)}
                    \prooftherefore{\texttt{f} (k + 1) = \frac{k + 1}{k + 2}$ & \hfill by (1.2), and (1.3)$ }
                    \proofline{2.0}{k > 0}{by case}
                    \proofline{2.1}{k \geq 1}{by case}
                    \proofline{2.2}{k + 1 \geq 2}{by (2.1), and arithmetic}
                    \proofline{2.3}{\texttt{f } (k + 1) = \frac{1}{(k + 1)(k + 2)} + \texttt{ f } k}{by (2.2), and def. of \texttt{f}}
                    \proofline{2.4}{\texttt{f } (k + 1) = \frac{1}{(k + 1)(k + 2)} + \frac{k}{k + 1}}{by (2.3), and inductive hypothesis}
                    \proofline{2.5}{\texttt{f } (k + 1) = \frac{1}{(k + 1)(k + 2)} + \frac{k(k + 2)}{(k + 1)(k + 2)}}{by (2.4), and arithmetic}
                    \prooftherefore{\texttt{f} (k + 1) = \frac{k + 1}{k + 2}$ & \hfill by (2.5), and arithmetic$ }
                \end{reasoning}
                The third approach follows this; for any $P \subseteq \mathbb{Z}$, and any $m : \mathbb{Z}$, we have $P(m) \land \forall k \geq m [P(k) \rightarrow P(k + 1)] \rightarrow \forall n \geq m [P(n)]$. This uses $\forall n \geq m [P(n)]$, as a shorthand for $\forall n : \mathbb{Z} [n \geq m \rightarrow P(n)]$. Note how this isn't any different from the principle; in reality, the principle is a "specific case" of the technique, where $m = 0$. % if you're at king's, and think natural numbers start at 1, you're wrong.
                \medskip

                Now, using the technique with $m = 1$, we can do the original proof inductively;
                \medskip

                $\textcolor{blue}{\texttt{f } 1 = \frac{1}{1 + 1}} \land \textcolor{red}{\forall k \geq 1 [\texttt{f } k = \frac{k}{k + 1} \rightarrow \texttt{ f } (k + 1) = \frac{k + 1}{k + 2}]} \rightarrow \textcolor{violet}{\forall n \geq 1 [\texttt{f } n = \frac{n}{n + 1}]}$

                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\texttt{f } 1 = \frac{1}{ 1+ 1}$}
                    \proofeq{\texttt{f } 1}{\frac{1}{2}}{by def. of \texttt{f}}
                    \proofeq{}{\frac{1}{1 + 1}}{by arithmetic}
                    \proofis
                    \prooftext{Take arbitrary $k : \mathbb{Z}$}
                    \proofline{\text{a}1}{k \geq 1}{assumption}
                    \prooftext{Inductive hypothesis: $\texttt{f } k = \frac{k}{k + 1}$}
                    \prooftext{To show: $\texttt{f } (k + 1) = \frac{k + 1}{k + 2}$}
                    \proofeq{\texttt{f } (k + 1)}{\frac{1}{(k + 1)(k + 2)} + \texttt{f } k}{by def. of \texttt{f}, and (a1)}
                    \proofeq{}{\frac{1}{(k + 1)(k + 2)} + \frac{k}{k + 1}}{by inductive hypothesis}
                    \proofeq{}{\frac{1}{(k + 1)(k + 2)} + \frac{k(k + 2)}{(k + 1)(k + 2)}}{by arithmetic}
                    \proofeq{}{\frac{k^2 + 2k + 1}{(k + 1)(k + 2)}}{by arithmetic}
                    \proofeq{}{\frac{(k + 1)^2}{(k + 1)(k + 2)}}{by arithmetic}
                    \proofeq{}{\frac{k + 1}{k + 2}}{by arithmetic}
                \end{reasoning}
            \subsubsection*{Strong Induction}
                While mathematical induction is powerful, it only allows for the inductive step ($k + 1$) to refer to the direct predecessor ($k$). On the other hand, strong induction allows the inductive step to refer to any predecessor, such as $k - 1$, $k - 2$, and so on. For example, if an algorithm was to recurse down by two units, we wouldn't be able to use the inductive hypothesis to replace \texttt{g (k - 1)} from doing the inductive step on $k + 1$. An example of this is this Haskell program, with the property $\forall n : \mathbb{N} [\texttt{g } n = 3^n - 2^n]$;
                \begin{lstlisting}
                    g :: Int -> Int
                    g 0 = 0
                    g 1 = 1
                    g n = (5 * g (n - 1)) - (6 * g (n - 2))
                \end{lstlisting}
                As such, we need the principle of strong induction; $P(0) \land \forall k : \mathbb{N} [\forall j \in [0..k] [P(j)] \rightarrow P(k + 1)] \rightarrow \forall n : \mathbb{N} [P(n)]$. Here we are using the following shorthand; $j \in [m..n]$ means $m \leq j \leq n$, and similarly $j \in [m..n)$ means $m \leq j < n$. Complete induction has the same base case, where we need to verify $P(0)$, however, the inductive step differs as we have to assume that $P(i)$ holds for all $i \leq k$, then show that $P(k + 1)$ holds. If both of those hold, then it follows that $P(n)$ follows for all $n \in \mathbb{N}$ With this, we can now write down the strong induction principle on $\texttt{g } n = 3^n - 2^n$.
                \medskip

                $\textcolor{blue}{\texttt{g } 0 = 3^0 - 2^0} \land \textcolor{red}{\forall k [\forall j \in [0..k] [\texttt{g } j = 3^j - 2^j] \rightarrow \texttt{g } (k + 1) = 3^{k + 1} - 2^{k + 1}]} \rightarrow \textcolor{violet}{\forall n : \mathbb{N} [\texttt{g }n = 3^n - 2^n]}$
                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\texttt{g } 0 = 3^0 - 2^0$}
                    \proofeq{\texttt{g } 0}{0}{by def. of \texttt{g}}
                    \proofeq{}{1 - 1}{by arithmetic}
                    \proofeq{}{3^0 - 2^0}{by arithmetic}
                    \proofis
                    \prooftext{Take arbitrary $k : \mathbb{N}\ (k \neq 0)$}
                    \prooftext{Case 1: $k = 0$}
                    \prooftext{To show: $\texttt{g } 1 = 3^1 - 2^1$}
                    \proofeq{\texttt{g } 1}{1}{by def. of \text{g}}
                    \proofeq{}{3 - 2}{by arithmetic}
                    \proofeq{}{3^1 - 2^1}{by arithmetic}
                    \prooftext{Case 2: $k \neq 0$}
                    \proofline{1}{k \geq 1}{because $k : \mathbb{N}$, and $k \neq 0$ by case}
                    \proofline{2}{k, k - 1 \in [0..k]}{from (1)}
                    \prooftext{Inductive hypothesis: $\forall j \in [0..k] [\texttt{g } j = 3^j - 2^j]$}
                    \prooftext{To show: $\texttt{g } (k + 1) = 3^{k + 1} - 2^{k + 1}$}
                    \proofeq{\texttt{g } (k + 1)}{5 \cdot \texttt{g } k - 6 \cdot \texttt{g } (k - 1)}{by (1), and def. of \text{g}}
                    \proofeq{}{5 \cdot (3^k - 2^k) - 6 \cdot (3^{k - 1} - 2^{k - 1})}{by (2), and inductive hypothesis}
                    \proofeq{}{5 \cdot 3 \cdot 3^{k - 1} - 5 \cdot 2 \cdot 2^{k - 1} - 6 \cdot 3^{k - 1} + 6 \cdot 2^{k - 1}}{by arithmetic}
                    \proofeq{}{9 \cdot 3^{k - 1} - 4 \cdot 2^{k - 1}}{by arithmetic}
                    \proofeq{}{3^{k + 1} - 2^{k + 1}}{by arithmetic}
                \end{reasoning}
                Once again, this principle can be applied for some $m$, and is therefore modified to be $P(m) \land \forall k : \mathbb{Z} [\forall j \in [m..k] [P(j)] \rightarrow P(k + 1)] \rightarrow \forall n \geq m [P(n)]$. The same shorthand we used before applies here.
        \subsection*{Induction over Haskell Lists}
            The example we will be working on involves the follow Haskell functions;
            \begin{lstlisting}
                elem :: Eq a => a -> [a] -> Bool
                elem x []     = False
                elem x (y:ys) = x == y || elem x ys

                subList :: Eq a => [a] -> [a] -> [a]
                subList [] ys = []
                subList (x:xs) ys
                  | elem x ys = subList xs ys
                  | otherwise = x:(subList xs ys)
            \end{lstlisting}
            As well as the specification $\forall xs : \texttt{[a]} \forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList } xs\ ys]$. Note that we use $z \in ys$ as shorthand for $\texttt{elem } z\ ys$. The function \texttt{subList} $xs$ $ys$ removes all elements of $ys$ from $xs$.
            \medskip

            The goal here is to prove $\forall xs : \texttt{[a]} [Q(xs)]$, where $Q(xs) \triangleq \forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList }xs\ ys]$. Induction doesn't simply work here, as $Q$ isn't defined over a set of numbers, but rather over the lists of \texttt{a}. Once again, we can take multiple approaches to this problem;
            \begin{enumerate}[1.]
                \itemsep0em
                \item map lists to numbers, by expressing $Q \subseteq \texttt{[a]}$, with an equivalent $P \subseteq \mathbb{N}$
                    \subitem there's a proof of this in \textit{Induction over Haskell data structures (full notes).pdf} - the point is that it's a bad idea, and structural induction should be used instead.
                    \subitem this method of reasoning is indirect - the property \texttt{length} is unrelated to $P$
                \item use structural induction
                    \subitem in a step of mathematical induction, we need to argue a property is inherited by the \textbf{predecessor} to its \textbf{successor}, such that 4 succeeds 3
                    \subitem this concept needs to be generalised to other data structures, for example; can we say \texttt{1:2:3:[]} is a successor to \texttt{2:3:[]}?
            \end{enumerate}
            \subsubsection*{Structural Induction Principle (Lists)}
                For any type $\texttt{T}$, and $P \subseteq \texttt{[T]}$; we can say $P(\texttt{[]}) \land \forall vs : \texttt{[T]} \forall v : \texttt{T} [P(vs) \rightarrow P(v : vs)] \rightarrow \forall xs : \texttt{[T]} [P(xs)]$
                \medskip

                Now, we can apply the structural induction principle to $xs$ for \texttt{subList};

                $\phantom{\forall vs : \texttt{[a]} \forall v : \texttt{a}[(} \textcolor{red}{\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList [] } ys]} \land \\ \textcolor{blue}{\forall vs : \texttt{[a]} \forall v : \texttt{a} [(\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList }vs\ ys]) \rightarrow} \\ \phantom{\forall vs : \texttt{[a]} \forall v : \texttt{a}[} \textcolor{blue}{(\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList }(v : vs)\ ys])]} \rightarrow \\ \phantom{\forall v : \texttt{a}(} \textcolor{violet}{\forall xs : \texttt{[a]}[\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList } xs\ ys]]}$ % i should really learn how to align things properly.
                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList [] } ys]$}
                    \proofline{\text{a}1}{z \in ys}{otherwise, it's trivial to prove}
                    \proofline{1}{\texttt{subList [] } ys}{by def. of \texttt{subList}}
                    \proofline{2}{z \not\in \texttt{subList []} ys}{by (1), and def. of \texttt{elem}}
                    \proofis
                    \prooftext{Take arbitrary $v : \texttt{a}$, and $vs : \texttt{[a]}$}
                    \prooftext{Inductive hypothesis: $\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList } vs\ ys]$}
                    \prooftext{To show: $\forall ys : \texttt{[a]} \forall z : \texttt{a} [z \in ys \rightarrow z \not\in \texttt{subList } (v : vs)\ ys]$}
                    \proofline{\text{a}1}{z \in ys}{otherwise, it's trivial to prove}
                    \proofline{0.1}{z \not\in \texttt{subList } vs\ ys}{by (a1), and inductive hypothesis}
                    \proofline{1.0}{v \in ys}{by case}
                    \proofline{1.1}{\texttt{subList } (v : vs)\ ys = \texttt{subList }vs\ ys}{by (1.0), and def. of \texttt{subList}}
                    \proofline{1.2}{z \not\in \texttt{subList } (v : vs)\ ys}{by (0.1), and (1.1)}
                    \proofline{2.0}{v \not\in ys}{by case}
                    \proofline{2.1}{\texttt{subList } (v : vs)\ ys = v : (\texttt{subList }vs\ ys)}{by (2.0), and def. of \texttt{subList}}
                    \proofline{2.2}{z \neq v}{by (a1), and (2.0)}
                    \proofline{2.3}{z \not\in \texttt{subList } (v : vs)\ ys}{by (0.1), (2.2), (2.3), and def. of \texttt{elem}}
                \end{reasoning}
            \subsubsection*{Lemmas for Lists}
                The following lemmas apply for arbitrary \texttt{u:a}, and \texttt{us,vs,ws:[a]}
                \begin{enumerate}[(A)]
                    \item \texttt{us++[] = us}
                    \item \texttt{[]++us = us}
                    \item \texttt{(u:us)++vs = u:(us++vs)}
                    \item \texttt{(us++vs)++ws = us++(vs++ws)}
                \end{enumerate}
                We will be using these lemmas on to prove $\forall xs : \texttt{[a]} \forall ys : \texttt{[a]} [\texttt{rev } (xs ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } xs)]$, on the following Haskell function;
                \begin{lstlisting}
                    rev :: [a] -> [a]
                    rev []     = []
                    rev (x:xs) = (rev xs) ++ [x]
                \end{lstlisting}
                \medskip

                $\phantom{\forall vs : \texttt{[a]} \forall v : \texttt{a}[(} \textcolor{red}{\forall ys : \texttt{[a]} [\texttt{rev } (\texttt{[]} ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev []})]} \land \\ \textcolor{blue}{\forall vs : \texttt{[a]} \forall v : \texttt{a} [(\forall ys : \texttt{[a]} [\texttt{rev } (vs ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } vs)]) \rightarrow} \\ \phantom{\forall vs : \texttt{[a]} \forall v : \texttt{a}[} \textcolor{blue}{(\forall ys : \texttt{[a]} [\texttt{rev } ((v : vs) ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } (v : vs))])]} \rightarrow \\ \phantom{\forall v : \texttt{a}(} \textcolor{violet}{\forall xs : \texttt{[a]}[\forall ys : \texttt{[a]} [\texttt{rev } (xs ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } xs)]]}$ % i should really learn how to align things properly.
                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\forall ys : \texttt{[a]} [\texttt{rev } (\texttt{[]} ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev []})]$}
                    \proofeq{\texttt{rev }(\texttt{[]} ++ ys)}{\texttt{rev } ys}{by (B)}
                    \proofeq{}{(\texttt{rev } ys) ++ \texttt{[]}}{by (A)}
                    \proofeq{}{(\texttt{rev } ys) ++ (\texttt{rev []})}{by def. of \texttt{rev}}
                    \proofis
                    \prooftext{Take arbitrary $z : \texttt{a}$, and $zs : \texttt{[a]}$}
                    \prooftext{Inductive hypothesis: $\forall ys : \texttt{[a]} [\texttt{rev } (zs ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } zs)]$}
                    \prooftext{To show: $\forall ys : \texttt{[a]} [\texttt{rev } ((z : zs) ++ ys) = (\texttt{rev } ys) ++ (\texttt{rev } (z : zs))]$}
                    \proofeq{\texttt{rev } ((z : zs) ++ ys)}{\texttt{rev } (z : (zs ++ ys))}{by (C)}
                    \proofeq{}{\texttt{rev } (zs ++ ys) ++ [z]}{by def. of \texttt{rev}}
                    \proofeq{}{((\texttt{rev } ys) ++ (\texttt{rev } zs)) ++ [z]}{by inductive hypothesis}
                    \proofeq{}{(\texttt{rev } ys) ++ ((\texttt{rev } zs) ++ [z])}{by (D)}
                    \proofeq{}{(\texttt{rev } ys) ++ (\texttt{rev } (z : zs))}{by def. of \texttt{rev}}
                \end{reasoning}
                Unlike in induction over natural numbers, each list has an infinite number of successors (for example, both \texttt{3:[]}, and \text{877:[]} are successors of \texttt{[]}), which is why it's important for us to consider arbitrary values. Intuitively, assuming the base case of $P(\texttt{[]})$ holds, we have $P(\texttt{[]}) \rightarrow (P(\texttt{x:[]}) \rightarrow (P(\texttt{y:x:[]}) \rightarrow P(\texttt{z:y:x[]})))$, and so on, hence it holds for all lists.
        \subsection*{Induction over Haskell Data Structures}
            While we can now perform induction over the natural numbers, as well as lists of arbitrary type, we cannot yet perform induction over arbitrary data structures, which are recursively defined. Consider the following data structures;
            \begin{itemize}
                \itemsep0em
                \item \texttt{data Nat = Zero | Succ Nat}
                    \subitem $P(\texttt{Zero}) \land \forall n : \texttt{Nat} [P(n) \rightarrow P(\texttt{Succ } n)] \rightarrow \forall n : \texttt{Nat} [P(n)]$
                \item \texttt{data Tree a = Empty | Node (Tree a) a (Tree a)}
                    \subitem $P(\texttt{Empty}) \land \forall t_1, t_2 : \texttt{Tree T} \forall x \texttt{T} [P(t_1) \land P(t_2) \rightarrow P(\texttt{Node }t_1\ x\ t_2)] \rightarrow \forall t : \texttt{Tree T} [P(t)]$
                \item \texttt{data BExp = T | F | BNt BExp | BAnd BExp BExp}
                    \subitem $P(\texttt{T}) \land P(\texttt{F}) \land \forall b : \texttt{BExp} [P(b) \rightarrow P(\texttt{BNt } b)] \land \forall b_1, b_2 : \texttt{BExp} [P(b_1) \land P(b_2) \rightarrow P(\texttt{BAnd } b_1 b_2)] \rightarrow \forall b : \texttt{BExp} [P(b)]$
            \end{itemize}
        \subsection*{Proof Strategies}
            A situation may arise where a statement cannot be proven directly from induction; for example $\forall is \texttt{[Int]} [\texttt{sum } is = \texttt{sum\_tr } is\ 0]$, on the following functions;
            \begin{lstlisting}
                sum :: [Int] -> Int
                sum []     = 0
                sum (i:is) = i + sum is

                sum_tr :: [Int] -> Int -> Int
                sum_tr [] k     = k
                sum_tr (i:is) k = sum_tr is (i+k)
            \end{lstlisting}
            \begin{reasoning}
                \proofbc
                \prooftext{This is trivial to prove, also I'm tired}
                \proofis
                \prooftext{Take arbitrary $i : \texttt{Int}$, and $is : \texttt{[Int]}$}
                \prooftext{Inductive hypothesis: $\texttt{sum } is = \texttt{sum\_tr } is\ 0$}
                \prooftext{To show: $\texttt{sum } (i : is) = \texttt{sum\_tr } (i : is)\ 0$}
                \proofeq{\texttt{sum } (i : is)}{i + \texttt{sum } is}{by def. of \texttt{sum}}
                \proofeq{}{i + \texttt{sum\_tr } is\ 0}{by inductive hypothesis}
                \proofeq{}{???}{???}
                \proofeq{}{\texttt{sum\_tr } is\ i}{???}
                \proofeq{}{\texttt{sum\_tr } (i:is)\ 0}{by def. of \texttt{sum\_tr}}
            \end{reasoning}
            As we cannot prove this directly by induction, we need to use one of the following approaches;
            \begin{enumerate}[1.]
                \itemsep0em
                \item invent an auxiliary lemma
                    \subitem the lemma in this case would be as follows; $\forall i : \texttt{Int} \forall k : \texttt{Int} \forall is : \texttt{[Int]} [i + (\texttt{sum\_tr } is\ k) = \texttt{sum\_tr } is\ (i + k)]$, which would be the justification for the penultimate line in the proof (skipping the i + 0 step).
                \item strengthen original property
                    \subitem instead of proving the original property, we will prove $\textcolor{blue}{\forall k : \texttt{Int}}\forall is : \texttt{[Int]} [\textcolor{blue}{k} + (\texttt{sum } is) = \texttt{sum\_tr } is\ \textcolor{blue}{k}]$
                    \subitem note that the stronger property is a general form of the original property (which is a specific case, where $k = 0$)
            \end{enumerate}
            \begin{reasoning}
                \proofbc
                \prooftext{Our aim here is to show $\forall k : \texttt{Int} [k + (\texttt{sum []}) = \texttt{sum\_tr [] } k]$}
                \prooftext{Take arbitrary $k : \texttt{Int}$}
                \proofeq{k + (\texttt{sum []})}{k + 0}{by def. of \texttt{sum}}
                \proofeq{}{k}{by arithmetic}
                \proofeq{}{\texttt{sum\_tr [] } k}{by def. of \texttt{sum\_tr}}
                \proofis
                \prooftext{Take arbitrary $i : \texttt{Int}$, and $is : \texttt{[Int]}$}
                \prooftext{Inductive hypothesis: $\forall m : \texttt{Int} [m + (\texttt{sum } is) = \texttt{sum\_tr } is\ m]$}
                \prooftext{To show: $\forall n : \texttt{Int} [k + (\texttt{sum } (i : is)) = \texttt{sum\_tr } (i : is)\ n]$}
                \prooftext{Take arbitrary $n : \texttt{Int}$}
                \proofeq{n + \texttt{sum } (i : is)}{n + i + \texttt{sum } is}{by def. of \texttt{sum}, and arithmetic}
                \proofeq{}{\texttt{sum\_tr } is\ (n + i)}{by inductive hypothesis, and $m = n + i$}
                \proofeq{}{\texttt{sum\_tr } (i : is)\ n}{by def. of \texttt{sum\_tr}}
            \end{reasoning}
            There are also induction principles for more complex cases;
            \begin{itemize}
                \itemsep0em
                \item \texttt{data T = C1 [Int] | C2 Int T}
                    \subitem $\forall is : \texttt{[Int]} [P(\texttt{C1 } is)] \land \forall i : \texttt{Int} \forall t : \texttt{T} [P(t) \rightarrow P(\texttt{C2 } i\ t)] \rightarrow \forall t : \texttt{T} [P(t)]$
                \item \texttt{data Reds = BaseR | Red Greens \\ data Greens = BaseG | Green Reds}
                    \subitem $P(\texttt{BaseR} \land \forall g : \texttt{Greens} [Q(g) \rightarrow P(\texttt{Red } g)]) \land Q(\texttt{BaseG}) \land \forall r : \texttt{Reds} [P(r) \rightarrow Q(\texttt{Green } r)] \rightarrow \forall r : \texttt{Red} [P(r)] \land \forall g : \texttt{Green} [Q(g)]$
                    \subitem $P(\texttt{BaseR}) \land P(\texttt{Red BaseG}) \land \forall r : \texttt{Reds} [P(r) \rightarrow P(\texttt{Red Green } r)] \rightarrow \forall r : \texttt{Reds} [P(r)]$
            \end{itemize}
            Going back to the cactus problem; we can express the cactus as a set of data types;
            \begin{lstlisting}
                data Cactus = Root Tree
                data Tree   = Leaf | Node Trees
                data Trees  = Empty | Cons Tree Trees
            \end{lstlisting}
            This (\texttt{Tree}) then has the inductive principle $P(\text{Leaf}) \land \forall ts : \texttt{Trees} [Q(ts) \rightarrow P(\texttt{Node }ts)] \land Q(\texttt{Empty}) \land \forall t : \texttt{Tree} \forall ts : \texttt{Trees} [P(\texttt{t}) \land Q(\texttt{ts}) \rightarrow Q(\texttt{Cons }t\ ts)] \rightarrow \forall t : \texttt{Tree} [P(t)] \land \forall ts : \texttt{Trees} [Q(ts)]$.
            \smallskip

            However, it's trivial to see that \texttt{Trees} is essentially equivalent to \texttt{[Tree]} - therefore we can simplify the data types to;
            \begin{lstlisting}
                data Cactus = Root Tree
                data Tree   = Leaf | Node [Tree]
            \end{lstlisting}
            Now; the new \texttt{Tree} structure has the inductive principle; $P(\texttt{Leaf}) \land \forall ts : \texttt{Trees} [\forall t : \texttt{Tree}, \forall ts_1, ts_2 : \texttt{Trees} [\textcolor{violet}{ts = ts_1 ++ [t] ++ ts_2 \rightarrow P(t)}] \rightarrow P(\texttt{Node } ts)] \rightarrow \forall t : \texttt{Tree} [P(t)]$. The meaning of the part in \textcolor{violet}{violet} is that every item in $ts$ satisfies the property $P$, I think.
            \medskip

            In summary, by having a recursively defined data type, it allows us to construct an induction principle, which then leads to a proof schema. We are able to use first-order equivalences to swap quantifiers, which may allow for a proof on an easier equivalent property. Occasionally, lemmas will need to be strengthened, or we will need to create auxiliary lemmas.
        \subsection*{Induction over Recursive Relations and Functions}
            As every inductively defined set creates a successor relation (+1 for $\mathbb{N}$, or \texttt{Node} for \texttt{Tree}), all inductively defined relations, and functions give rise to successor relations, therefore all inductively defined sets, relations, and functions give rise to an induction induction principle. Generalising the principle of induction from sets to functions, and relations, follows from the idea that relations, and functions, can both be represented through sets. Consider the "mystery" function \texttt{M};
            \begin{lstlisting}
                M :: Int -> Int
                M m = M'(m, 0, 1)

                M' :: (Int, Int, Int) -> Int
                M' (i, cnt, acc)
                  | i == cnt  = acc
                  | otherwise = M'(i, cnt+1, 2*acc)
            \end{lstlisting}
            We can then evaluate the value of \texttt{M}($n$), let $n = 4$;
            \begin{reasoning}
                \proofeq{\texttt{M}(4)}{\texttt{M'}(4, 0, 1)}{by def. of \texttt{M}}
                \proofeq{}{\texttt{M'}(4, 0, 1)}{by def. of \texttt{M'}}
                \proofeq{}{\texttt{M'}(4, 1, 2)}{by def. of \texttt{M'}}
                \proofeq{}{\texttt{M'}(4, 2, 4)}{by def. of \texttt{M'}}
                \proofeq{}{\texttt{M'}(4, 3, 8)}{by def. of \texttt{M'}}
                \proofeq{}{\texttt{M'}(4, 4, 16)}{by def. of \texttt{M'}}
                \proofeq{}{16}{by def. of \texttt{M'}}
            \end{reasoning}
            In general, let it be \textbf{Assrt\_1}, $\forall m : \mathbb{N} [\texttt{M}(m) = 2^m]$. While the definition for \texttt{M'} might feel forced, or deliberately implemented due to the increasing argument size, we care about it for a few reasons. Firstly, it's a tail-recursive function, and also once translated to an imperative language, it acts as a loop. For example, we can represent it in Java in a similar way;
            \begin{lstlisting}
                cnt = 0;
                acc = 0;
                while !(m == cnt) {
                  cnt = cnt + 1;
                  acc = 2*acc;
                }
                return acc;
            \end{lstlisting}
            We want to establish \textbf{Assrt\_2}: $\forall m, cnt, acc, p : \mathbb{N} [\texttt{M'}(m, cnt, acc) = p \rightarrow p = 2^{m - cnt} \cdot acc]$. The challenge with this is how it's recursively defined with increasing arguments. Due to this, we have to take one of the following approaches;
            \begin{enumerate}[1.]
                \itemsep0em
                \item find some measure which decreases, rather than increases, with each level of recursion
                \item count the number of recursive calls in \texttt{M'}
                \item a new induction principle
            \end{enumerate}
            In the first approach, we show that if $m < cnt$, then the function does not terminate ($m < cnt \rightarrow m \neq cnt$, as the termination condition is $m = cnt$). Hence \textbf{Assrt\_2} can be shown as \textbf{Assrt\_2'} = $\forall m, cnt, acc, p : \mathbb{N} [m \geq cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]$. However, in order to be able to prove \textbf{Assrt\_2'}, we need to prove \textbf{Assrt\_3}: $\forall k, m, cnt, acc : \mathbb{N} [k = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]$. We also need to prove that $\textbf{Assrt\_3} \rightarrow \textbf{Assrt\_2'}$.
            \medskip

            Proving the latter is fairly straightforward, if $k = m - cnt$, and $k \geq 0$ (since it's a natural number), then it follows that $m - cnt \geq 0$, therefore $m \geq cnt$.
            \medskip

            In order to prove \textbf{Assrt\_3}, we need to apply mathematical induction over $k$, and formally apply the principle as;
            \smallskip

            \begin{itemize}
                \itemsep0em
                \item $\forall m, cnt, acc : \mathbb{N} [m = cnt \rightarrow \texttt{M'}(i, cnt, acc) = acc]$
                \item $\forall m, cnt, acc : \mathbb{N} [m > cnt \rightarrow ]$
            \end{itemize}

            $\phantom{\forall k : \mathbb{N}[} \textcolor{blue}{\forall m, cnt, acc : \mathbb{N} [0 = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]} \land \\ \textcolor{red}{\forall k : \mathbb{N} [\forall m, cnt, acc : \mathbb{N} [k = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc] \rightarrow } \\ \phantom{\forall k : \mathbb{N} [} \textcolor{red}{\forall m, cnt, acc : \mathbb{N} [k + 1 = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]]} \rightarrow \\ \phantom{\ : \mathbb{N}[} \textcolor{violet}{\forall k, m, cnt, acc : \mathbb{N} [k = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]}$
            \begin{reasoning}
                \proofbc
                \prooftext{Our aim here is to show $\forall m, cnt, acc : \mathbb{N} [0 = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc]$}
                \prooftext{Take arbitrary $m, cnt, acc : \mathbb{N}$}
                \proofline{\text{a}1}{0 = m - cnt}{assumption, otherwise the proof is trivial}
                \proofline{1}{m = cnt}{by (a1), and arithmetic}
                \proofeq{\texttt{M'}(m, cnt, acc)}{acc}{by (1), and def. of \texttt{M'}}
                \proofeq{}{2^0 \cdot acc}{by arithmetic}
                \proofeq{}{2^{m - cnt} \cdot acc}{by (a1)}
                \proofis
                \prooftext{Take arbitrary $m : \mathbb{N}$}
                \prooftext{Inductive hypothesis: $\forall acc_1, cnt_1 : \mathbb{N} [k = m - cnt_1 \rightarrow \texttt{M'}(m, cnt_1, acc_1) = 2^{m - cnt_1} \cdot acc_1]$}
                \prooftext{To show: $k + 1 = m - cnt \rightarrow \texttt{M'}(m, cnt, acc) = 2^{m - cnt} \cdot acc$}
                \prooftext{Take arbitrary $cnt, acc : \mathbb{N}$}
                \proofline{\text{a}1}{k + 1 = m - cnt}{assumption, otherwise the proof is trivial}
                \proofline{1}{k \geq 0}{by $k : \mathbb{N}$}
                \proofline{2}{k + 1\geq 1}{by arithmetic}
                \proofline{3}{m - cnt \geq 1}{by (2), and arithmetic}
                \proofline{4}{m \geq cnt + 1}{by arithmetic}
                \proofline{5}{m > cnt}{by definition of $\geq$, arithmetic, and $m, cnt: \mathbb{N}$}
                \proofline{6}{m \neq cnt}{by (5)}
                \proofeq{\texttt{M'}(m, cnt, acc)}{\texttt{M'}(m, cnt + 1, 2 \cdot acc)}{by (6), and def. of \texttt{M'}}
                \proofeq{}{\texttt{M'}(m, cnt_1, acc_1)}{where $cnt_1 = cnt + 1$, $acc_1 = 2 \cdot acc$}
                \proofeq{}{2^{m - cnt_1} \cdot acc_1}{by inductive hypothesis}
                \proofeq{}{2^{m - cnt - 1} \cdot 2 \cdot acc}{by substitution}
                \proofeq{}{2^{m - cnt} \cdot acc}{by arithmetic}
            \end{reasoning}
            In the second approach, we can define \texttt{M'} in a new function \texttt{M''} as follows;
            \begin{enumerate}[M\_1:]
                \itemsep0em
                \setcounter{enumi}{3}
                \item $m = cnt \rightarrow \texttt{M''}(m, cnt, acc) = (0, acc)$
                \item $m \neq cnt \land \texttt{M''}(m, cnt + 1, 2 \cdot acc) = (k, n) \rightarrow \texttt{M''}(m, cnt, acc) = (k + 1, n)$
            \end{enumerate}
            This then leads to the following;
            \smallskip

            \textbf{Assrt\_4}: $\forall s : \mathbb{N} \forall m, cnt, acc, n : \mathbb{N} [\texttt{M''}(m, cnt, acc) = (s, n) \rightarrow n = 2^{m - cnt} \cdot acc]$ - proven by induction over $s$
            \smallskip

            \textbf{Assrt\_5}: $\forall m, cnt, acc, n : \mathbb{N} [\texttt{M'}(m, cnt, acc) = n \rightarrow \texttt{M''}(m, cnt, acc) = (m - cnt, n)]$ - proven by induction over $m - cnt$ (basically, do induction over $k$ as in; $\forall k, m, cnt, acc, n : \mathbb{N} [m - cnt = k \land \texttt{M'}(m, cnt, acc) = n \rightarrow \texttt{M''}(m, cnt, acc) = (m - cnt, n)]$)
            \smallskip

            Once again, we have to then prove that the two assertions implies the original; as in $\textbf{Assrt\_4} \land \textbf{Assrt\_5} \rightarrow \textbf{Assrt\_2}$.
            \subsubsection*{Generalising the Successor}
                While it is possible to reason about functions by purely mathematical induction, it's often indirect. For example, having to do induction over $m - cnt$, in the first approach, or counting recursive depth in the second. In both mathematical, and structural induction, we want to argue that properties are inherited from an element to their successor, which means "is constructed from" (hence, \texttt{x:[]} is constructed from \texttt{[]}, or 4 is constructed from 3). If we generalise the concept of a successor to \textbf{recursively defined relations, and functions}, we can say that it means "is defined in terms of", hence, \texttt{M''}(3, 2, 4) succeeds \texttt{M''}(3, 3, 8).
                \medskip

                Generally, an inductive definition requires a finite set of "primitive" (base) cases, and a finite set of "composite" (inductive) derived cases. This inductive definition will lead to an inductive principle. Sets can be defined inductively, and relations, and functions \textbf{may} be defined inductively. The latter two can be defined in terms of a set (relations defined as the set of elements in the relation, and functions represented as a set of pairs) - if we can apply an induction to reason about elements in the sets, the induction follows for the relation, or function.
        \subsection*{Inductively Defined Sets}
            \subsubsection*{Example 1 - Natural Numbers}
                Consider the set $S_\mathbb{N}$, defined over the alphabet \texttt{Zero}, and \texttt{Succ}, with the rules;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $\texttt{Zero} \in S_\mathbb{N}$
                    \item $\forall n [n \in S_\mathbb{N} \rightarrow \texttt{Succ } n \in S_\mathbb{N}]$
                \end{enumerate}
                For example, in order to show that $\texttt{Succ Succ Succ Zero} \in S_\mathbb{N}$, we'd need to do the following;
                \begin{reasoning}
                    \proofline{1}{\texttt{Zero} \in S_\mathbb{N}}{by (R1)}
                    \proofline{2}{\texttt{Succ Zero} \in S_\mathbb{N}}{by (1), and (R2)}
                    \proofline{3}{\texttt{Succ Succ Zero} \in S_\mathbb{N}}{by (2), and (R2)}
                    \proofline{4}{\texttt{Succ Succ Succ Zero} \in S_\mathbb{N}}{by (3), and (R2)}
                \end{reasoning}
                For some property $Q \subseteq S_\mathbb{N}$, we have the primitive case \texttt{Zero}, and the composite case \texttt{Succ}; therefore it follows that the inductive principle for $Q$ is $\textcolor{blue}{Q(\texttt{Zero})} \land \textcolor{red}{\forall m \in S_\mathbb{N} [Q(m) \rightarrow Q(\texttt{Succ } m)]} \rightarrow \textcolor{violet}{\forall n \in S_\mathbb{N} [Q(n)]}$.
            \subsubsection*{Example 2 - Tree}
                Consider the set \texttt{Tree}, defined with the rules;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $i \in \mathbb{N} \rightarrow (\texttt{Leaf } i) \in \texttt{Tree}$
                    \item $\forall t1, t2 \in \texttt{Tree}, c \in \texttt{Char} [(\texttt{Node } c\ t1\ t2) \in \texttt{Tree}]$
                \end{enumerate}
                For example, to show that $(\texttt{Node } 'a'\ (\texttt{Leaf } 5)\ (\texttt{Node } 'b'\ (\texttt{Leaf } 9)\ (\texttt{Leaf } 3))) \in \texttt{Tree}$, we'd need to do the following;
                \begin{reasoning}
                    \proofline{1}{(\texttt{Leaf } 3) \in \texttt{Tree}}{by (R1), and $3 \in \mathbb{N}$}
                    \proofline{2}{(\texttt{Leaf } 9) \in \texttt{Tree}}{by (R1), and $9 \in \mathbb{N}$}
                    \proofline{3}{(\texttt{Leaf } 5) \in \texttt{Tree}}{by (R1), and $5 \in \mathbb{N}$}
                    \proofline{4}{(\texttt{Node } 'b'\ (\texttt{Leaf } 9)\ (\texttt{Leaf } 3))}{by (R2), (1), (2), and $'b' \in \texttt{Char}$}
                    \proofline{5}{(\texttt{Node } 'a'\ (\texttt{Leaf } 5)\ (\texttt{Node } 'b'\ (\texttt{Leaf } 9)\ (\texttt{Leaf } 3))) \in \texttt{Tree}}{by (R2), (3), (4), and $'a' \in \texttt{Char}$}
                \end{reasoning}
                Once again, for some property $Q \subseteq \texttt{Tree}$, we have the inductive principle; $\textcolor{blue}{\forall i \in \mathbb{N} [Q(\texttt{Leaf } i)]} \land \textcolor{red}{\forall t_1, t_2 \in \texttt{Tree} \forall c \in \texttt{Char} [Q(t_1) \land Q(t_2) \rightarrow Q(\texttt{Node } c\ t_1\ t_2)]} \rightarrow \textcolor{violet}{\forall t \in \texttt{Tree} [Q(t)]}$.
            \subsubsection*{Example 3 - Ordered List}
                Considered the set $OL \subseteq N^*$, defined with the rules;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $[] \in OL$
                    \item $\forall i \in \mathbb{N} [i : [] \in OL]$
                    \item $\forall i, j \in \mathbb{N}, js \in \mathbb{N}^* [i \leq j \land (j : js) \in OL \rightarrow i : j : js \in OL]$
                \end{enumerate}
                For some property $Q \subseteq \mathbb{N}^*$, we get the inductive principle $\textcolor{blue}{Q([])} \land \textcolor{blue}{\forall i \in \mathbb{N} [Q(i : [])]} \land \\ \textcolor{red}{\forall i, j \in \mathbb{N}, js \in \mathbb{N}^* [i \leq j \land (j : js) \in OL \land Q(j : js) \rightarrow Q(i : j : js)]} \rightarrow \textcolor{violet}{\forall ns \in OL [Q(ns)]}$.
        \subsection*{Inductively Defined Relations, and Predicates}
            \subsubsection*{Example 1 - "Strictly Less Than"}
                The predicate $SL \subseteq \mathbb{N} \times \mathbb{N}$, is defined by the rules;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $\forall k \in \mathbb{N} [SL(0, k + 1)]$
                    \item $\forall m, n \in \mathbb{N} [SL(m, n) \rightarrow SL(m + 1, n + 1)]$
                \end{enumerate}
                For some property $Q \subseteq \mathbb{N} \times \mathbb{N}$, $SL$ gives the following inductive principle; $\textcolor{blue}{\forall k \in \mathbb{N} [Q(0, k + 1)]} \rightarrow \textcolor{red}{\forall m, n \in \mathbb{N} [SL(m, n) \land Q(m, n) \rightarrow Q(m + 1, n + 1)]} \rightarrow \textcolor{violet}{\forall m, n \in \mathbb{N} [SL(m, n) \rightarrow Q(m, n)]}$
            \subsubsection*{Example 2 - Even}
                Consider the predicate $E \subseteq S_\mathbb{N}$, which is defined by;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $E(\texttt{Zero})$
                    \item $\forall n \in S_\mathbb{N} [E(n) \rightarrow E(\texttt{Succ Succ Zero})]$
                \end{enumerate}
                If we wanted to establish the property $Q \subseteq S_\mathbb{N}$, we're able to use the definition of $E$ to obtain the inductive principle; $\textcolor{blue}{Q(\texttt{Zero})} \land \textcolor{red}{\forall n \in S_\mathbb{N} [E(n) \land Q(n) \rightarrow Q(\texttt{Succ Succ } n)]} \rightarrow \textcolor{violet}{\forall n \in S_\mathbb{N} [E(n) \rightarrow Q(n)]}$.
        \subsection*{Inductively Defined Functions}
            \subsubsection*{Example 1}
                Consider the function \texttt{F}, defined in Haskell as
                \begin{lstlisting}
                    F :: Int -> Int
                    F 0 = 0
                    F i = 1 + (i - 3)
                \end{lstlisting}
                Thus, this can be described in the following rules;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $\forall i : \mathbb{Z} [i = 0 \rightarrow \texttt{F } i = 0]$
                    \item $\forall i, j : \mathbb{Z} [i \neq 0 \land \texttt{F } (i - 3) = j \rightarrow \texttt{F } i = 1 + j]$
                \end{enumerate}
                Given a predicate $Q \subseteq \mathbb{Z} \times \mathbb{Z}$, we have the following inductive principle, used to prove $\forall i, j : \mathbb{Z} [\texttt{F } i = j \rightarrow Q(i, j)]$;
                \medskip

                $\textcolor{blue}{Q(0, 0)} \land \textcolor{red}{\forall i, j : \mathbb{Z} [i \neq 0 \land \texttt{F } (i - 3) = k \land Q(i - 3, j) \rightarrow Q(i, 1 + j)]} \rightarrow \textcolor{violet}{\forall i, j : \mathbb{Z} [\texttt{F } i = j \rightarrow Q(i, j)]}$
                \medskip

                It's important to note that the function doesn't say that $\forall i : \mathbb{Z} [Q(i, \texttt{F } i)]$, since we have no guarantee of function termination. The property established is that \textbf{if} the function terminates ($\texttt{F } i = j$), then $Q(i, \texttt{F } i)$ is satisfied.
            \subsubsection*{Example 2}
                The next example works on the function \texttt{G}, defined in Haskell as;
                \begin{lstlisting}
                    G :: (Nat, Nat) -> Nat
                    G (i, j) = G' (i, j, 0, 0)

                    G' :: (Nat, Nat, Nat, Nat) -> Nat
                    G' (i, j, cnt, acc)
                      | i == cnt  = acc
                      | otherwise = G' (i, j, cnt + 1, acc + j)
                \end{lstlisting}
                Like one of our previous induction over recursive functions questions, the arguments continue to increase in size, but also the number of execution steps decreases. Once again we can define a set of rules for the aforementioned function;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $\forall i, j : \mathbb{N} [\texttt{G } (i, j) = \texttt{G' } (i, j, 0, 0)]$
                    \item $\forall i, j, acc : \mathbb{N} [\texttt{G' } (i, j, i, acc) = acc]$
                    \item $\forall i, j, cnt, acc, r : \mathbb{N} [i \neq cnt \land \texttt{G' } (i, j, cnt + 1, acc + j) = r \rightarrow \texttt{G' } (i, j, cnt, acc) = r]$
                \end{enumerate}
                The first rule establishes that $\texttt{G' } (i, j, 0, 0)$ terminates, and it has an equivalent value to $\texttt{G } (i, j)$. This can also be expressed as $\forall i, k : \mathbb{N} \exists k : \mathbb{N} [\texttt{G' } (i, j, 0, 0) = k \land \texttt{G } (i, j) = k]$
                \medskip

                If we apply the inductive principle to the predicate $Q \subseteq \mathbb{N} \times \mathbb{N} \times \mathbb{N} \times \mathbb{N} \times \mathbb{N}$, we get;
                \medskip

                $\textcolor{blue}{\forall i, j, acc : \mathbb{N} [Q(i, j, i, acc, acc)]} \land \textcolor{red}{\forall i, j, acc, cnt, r : \mathbb{N} [i \neq cnt \land } \\ \textcolor{red}{\texttt{G' } (i, j, cnt + 1, acc + j) = r \land Q(i, j, cnt + 1, acc + j, r) \rightarrow Q(i, j, cnt, acc, r)]} \rightarrow \\ \textcolor{violet}{\forall i, j, acc, cnt, r : \mathbb{N} [\texttt{G' }(i, j, cnt, acc) = r \rightarrow Q(i, j, cnt, acc, r)]}$
                \medskip

                The goal here is to prove $\forall i, j : \mathbb{N} [\texttt{G } (i, j) = i \cdot j]$. In order to prove this, we have to show $\forall i, j : \mathbb{N} \exists r : \mathbb{N} [\texttt{G' } (i, j, 0, 0) = r \land r = i \cdot j]$. However, to show this we need to show $\forall i, j : \mathbb{N} \exists r : \mathbb{N} [\texttt{G' } (i, j, 0, 0) = r]$, as well as $\forall i, j, r \in \mathbb{N} [\texttt{G' } (i, j, 0, 0) = r \rightarrow r = i \cdot j]$. In order to show this, we can show $\forall i, j, cnt, acc, n : \mathbb{N} [i - cnt = n \rightarrow \exists r : \mathbb{N} [\texttt{G' } (i, j, cnt, acc) = r]]$, and $\forall i, j, cnt, acc, r : \mathbb{N} [\texttt{G' } (i, j, cnt, acc) = r \rightarrow r = (i - cnt) \cdot j + acc]$, respectively. I have no idea why.
                \medskip

                Take the property $Q(i, j, cnt, acc, r)$ to mean $r = (i - cnt) \cdot j + acc$
                \begin{reasoning}
                    \proofbc
                    \prooftext{Our aim here is to show $\forall i, j, acc : \mathbb{N} : acc = (i - i) \cdot j + acc$}
                    \prooftext{Take arbitrary $i, j, acc : \mathbb{N}$}
                    \proofeq{acc}{0 + acc}{by arithmetic}
                    \proofeq{}{0 \cdot j + acc}{by arithmetic}
                    \proofeq{}{(i - i) \cdot j + acc}{by arithmetic}
                    \proofis
                    \prooftext{Take arbitrary $i, j, cnt, acc, r : \mathbb{N}$}
                    \proofline{\text{a}1}{i \neq cnt}{assumption, otherwise the proof is trivial}
                    \proofline{\text{a}2}{\texttt{G' } (i, j, cnt + 1, acc + j) = r}{assumption, otherwise the proof is trivial}
                    \prooftext{Inductive hypothesis: $r = (i - (cnt + 1)) \cdot j + (acc + j)$}
                    \prooftext{To show: $r = (i - cnt) \cdot j + acc$}
                    \prooftext{This is a simple proof, as the work went into creating the last property}
                    \proofeq{r}{(i - (cnt + 1)) \cdot j + (acc + j)}{by inductive hypothesis}
                    \proofeq{}{(i - cnt - 1) \cdot j + acc + j}{by arithmetic}
                    \proofeq{}{(i - cnt) \cdot j - j + acc + j}{by arithmetic}
                    \proofeq{}{(i - cnt) \cdot j + acc}{by arithmetic}
                \end{reasoning}
            \subsubsection*{Example 3}
                Consider the DivMod function, defined as $\texttt{DM} : \mathbb{Z} \times \mathbb{Z} \mapsto \mathbb{Z} \times \mathbb{Z}$, and $\texttt{DM'} : \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z} \mapsto \mathbb{Z} \times \mathbb{Z}$, which is defined in Haskell as;
                \begin{lstlisting}
                    DM :: (Int, Int) -> (Int, Int)
                    DM (i, j) = DM'(i, j, 0, 0)

                    DM' :: (Int, Int, Int, Int) -> (Int, Int)
                    DM' (i, j, cnt, acc)
                      | acc + j > i = (cnt, i - acc)
                      | otherwise   = DM' (i, j, cnt + 1, acc + j)
                \end{lstlisting}
                Once again, we're able to obtain a set of rules for this;
                \begin{enumerate}[R1]
                    \itemsep0em
                    \item $\forall i, j : \mathbb{Z} [\texttt{DM } (i, j) = \texttt{DM' } (i, j, 0, 0)]$
                    \item $\forall i, j, cnt, acc : \mathbb{Z} [acc + j > i \rightarrow \texttt{DM' } (i, j, cnt, acc) = (cnt, i - acc)]$
                    \item $\forall i, j, cnt, acc, k1, k2 : \mathbb{Z} [\texttt{DM' } (i, j, cnt + 1, acc + j) = (k1, k2) \rightarrow \texttt{DM' } (i, j, cnt, acc) = (k1, k2)]$
                \end{enumerate}
                At this point, we can spot a general pattern for functions with recursively defined helper functions. The first rule tends to establish that the original function calls the helper. The second is the non-recursive case of the helper function, and the third is in the format $\texttt{(recursive condition)} \land \texttt{(function next step)} = (k_1, k_2, ..., k_n) \rightarrow \texttt{(function current step)} = (k_1, k_2, ..., k_n)$. For some predicate $Q \subseteq \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z} \times \mathbb{Z}$, we have the following inductive principle for \texttt{DM'};
                \medskip

                $\textcolor{blue}{\forall i, j, cnt, acc : \mathbb{Z} [acc + j > i \rightarrow Q(i, j, cnt, acc, cnt, i - acc)]} \land \\ \textcolor{red}{\forall i, j, cnt, acc, k1, k2 : \mathbb{Z} [acc + j \leq i \land \texttt{DM' } (i, j, cnt + 1, acc + j) = (k1, k2) \land } \\ \textcolor{red}{ Q(i, j, cnt + 1, acc + j, k1, k2)] \rightarrow Q(i, j, cnt, acc, k1, k2)]} \rightarrow \\ \textcolor{violet}{\forall i, j, cnt, acc, k1, k2 : \mathbb{Z} [\texttt{DM' } (i, j, cnt, acc) = (k1, k2) \rightarrow Q(i, j, cnt, acc, k1, k2)]}$
                \medskip

                The goal here is to show $\forall i, j \in \mathbb{Z} [\texttt{DM } (i, j) = (k1, k2) \rightarrow i = k1 \cdot j + k2 \land k2 < j]$
        \subsection*{Conclusion to Haskell Induction}
            In conclusion, every inductively defined set, relation, or function has a successor relation. By having this successor relation, it allows for there to be an inductive principle (generic). Once this inductive principle can be specialised for a specific predicate, it gives rise for a proof schema, which can be proven with our rules of logic. By considering our \texttt{M} function, we can say the following;
            \begin{enumerate}[R1]
                \itemsep0em
                \item $\forall m : \mathbb{N} [\texttt{M } m = \texttt{M' } (m, 0, 1)]$
                \item $\forall m, cnt, acc : \mathbb{N} [m = cnt \rightarrow \texttt{M' } (m, cnt, acc) = acc]$
                \item $\forall m, cnt, acc, r : \mathbb{N} [m \neq cnt \land \texttt{M' } (m, cnt + 1, 2 \cdot acc) = r \rightarrow \texttt{M' } (m, cnt, acc)]$
            \end{enumerate}
            This allows us to derive the general inductive principle as;
            \medskip

            $\textcolor{blue}{\forall m, acc : \mathbb{N} [Q(m, m, acc, acc)]} \land \\ \textcolor{red}{\forall m, acc, cnt, r : \mathbb{N} [m \neq cnt \land \texttt{M' }(m, cnt + 1, 2 \cdot acc) = r \land Q(m, cnt + 1, 2 \cdot acc, r) \rightarrow Q(m, cnt, acc, r)]} \\ \rightarrow \textcolor{violet}{\forall m, cnt, acc, r : \mathbb{N} [\texttt{M' } (m, cnt, acc) = r \rightarrow Q(m, cnt, acc, r)]}$
            \medskip

            However, we're defining $Q(m, cnt, acc, r)$ to be $r = 2^{m - cnt} \cdot acc$, therefore we can specialise the principle to be;
            \medskip

            $\textcolor{blue}{\forall m, acc : \mathbb{N} [acc = 2^{m - m} \cdot acc]} \land \\ \textcolor{red}{\forall m, acc, cnt, r : \mathbb{N} [m \neq cnt \land \texttt{M' }(i, cnt + 1, 2 \cdot acc) = r \land r = 2^{m - (cnt + 1)} \cdot 2 \cdot acc \rightarrow r = 2^{m - cnt} \cdot acc]} \rightarrow \\ \textcolor{violet}{\forall m, cnt, acc, r : \mathbb{N} [\texttt{M' } (m, cnt, acc) = r \rightarrow r = 2^{m - cnt} \cdot acc]}$
            \medskip

            As the work went mostly into setting up the proof schema, it follows that the proof by induction here is trivial.
        \subsection*{Specifications for Java Programs}
            \subsubsection*{Sequential Specification}
                As Java isn't a functional language, it therefore has side-effects, and is therefore more difficult to reason about as we need to consider how values change.
                \medskip

                For example, consider an extremely simple Java program;
                \begin{lstlisting}
                    // PRE: a = $u$ $\land$ x = $v$
                    int y = a + x
                    // POST: a = $u$ $\land$ x = $v$ $\land$ y = $u + v$
                \end{lstlisting}
                This can be translated into the following; for any integers $u$, and $v$, if the start value of \texttt{a} is $u$, and \texttt{x} has value $v$, after executing the code, both \texttt{a}, and \texttt{x} retain their original values, and \texttt{y} now has the value $u + v$. There is an \textbf{implicit universal quantification} of $u$, and $v$ over the whole program specification. It's crucial that the quantification is over the entire specification, as having the post condition be represented as $\forall u, v [\texttt{a} = u \land \texttt{x} = v \land \texttt{y} = u + v]$ is incorrect, since that suggests \texttt{a}, and \texttt{x} holds all possible values after the code has been executed.
                \medskip

                Unsurprisingly, not all programs consist of one line, therefore we may need to reason about a sequence of state changes as follows;
                \begin{lstlisting}
                    // PRE: $P$
                    somecodeblock0
                    // MID: $P_1$
                    somecodeblock
                    // MID: $P_2$
                    somecodeblock2
                    // POST: $Q$
                \end{lstlisting}
                We can assume $P$ to show that $P_1$ holds after \texttt{somecodeblock0}, and so on. This can be expressed as a \textbf{Hoare Triple}; which is in the form $\{ P \}\ \texttt{code}\ \{ Q \}$, which means "assuming that some property $P$ holds, show that after \texttt{code} executes, $Q$ will hold". For example, we could have the Hoare triple $\{ 0 \leq \texttt{x} < 10 \}\ \texttt{x++;}\ \{0 \leq \texttt{x} \leq 10\}$.
                \smallskip

                In order to prove that example, we'd need to show $0 \leq \texttt{x}_\text{old} < 10 \land \texttt{x} = \texttt{x}_\text{old} + 1 \rightarrow 0 \leq \texttt{x} \leq 10$. It's important to note the use of $\texttt{x} = \texttt{x}_\text{old} + 1$, as if we were to naively write $\texttt{x} = \texttt{x} + 1$, we would be able to imply anything from an obvious falsity. In general, for some variable \texttt{x}, we will have \texttt{x} refer to the most recent value (which is \textbf{after} the code execution), $\texttt{x}_\text{old}$ will refer to the value \textbf{before} the code execution, and $\texttt{x}_\text{pre}$ refers to the \textbf{original} value passed in. The convention is that the annotations are only used when variables might be modified by the code.
                \medskip

                Hoare's assignment axiom is as follows;
                \unaryproof{$P[\texttt{x} \mapsto \texttt{x}_\text{old}] \land \text{x} = E[\texttt{x} \mapsto \texttt{x}_\text{old}] \rightarrow Q$}{$\{ P \}\ \texttt{x} = E;\ \{ Q \}$}
                \smallskip

                Note that $[\texttt{x} \mapsto \texttt{x}_\text{old}]$ means any occurrence of \texttt{x} is replaced with $\texttt{x}_\text{old}$.
            \subsubsection*{Method Specification}
                Consider the general layout of a method as
                \begin{lstlisting}
                    type someMethod(type x$_1$, ..., type x$_n$)
                    // PRE: $P$
                    // POST: $Q$
                    {
                    somecodeblock0
                    // MID: $R$
                    somecodeblock1
                    // MID: $S$
                    somecodeblock2
                    }
                \end{lstlisting}
                The following specification suggests that if $P[\texttt{x}_1 \mapsto v_1, ... \texttt{x}_n \mapsto v_n]$ holds before the call to \\ $\texttt{someMethod}(v_1, v_2 ..., v_n)$, then $Q[\texttt{x}_1 \mapsto v_1, ... \texttt{x}_n \mapsto v_n]$ holds on the return. Note that $v_i$ is a value, and $\texttt{x}_i$ is variable. Sometimes, this will be simplified as $\bar{\texttt{x}}$, or $\bar{v}$. The rules for the mid-conditions are the same as before.
                \medskip

                For the types of conditions, we have the following rules;
                \begin{itemize}
                    \itemsep0em
                    \item pre-condition
                        \begin{itemize}
                            \itemsep0em
                            \item required to hold before code execution
                            \item assumption the code can make
                        \end{itemize}
                    \item post-condition
                        \begin{itemize}
                            \itemsep0em
                            \item expected to hold after code execution, given it terminates and pre-condition held
                            \item guarantee the code must make
                        \end{itemize}
                    \item mid-condition
                        \begin{itemize}
                            \itemsep0em
                            \item acts as a post-condition for preceding lines, and pre-condition for subsequent lines
                            \item assumption made at specific point in code
                            \item guaranteed by preceding code
                            \item assumed by subsequent code
                            \item "stepping stone" about correctness
                            \item if it evaluates to false, it means the program cannot reach that point - often it means the mid-condition is incorrect
                        \end{itemize}
                \end{itemize}
                The following shorthands will be used in order to describe number ranges, and arrays;
                \begin{itemize}
                    \itemsep0em
                    \item $i \in (m..n) \triangleq m < i < n$
                    \item $i \in [m..n) \triangleq m \leq i < n$
                    \item $i \in (m..n] \triangleq m < i \leq n$
                    \item $i \in [m..n] \triangleq m \leq i \leq n$
                    \item $v \in \texttt{a[m..n)} \triangleq \exists i \in [m..n) [0 \leq i < \texttt{a.length} \land \texttt{a}[i] = v]$
                \end{itemize}
                $\texttt{a}(m..n)$ is referred to as an \textbf{array slice}, and closed-open intervals for slices is often useful for reasoning. We often simplify our notation by ignoring bounds if they refer to the start, or end, of an array. With some arbitrary index $i$ (existing in the array, presumably), we use the following notation;
                \begin{itemize}
                    \itemsep0em
                    \item $\texttt{a[..i)}$ \hfill the array slice from 0 up to $i$, but not including $i$
                    \item $\texttt{a[i..)}$ \hfill the array slice from $i$ up to the end
                    \item $\texttt{a[..)}$ \hfill the whole array
                    \item $\texttt{a}_\text{old/pre}\texttt{[..)}$ \hfill refers to the older / previous value of an array's reference
                    \item $\texttt{a[..)}_\text{old/pre}$ \hfill refers to the older / previous value of an array's contents
                    \item $\texttt{a}_\text{old/pre}\texttt{[..)}_\text{old/pre}$ \hfill refers to the older / previous value of both
                    \item $\texttt{a[..)} \sim \texttt{b[..)}$ \hfill \texttt{a} is a permutation of \texttt{b} (and vice versa)
                    \item $\texttt{a[..)} \approx \texttt{b[..)}$ \hfill \texttt{a}, and \texttt{b} have identical contents
                    \item $\sum \texttt{a[x..y)}$ \hfill the sum of elements from index $x$, up to (but not including) index $y$
                    \item $\prod \texttt{a[x..y)}$ \hfill the product of elements from index $x$, up to (but not including) index $y$
                \end{itemize}
                In Java, we rarely overwrite an entire array, so referencing a reference is rarely used, but we will often reference the contents of the array, as it is common for methods to be able to update contents. We also often make use of the predicates \texttt{sorted}, \texttt{min}, and \texttt{max}, which do what the name suggests. They are only well-defined for arrays with comparable contents.
                \medskip

                Consider the following function;
                \begin{lstlisting}
                    int biggest(int x, int y, int z)
                    // PRE ($P$): $\top$
                    // POST ($Q$): r = max{x, y, z}
                    {
                    int res;
                    if (x >= y) {
                        res = x;
                    } else {
                        res = y;
                    }
                    // MID ($M_1$): res = max{x, y}
                    if (z >= res) {
                        res = z;
                    }
                    // MID ($M_2$): res = max{z, max{x, y}}
                    return res;
                    }
                \end{lstlisting}
                It's important to note the mid-condition ($M_2$) in line 15, since we are describing a logical assertion, not what the code is doing. For example, writing \texttt{res = max\{res, z\}} is invalid, as it is only true when $\texttt{res} \geq \texttt{z}$, but that isn't guaranteed in the program specification, which doesn't constrain any of the input values (other than type). We also cannot write $\texttt{res = max\{}\texttt{res}_\text{old}\texttt{, z\}}$, since that is only used in our proofs - as a tool to distinguish between values at different points in code execution.
                \medskip

                With that code, we end up with the following proof obligations;
                \begin{align*}
                    P \land \texttt{if (x >= y) \{ res = x; \} else \{ res = y; \}} & \rightarrow M_1 \\
                    \top \land \texttt{res} = \texttt{max\{x, y\}} & \rightarrow \texttt{res} = \texttt{max\{x, y\}} \\ \\
                    M_1[\texttt{res} \mapsto \texttt{res}_\text{old}] \land \texttt{if (z >= res) \{ res = z; \}} & \rightarrow M_2 \\
                    \texttt{res}_\text{old} = \texttt{max\{x, y\}} \land \texttt{res} = \texttt{max\{z, }\texttt{res}_\text{old}\texttt{\}} & \rightarrow \texttt{res} = \texttt{max\{z, max\{x, y\}\}} \\ \\
                    M_2 \land \texttt{return res;} & \rightarrow Q \\
                    \texttt{res = max\{z, max\{x, y\}\}} \land \textbf{r} = \texttt{res} & \rightarrow \textbf{r} = \texttt{max\{x, y, z\}}
                \end{align*}
                Note how $M_2$ doesn't have the mapping applied, since there is no change to any of the values. It's important to note that a piece of code may have multiple pre/post-conditions, and the post-condition(s) depends on the code as well as the pre-condition(s). We can use mid-conditions as "stepping-stones" in our reasoning.
            \subsubsection*{Conditional Branches}
                Conditional branching is another construct that we will be using fairly often; as such we need to prove that branching code will still satisfy the given specification. Consider this generic example of a conditional branch;
                \begin{lstlisting}
                    // PRE: $P$
                    if (cond) {
                    code1;
                    } else {
                    code2;
                    }
                    // POST: $Q$
                \end{lstlisting}
                We can then express this as \binaryproof{$\{ P \land \texttt{cond} \}$ \texttt{code1} $\{ Q \}$}{$\{ P \land \neg\texttt{cond} \}$ \texttt{code2} $\{ Q \}$}{$\{ P \}\ \texttt{if (cond) \{ code1 \} else \{ code2 \}}\ \{ Q \}$}
                \begin{lstlisting}
                    // PRE: $P$
                    if (cond) {
                    // MID: $P \land \texttt{cond}$
                    code1;
                    // MID: $R_1$
                    } else {
                    // MID: $P \land \neg\texttt{cond}$
                    code2;
                    // MID: $R_2$
                    }
                    // POST: $Q$
                \end{lstlisting}
                Both \texttt{code1}, and \texttt{code2} can assume $P$, as well as their condition, but they \textbf{both} have to establish $Q$, (hence $R_1 \rightarrow Q$, and $R_2 \rightarrow Q$). By doing this, we can reduce the complexity of our proof by doing a case-by-case analysis, instead of having some general condition within both branches. Consider the first half of the \texttt{biggest} function that we defined previously;
                \begin{lstlisting}
                    int biggest(int x, int y, int z)
                    // PRE ($P$): $\top$
                    ...
                    {
                    int res;
                    if (x >= y) {
                        // MID ($P \land \texttt{cond}$): x $\geq$ y
                        res = x;
                        // MID ($R_1$): res = x $\land$ x $\geq$ y
                    } else {
                        // MID ($P \land \neg\texttt{cond}$): y $>$ x
                        res = y;
                        // MID ($R_2$): res = y $\land$ y $>$ x
                    }
                    // MID ($M_1$): res = max{x, y}
                    ...
                    }
                \end{lstlisting}
                \begin{align*}
                    P \land \texttt{cond} \land \texttt{res = x;} & \rightarrow R_1 \\
                    \texttt{x} \geq \texttt{y} \land \texttt{res} = \texttt{x} & \rightarrow \texttt{res} = \texttt{x} \land \texttt{x} \geq \texttt{y} \\ \\
                    P \land \neg\texttt{cond} \land \texttt{res = y;} & \rightarrow R_2 \\
                    \texttt{y} > \texttt{x} \land \texttt{res} = \texttt{y} & \rightarrow \texttt{res} = \texttt{y} \land \texttt{y} > \texttt{x} \\ \\
                    R_1 & \rightarrow M_1 \\
                    \texttt{res} = \texttt{x} \land \texttt{x} \geq \texttt{y} & \rightarrow \texttt{res} = \texttt{max\{x, y\}} \\ \\
                    R_2 & \rightarrow M_1 \\
                    \texttt{res} = \texttt{y} \land \texttt{y} > \texttt{x} & \rightarrow \texttt{res} = \texttt{max\{x, y\}}
                \end{align*}
                While this complicates the proof obligations in this case, sometimes the conditional branches may be significantly different from each other.
            \subsubsection*{Method Calls}
                Consider the following methods here;
                \begin{lstlisting}
                    void mainMethod() {
                    ...
                    // MID: $P$
                    someMethod($v_1$, ..., $v_n$);
                    // MID: $Q$
                    }
                    void someMethod(type x$_1$, ..., type x$_n$)
                    // PRE: $R$
                    // POST: $S$
                    {
                    code
                    }
                \end{lstlisting}
                The first requirement is to show that $P \rightarrow R[\bar{\texttt{x}} \mapsto \bar{v}]$, once that's proven, we can apply the method as;
                \smallskip

                \unaryproof{$P[\bar{v}[..) \mapsto \bar{v}[..)_\text{old}] \land S[\bar{\texttt{x}} \mapsto \bar{v}, \bar{\texttt{x}}\texttt{[..)}_\text{pre} \mapsto \bar{v}[..)_\text{old}] \rightarrow Q$}{$\{ P \}\ \texttt{someMethod($v_1$, ..., $v_n$)}\ \{ Q \}$}
                \medskip

                The substitutions done in $R$, and $S$ replace the variables in the method specification with the values used at the call point in our code. The second substitution in $S$, and the substitution in $P$ consider the (possibly) updated program state caused by \texttt{someMethod}. Care should be taken with post-condition belonging to \texttt{someMethod}, as a reference to $\texttt{a[..)}_\text{pre}$ would refer to the contents of the array before the method was called. Since Java is a call by value language, variables of primitive type aren't updated by the method call. However, when we pass variables of reference type (such as the array in this context), the contents \textbf{can} be updated.
                \medskip

                If we consider return values from a method, such that we can change the code to be the following;
                \begin{lstlisting}
                    void mainMethod() {
                    ...
                    // MID: $P$
                    res = someMethod($v_1$, ..., $v_n$);
                    // MID: $Q$
                    }
                    type someMethod(type x$_1$, ..., type x$_n$) {
                    ...
                \end{lstlisting}
                We need to be careful with the modification of \texttt{res}. Once again, the pre-condition of \texttt{someMethod} still needs to be satisfied in the same way, but we will also need additional substitutions as follows;
                \smallskip

                \unaryproof{$P[\bar{v}[..) \mapsto \bar{v}[..)_\text{old}]\textcolor{blue}{[\texttt{res} \mapsto \texttt{res}_\text{old}]} \land \textcolor{blue}{\texttt{res} = \mathbf{r}} \land S[\bar{\texttt{x}} \mapsto \bar{v}, \bar{\texttt{x}}\texttt{[..)}_\text{pre} \mapsto \bar{v}[..)_\text{old}]\textcolor{blue}{[\texttt{res} \mapsto \texttt{res}_\text{old}]} \rightarrow Q$}{$\{ P \}\ \texttt{\textcolor{blue}{res} = someMethod($v_1$, ..., $v_n$)}\ \{ Q \}$}
                \medskip

                Note that the substitution is after every other substitution, since it's needed to reflect the order of the code execution. The rest of the rules are the same as before, except the extra conjuncts account for the updating program state due to the assignment of the return value.
                \medskip

                Consider an example, where we get the smallest value of a list by taking the first item of the sorted version of the given list, with the code in Java being defined as follows;
                \begin{lstlisting}
                    void sort(int[] b)
                    // PRE ($P_1$): b $\neq$ null
                    // POST ($Q_1$): b[..) $\sim$ b[..)$_\text{pre}$ $\land$ sorted(b[..))
                    {
                    ...
                    }

                    int smallest(int[] a)
                    // PRE ($P_2$): a $\neq$ null $\land$ a.length $>$ 0
                    // POST ($Q_2$): r = min(a[..)$_\text{pre}$)
                    {
                    // MID ($M_1$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ a $\neq$ null $\land$ a.length $>$ 0
                    sort(a);
                    // MID ($M_2$): a[..) $\sim$ a[..)$_\text{pre}$ $\land$ sorted(a[..)) $\land$ a.length $>$ 0
                    int res = a[0];
                    // MID ($M_3$): a[..) $\sim$ a[..)$_\text{pre}$ $\land$ res = min(a[..))
                    return res;
                    }
                \end{lstlisting}
                Informally (and formally below), the obligations are as follows;
                \begin{itemize}
                    \itemsep0em
                    \item $P_2[\texttt{a[..)} \mapsto \texttt{a[..)}_\text{pre}] \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \rightarrow M_1$
                        \subitem $\texttt{a} \neq \texttt{null} \land \texttt{a.length} > 0 \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land \texttt{a.length} > 0$
                        \subitem here we should remember that $P_2$ only describes the variables passed into the initial method call - to use this pre-condition, we need to use the initial $_\text{pre}$ versions of all variables; we also obtain the 3$^\text{rd}$ conjunct implicitly because no code has executed yet
                    \item $M_1 \rightarrow P_1[\texttt{b} \mapsto \texttt{a}]$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land \texttt{a.length} > 0 \rightarrow \texttt{a} \neq \texttt{null}$
                        \subitem no code has been executed in this obligation, therefore we don't need to consider the $_\text{old}$ variants - however we do need to substitute \texttt{b} with \texttt{a} in $P_1$
                    \item $M_1[\texttt{a[..)} \mapsto \texttt{a[..)}_\text{old}] \land Q_1[\texttt{b} \mapsto \texttt{a}, \texttt{b[..)}_\text{pre} \mapsto \texttt{a[..)}_\text{old}] \rightarrow M_2$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land \texttt{a.length} > 0 \land \texttt{a[..)} \sim \texttt{a[..)}_\text{old} \land \texttt{sorted(a[..))} \rightarrow \texttt{a[..)} \sim \texttt{a[..)}_\text{pre} \land \texttt{sorted(a[..))} \land \texttt{a.length} > 0$
                        \subitem this obligation considers the effect of the \texttt{sort} method, therefore we need to track the state of the input before and after \texttt{sort} is called - once again \texttt{b} is replaced with \texttt{a}, and we use the state \texttt{b[..)}$_\text{pre}$ to represent the state of the array on entry to \texttt{sort}, and \texttt{a[..)}$_\text{old}$ to represent the value just before the method call therefore \texttt{b[..)}$_\text{pre}$ is replaced with \texttt{a[..)}$_\text{old}$ in $Q_2$
                    \item $M_2[\texttt{res} \mapsto \texttt{res}_\text{old}] \land \texttt{res = a[0]} \rightarrow M_3$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a.length} > 0 \land \texttt{a[..)} \sim \texttt{a[..)}_\text{old} \land \texttt{sorted(a[..))} \land \texttt{res = a[0]} \rightarrow \texttt{a[..)}_\text{pre} \land \texttt{res = min(a[..))}$
                        \subitem because \texttt{res} didn't exist before the previous line, and $M_2$ makes no reference to \texttt{res}, the substitution makes no change to $M_2$
                    \item $M_3 \land \texttt{return res} \rightarrow Q_2$
                        \subitem $\texttt{a[..)} \sim \texttt{a[..)}_\text{pre} \land \texttt{res = min(a[..))} \land \textbf{r} = \texttt{res} \rightarrow \textbf{r} = \texttt{min(a[..))}$
                        \subitem no changes are done to any of the variables, since it only tracks the return value, there is no need to track old values in the program's state
                \end{itemize}
                While we've reasoned about the correctness of \texttt{smallest}, we don't know anything about \texttt{sort}. All we have done regarding it is that it satisfies its given specification. For code to be partially correct, it requires the code to satisfy the post-condition given it starts in a state satisfying its pre-condition, and terminates. Total correctness is the same, but guarantees the termination of the code.
            \subsubsection*{Recursion}
                The techniques required for recursion are the same as the ones we've already visited for reasoning regarding method calls. Like we did in reasoning, we assume that the method specifications hold for anything called within the body (even if we haven't proven it). The example this works on is a recursive method for summing an array;
                \begin{lstlisting}
                    int sum(int[] a)
                    // PRE ($P_1$): a $\neq$ null
                    // POST ($Q_1$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ r = $\sum$a[..)
                    {
                      int res = sumAux(a, 0);
                      // MID ($M_1$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ res = $\sum$a[..)
                      return res;
                    }

                    int sumAux(int[] a, int i)
                    // PRE ($P_2$): a $\neq$ null $\land$ 0 $\leq$ i $\leq$ a.length
                    // POST ($Q_2$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ r = $\sum$a[i..)
                    {
                      if (i == a.length) {
                        // MID ($M_2$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ i = a.length
                        return 0;
                      } else {
                        // MID ($M_3$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ a $\neq$ null $\land$ 0 $\leq$ i $<$ a.length
                        int val = a[i] + sumAux(a, i + 1);
                        // MID ($M_4$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ val = $\sum$a[i..)
                        return val;
                      }
                    }
                \end{lstlisting}
                Once again, due to modular verification, we can verify the correctness of \texttt{sum}, and \texttt{sumAux} independently of each other. The reasoning for \texttt{sum} is much simpler, since we're treating \texttt{sumAux} as a black-box that just works;
                \begin{itemize}
                    \itemsep0em
                    \item $P_1 \rightarrow P_2[\texttt{i} \mapsto 0]$
                        \subitem $\texttt{a} \neq \texttt{null} \rightarrow \texttt{a} \neq \texttt{null} \land 0 \leq 0 \leq \texttt{a.length}$
                        \subitem since there's no reference to the contents of the array in either of the preconditions, and no code has actually run, all that is required in this step is to substitute the call value for \texttt{sumAux}
                    \item $P_1 \land Q_2[\texttt{a[..)}_\text{pre} \mapsto \texttt{a[..)}_\text{old}, \texttt{i} \mapsto 0] \land \texttt{a[..)}_\text{old} \approx \texttt{a[..)}_\text{pre} \land \texttt{res} = \textbf{r} \rightarrow M_1$
                        \subitem $\texttt{a} \neq \texttt{null} \land \texttt{a[..)} \approx \texttt{a[..)}_\text{old} \land \textbf{r} = \sum \texttt{a[..)} \land \texttt{a[..)}_\text{old} \approx \texttt{a[..)}_\text{pre} \land \texttt{res} = \textbf{r} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{res} = \sum \texttt{a[..)}$
                        \subitem any potential updates to \texttt{a} from \texttt{sumAux} needs to be carefully tracked, which means we need to differentiate between the contents passed in (\texttt{a[..)}$_\text{old}$), from the initial contents (\texttt{a[..)}$_\text{pre}$), and the current ones (\texttt{a[..)})
                        \subitem however, we can see that the contents are not modified before the \texttt{sumAux} call therefore we can write, implicitly, $\texttt{a[..)}_\text{old} \approx \texttt{a[..)}_\text{pre}$
                    \item $M_1 \land \textbf{r} = \texttt{res} \rightarrow Q_1$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{res} = \sum \texttt{a[..)} \land \textbf{r} = \texttt{res} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \textbf{r} = \sum \texttt{a[..)}$
                \end{itemize}
                However, reasoning about \texttt{sumAux} is slightly more complex due to the requirement of handling the recursive calls. The formal proof obligations are as follows;
                \begin{itemize}
                    \item $P_2 \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} = \texttt{a.length} \rightarrow M_2$
                        \subitem $\texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} \leq \texttt{a.length} \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} = \texttt{a.length} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} = \texttt{a.length}$
                        \subitem there's no reference to the array contents in $P_2$, and implicitly there is no modification to the array from the code
                    \item $M_2 \land \textbf{r} = 0 \rightarrow Q_2$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} = \texttt{a.length} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \textbf{r} = \sum \texttt{a[i..)}$
                        \subitem this utilises the property $\forall k [\sum \texttt{a[}k\texttt{..}\texttt{)} = 0]$
                        \subitem we know that the array exists, since we have a value for the length of it, and proving \textbf{r} is trivial due to the property regarding the sum of an empty range
                    \item $P_3 \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} \neq \texttt{a.length} \rightarrow M_3$
                        \subitem $\texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} \leq \texttt{a.length} \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{i} \neq \texttt{a.length} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} < \texttt{a.length}$
                    \item $M_3 \rightarrow P_2[\texttt{i} \mapsto \texttt{i} + 1]$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} < \texttt{a.length} \rightarrow \texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} + 1 \leq \texttt{a.length}$
                    \item $M_3[\texttt{a[..)} \mapsto \texttt{a[..)}_\text{old}] \land Q_2[\texttt{a[..)}_\text{pre} \mapsto \texttt{a[..)}_\text{old}, \texttt{i} \mapsto \texttt{i} + 1] \land \texttt{val} = \texttt{a[i]}_\text{old} + \textbf{r} \rightarrow M_4$
                        \subitem $\texttt{a[..)}_\text{old} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} < \texttt{a.length} \land \texttt{a[..)} \approx \texttt{a[..)}_\text{old} \land \textbf{r} = \sum \texttt{a[i+1..)} \land \texttt{val} = \texttt{a[i]}_\text{old} + \textbf{r} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{val} = \sum \texttt{a[..)}$
                        \subitem the range for \texttt{i} is required, to ensure that the array access is legal
                    \item $M_4 \land \textbf{r} = \texttt{val} \rightarrow Q_2$
                        \subitem $\texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{val} = \sum \texttt{a[..)} \land \textbf{r} = \texttt{val} \rightarrow \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \textbf{r} = \sum \texttt{a[..)}$
                \end{itemize}
                For obvious reasons, reasoning regarding recursive functions in Java resembles reasoning about recursively defined functions in Haskell. Reasoning about the when the function terminates corresponds to proving the bases cases in Haskell, and the inductive steps are reasoning about when the function calls itself. Establishing the inductive hypothesis holds corresponds to the point where we establish the pre-condition of the callee holds, and the point where we establish the post-condition implying the mid-condition mirrors the conclusion of the inductive step.
            \subsubsection*{Iteration (Informal)}
                The final programming construct we'll be reasoning about in this course is iteration. Since the common loop blocks; \texttt{while}, \texttt{for}, and \texttt{repeat-until} can all be expressed as \texttt{while} loops, it follows that we can focus solely on that. For example, the following \texttt{for} loop can be expressed as a \texttt{while} loop;
                \begin{lstlisting}
                    // FOR LOOP
                    for (int i = 0; i < a.length; i++) {
                      res = res + a[i];
                    }

                    // WHILE LOOP
                    int i = 0;
                    while (i < a.length) {
                      res = res + a[i];
                      i++;
                    }
                \end{lstlisting}
                In general, we can summrise the structure of a \texttt{while} loop as follows;
                \begin{lstlisting}
                    while (cond) { // condition
                      somecode // loop body
                    }
                    // MID: $M$ - summarises effect of a loop
                \end{lstlisting}
                For example, consider the \texttt{sum} function we created earlier, but define it with iteration instead of recursion;
                \begin{lstlisting}
                    int sum(int[] a)
                    // PRE ($P$): a $\neq$ null
                    // POST ($Q$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ r = $\sum$a[..)
                    {
                      int res = 0;
                      int i = 0;
                      // INV ($I$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ a $\neq$ null $\land$ 0 $\leq$ i $\leq$ a.length $\land$ res = $\sum$a[..i)
                      while (i < a.length) { (cond)
                        res = res + a[i];
                        i++;
                        // MID: $\rightarrow I$
                      }
                      // MID ($M$): a[..) $\approx$ a[..)$_\text{pre}$ $\land$ res = $\sum$a[..)
                      return res;
                    }
                \end{lstlisting}
                Consider a property $P$, which satisfies the following conditions; $\forall n \in \mathbb{N} [P \text{ holds after } n \text{ iterations}]$, and $P \land \neg\texttt{cond} \rightarrow M$ (such that if $P$ holds, and the loop condition doesn't, it reaches the mid-condition directly \textbf{outside} the loop). This property is called the invariant. This invariant generalises the effect of the loop, on some arbitrary number of iterations. Therefore we no longer need to track the mid-condtions before, after, or during the loop. However, we will still write a mid-condition after the loop, as it's more convenient to do so, and then use that to construct our invariant.
                \medskip

                There's a similarity between the first requirement of the loop invariant, and the induction principle. In order to show that $P$ holds after $n$ iterations, where $n$ is an arbitrary natural number, we need to show that $P$ holds after no iterations ($n = 0$), hence $P$ holds before the loop, as well as showing that if $P$ holds after $k$ iterations, it implies that it holds after $k + 1$ iterations. The latter means that if both $P$, and \texttt{cond} hold, and after the execution of the loop body, $P$ will still hold. Note that normally line 11 wouldn't be written, but it's there to show that the invariant is reestablished after the execution of the loop body. The following predicates are defined as follows;
                \begin{align*}
                    I & \triangleq \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{a} \neq \texttt{null} \land 0 \leq \texttt{i} \leq \texttt{a.length} \land \texttt{res} = \sum \texttt{a[..i)} \\
                    \texttt{cond} & \triangleq \texttt{i} < \texttt{a.length} \\
                    M & \triangleq \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \land \texttt{res} = \sum \texttt{a[..)}
                \end{align*}
                This therefore comes with the following proof obligations - the code right before the loop must establish $I$, the body of the loop must show that $I$ holds, as long as \texttt{cond} holds, and finally $I \land \neg \texttt{cond} \rightarrow M$, immediately after the loop. For us to be able to reason about the behaviour of the loop, we need the invariant to hold at the start, and end, of every iteration (including the before we run the loop body for the first time, and after we run it for the final time). As such, these are the proofs we have to do;
                \begin{itemize}
                    \itemsep0em
                    \item $P \land \texttt{res} = 0 \land \texttt{i} = 0 \land \texttt{a[..)} \approx \texttt{a[..)}_\text{pre} \rightarrow I$
                        \subitem here, we can assume the pre-condition, and list the explicit effects of the code (the variable declaration), as well as the implicit effects (the array not being modified)
                    \item $I[\texttt{a[..)} \mapsto \texttt{a[..)}_\text{old}, \texttt{i} \mapsto \texttt{i}_\text{old}, \texttt{res} \mapsto \texttt{res}_\text{old}] \land \texttt{i}_\text{old} < \texttt{a.length} \land \texttt{res} = \texttt{res}_\text{old} + \texttt{a[i]}_\text{old} \land \texttt{i} = \texttt{i}_\text{old} + 1 \land \texttt{a[..)} \approx \texttt{a[..)}_\text{old} \rightarrow I$
                        \subitem since the loop body potentially changes the states, all of the program variables are tracked in our invariant
                    \item $I \land \texttt{i} \geq \texttt{a.length} \rightarrow M$
                        \subitem since no code is being executed, there's no need to differentiate between the current, and older values of our program state
                \end{itemize}
                However, we currently have no way of tracking the progress of our iteration. This means we need to find some integer expression, called the \textbf{variant}, which is larger than some value after the loop body is executed, and decreases in every iteration. If this holds, then the loop will terminate, in our case, the variant would be \texttt{a.length - i}. The invariant lets us know that the program execution is going as planned, as long as the loop body maintains its validtiy. However, the variant measures the progress of the iteration, therfore by proving the variant is bounded, and decreasing every iteration, we can use the invariant to prove the mid-condition.
                \medskip

                In general, to help us design an invariant, we should represent the state of the program at the beginning of each loop iteration as a diagram. The post-condition should be used to find a mid-condition after the loop, and this mid-condition (along with the loop condition) should be used to help find the invariant.
            \subsubsection*{Iteration (Formal)}
                Consider the general form of a loop as;
                \begin{lstlisting}
                    // PRE: $P$
                    // INV: $I$
                    // VAR: $V$
                    while (cond) {
                      body
                    }
                    // MID: $M$
                    // POST: $Q$
                \end{lstlisting}
                The Hoare logic rule displayed below captures \textbf{partial} correctness, and imposes the three proof obligations on the top line.
                \smallskip

                \trinaryproof{$P \rightarrow I$}{$\{ I \land \texttt{cond} \}\ \texttt{body}\ \{ I \}$}{$I \land \neg \texttt{cond} \rightarrow Q$}{$\{ P \}\ \texttt{while (cond) \{ body \}}\ \{ Q \}$}
                \smallskip

                In order for partial correctness to hold, we need the following;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item $I$ holds before the loop is entered
                    \item the loop body re-establishes $I$, if the condition holds
                    \item termination of the loop, and $I$, imply the mid-condition $M$
                \end{enumerate}
                Total correctness needs the above, as well as;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \setcounter{enumi}{3}
                    \item $V$ is bounded
                        \subitem $\exists c \in \mathbb{Z} [\{I \land \texttt{cond}\}\ \texttt{body}\ \{V \geq c\}]$
                        \subitem note that $c$ represents a lower-bound for $V$, since it is decreasing
                        \subitem generally any well-founded ordering with a limit works, but we will mainly look for an integer expression with a fixed lower bound (normally 0 in our cases)
                    \item $V$ decreases with each iteration
                        \subitem $\{I \land \texttt{cond}\}\ \texttt{body}\ \{V_\text{old} > V\}$
                        \subitem note that $V_\text{old}$ here is the value of $V$ before running \texttt{body}
                        \subitem this obligation requires us to prove the variant decreases towards $c$ on \textbf{every} iteration
                \end{enumerate}
                In order to prove $\{ I \land \texttt{cond} \}\ \texttt{body}\ \{ I \}$, we are required to show $I[\overline{\texttt{mod}} \mapsto \overline{\texttt{mod}}_\text{old}] \land \texttt{cond}[\overline{\texttt{mod}} \mapsto \overline{\texttt{mod}}_\text{old}] \land \texttt{body-effect} \rightarrow I$. Note that here, $\overline{\texttt{mod}}$ represents all the variables that ae modified by \texttt{body}.
                \medskip

                Consider the following example, represented by the code below;
                \begin{lstlisting}
                    int culSum(int[] a)
                    // PRE ($P$): a $\neq$ null
                    // POST ($Q$): r = $\sum$a[..)$_\text{pre}$ $\land$ $\forall \texttt{k} \in [0..\texttt{a.length}) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]$
                    {
                      // MID ($M_0$): a $\neq$ null $\land$ a[..) $\approx$ a[..)$_\text{pre}$
                      int res = 0;
                      int i = 0;
                      // INV ($I$): a $\neq$ null $\land$ 0 $\leq$ i $\leq$ a.length $\land$ a[i..) $\approx$ a[i..)$_\text{pre}$ $\land$ res = $\sum$a[..i)$_\text{pre}$ $\land$ $\forall \texttt{k} \in [0..\texttt{i}) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]$
                      // VAR ($V$): a.length - i
                      while (i < a.length) {
                        res = res + a[i];
                        a[i] = res;
                        i++;
                      }
                      // MID ($M$): res = $\sum$a[..)$_\text{pre}$ $\land$ $\forall \texttt{k} \in [0..\texttt{a.length}) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]$
                      return res;
                    }
                \end{lstlisting}
                This function also calculates the sum of an array, however it replaces each element of an array with the cumulative sum up to that point. Since this doesn't modify \texttt{a}, as Java is call by value, we don't need to track changes to \texttt{a}, or \texttt{a.length}. The entire proof is as follows;
                \begin{reasoning}
                    \prooftext{\textbf{Invariant holds before loop entry}}
                    \prooftext{Given:}
                    \proofline{1}{\texttt{a} \neq \texttt{null}}{from $M_0$}
                    \proofline{2}{\texttt{a[..)} _\text{old} \approx \texttt{a[..)}_\text{pre}}{from $M_0$}
                    \proofline{3}{\texttt{res} = 0}{code line 6}
                    \proofline{4}{\texttt{i} = 0}{code line 7}
                    \proofline{5}{\texttt{a[..)} \approx \texttt{a[..)}_\text{old}}{implciit from code}
                    \prooftext{To show:}
                    \proofline{\alpha}{\texttt{a} \neq \texttt{null}}{$I$}
                    \proofline{\beta}{0 \leq \texttt{i} \leq \texttt{a.length}}{$I$}
                    \proofline{\gamma}{\texttt{a[i..)} \approx \texttt{a[i..)}_\text{pre}}{$I$}
                    \proofline{\delta}{\texttt{res} = \sum \texttt{a[..i)}_\text{pre}}{$I$}
                    \proofline{\epsilon}{\forall \texttt{k} \in [0..\texttt{i}) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]}{$I$}
                    \prooftext{Proof:}
                    \proofline{\alpha}{}{follows immediately from (1)}
                    \proofline{6}{0 \leq 0 \leq \texttt{a.length}}{from (1)}
                    \proofline{\beta}{}{follows from (4), and (6)}
                    \proofline{7}{\texttt{a[..)} \approx \texttt{a[..)}_\text{pre}}{from (2), and (5)}
                    \proofline{8}{\texttt{a[0..)} \approx \texttt{a[0..)}_\text{pre}}{from (7), and def. of \texttt{a[..)}}
                    \proofline{\gamma}{}{follows from (4), and (8)}
                    \proofline{9}{\sum \texttt{a[..0)}_\text{pre} = 0}{from def. of $\sum$}
                    \proofline{10}{\sum \texttt{a[..i)}_\text{pre} = 0}{from (4), and (9)}
                    \proofline{\delta}{}{follows from (3), and (10)}
                    \proofline{11}{\forall \texttt{k} \in [0..0) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]}{from empty range}
                    \proofline{\epsilon}{}{follows from (4), and (11)}
                    \prooftext{\textbf{Loop body re-establishes invariant}}
                    \prooftext{Given:}
                    \proofline{1}{\texttt{a} \neq \texttt{null}}{$I$}
                    \proofline{2}{0 \leq \texttt{i}_\text{old} \leq \texttt{a.length}}{$I$}
                    \proofline{3}{\texttt{a[i}_\text{old}\texttt{..)}_\text{old} \approx \texttt{a[i}_\text{old}\texttt{..)}_\text{pre}}{$I$}
                    \proofline{4}{\texttt{res} = \sum  \texttt{a[..i}_\text{old}\texttt{)}_\text{pre}}{$I$}
                    \proofline{5}{\forall \texttt{k} \in [0..\texttt{i}_\text{old}) [\texttt{a[k]}_\text{old} = \sum \texttt{a[..k+1)}_\text{pre}]}{$I$}
                    \proofline{6}{\texttt{i}_\text{old} < \texttt{a.length}}{\texttt{cond}}
                    \proofline{7}{\texttt{res} = \texttt{res}_\text{old} + \texttt{a[i}_\text{old}\texttt{]}_\text{old}}{code line 12}
                    \proofline{8}{\texttt{a[i}_\text{old}\texttt{]} = \texttt{res}}{code line 13}
                    \proofline{9}{\texttt{i} = \texttt{i}_\text{old} + 1}{code line 14}
                    \proofline{10}{\texttt{a[..)} \approx \texttt{a[..i}_\text{old}\texttt{)}_\text{old} ++ \texttt{a[i}_\text{old}\texttt{]} ++ \texttt{a[i}_\text{old}\texttt{+1..)}_\text{old}}{implciit from code}
                    \prooftext{To show:}
                    \proofline{\alpha}{\texttt{a} \neq \texttt{null}}{$I$}
                    \proofline{\beta}{0 \leq \texttt{i} \leq \texttt{a.length}}{$I$}
                    \proofline{\gamma}{\texttt{a[i..)} \approx \texttt{a[i..)}_\text{pre}}{$I$}
                    \proofline{\delta}{\texttt{res} = \sum \texttt{a[..i)}_\text{pre}}{$I$}
                    \proofline{\epsilon}{\forall \texttt{k} \in [0..\texttt{i}) [\texttt{a[k]} = \sum \texttt{a[..k+1)}_\text{pre}]}{$I$}
                \end{reasoning}
\end{document}