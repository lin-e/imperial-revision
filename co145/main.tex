\documentclass[a4paper, 12pt]{article}
% packages
\usepackage{amssymb}
\usepackage[fleqn]{mathtools}
\usepackage{tikz}
\usepackage{enumerate}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\usepackage{logicproof}
\usepackage{diagbox}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{lstautogobble}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{stmaryrd}
\usetikzlibrary{arrows, shapes.gates.logic.US, circuits.logic.US, calc, automata, positioning}

% shorthand for verbatim
% \catcode`~=\active
% \def~#1~{\texttt{#1}}

% code listing
\lstdefinestyle{main}{
    numberstyle=\tiny,
    breaklines=true,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    numbers=left,
    basicstyle=\ttfamily,
    columns=fixed,
    fontadjust=true,
    basewidth=0.5em,
    autogobble,
    xleftmargin=3.0ex,
    mathescape=true
}
\newcommand{\dollar}{\mbox{\textdollar}} %
\lstset{style=main}

% augmented matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
\hskip -\arraycolsep
\let\@ifnextchar\new@ifnextchar
\array{#1}}
\makeatother

% ceiling / floor
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

% custom commands
\newcommand{\indefint}[2]{\int #1 \, \mathrm{d}#2}
\newcommand{\defint}[4]{\int_{#1}^{#2} #3 \, \mathrm{d}#4}
\newcommand{\dif}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\limit}[2]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle{\lim_{#1 \to #2}}$}}}
\newcommand{\summation}[3]{\sum\limits_{#1}^{#2} #3}
% \newcommand{\summation}[3]{\raisebox{0.5ex}{\scalebox{0.5}{$\displaystyle{\sum\limits_{#1}^{#2} #3}$}}}
\newcommand{\intbracket}[3]{\left[#3\right]_{#1}^{#2}}
\newcommand{\ulsmash}[1]{\underline{\smash{#1}}}

\newcommand{\powerset}[0]{\wp}
\renewcommand{\emptyset}[0]{\varnothing}
\newcommand{\la}[0]{\langle}
\newcommand{\ra}[0]{\rangle}

\newcommand{\unaryproof}[2]{\AxiomC{#1} \UnaryInfC{#2} \DisplayProof}
\newcommand{\binaryproof}[3]{\AxiomC{#1} \AxiomC{#2} \BinaryInfC{#3} \DisplayProof}
\newcommand{\trinaryproof}[4]{\AxiomC{#1} \AxiomC{#2} \AxiomC{#3} \TrinaryInfC{#4} \DisplayProof}

% no indent
\setlength\parindent{0pt}
\setlength\itemsep{0em}

% reasoning proofs
\usepackage{ltablex}
\usepackage{environ}
\keepXColumns
\NewEnviron{reasoning}{
    \begin{tabularx}{\textwidth}{rlX}
        \BODY
    \end{tabularx}
}
\newcommand{\proofline}[3]{$(#1)$ & $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofarbitrary}[1]{& take arbitrary $#1$ \smallskip \\}
\newcommand{\prooftext}[1]{\multicolumn{3}{l}{#1} \smallskip \\}
\newcommand{\proofmath}[3]{$#1$ & = $#2$ & \hfill #3 \smallskip \\}
\newcommand{\proofiff}[3]{$#1$ & $\Leftrightarrow$ $#2$ & \hfill #3 \smallskip \\}
\newcommand{\prooftherefore}[1]{& $\therefore #1$ \smallskip \\}
\newcommand{\proofbc}[0]{\prooftext{\textbf{Base Case}}}
\newcommand{\proofis}[0]{\prooftext{\textbf{Inductive Step}}}

% reasoning er diagrams
\newcommand{\nattribute}[4]{
    \node[draw, state, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\mattribute}[4]{
    \node[draw, state, accepting, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\dattribute}[4]{
    \node[draw, state, dashed, inner sep=0cm, minimum size=0.2cm, label=#3:{#4}] (#1) at (#2) {};
}
\newcommand{\entity}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 0.5)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -0.5)$) {};
    \draw
    ($(#1-c) + (-1, 0.5)$) -- ($(#1-c) + (1, 0.5)$) -- ($(#1-c) + (1, -0.5)$) -- ($(#1-c) + (-1, -0.5)$) -- cycle;
}
\newcommand{\relationship}[3]{
    \node[] (#1-c) at (#2) {#3};
    \node[inner sep=0cm] (#1-l) at ($(#1-c) + (-1, 0)$) {};
    \node[inner sep=0cm] (#1-r) at ($(#1-c) + (1, 0)$) {};
    \node[inner sep=0cm] (#1-u) at ($(#1-c) + (0, 1)$) {};
    \node[inner sep=0cm] (#1-d) at ($(#1-c) + (0, -1)$) {};
    \draw
    ($(#1-c) + (-1, 0)$) -- ($(#1-c) + (0, 1)$) -- ($(#1-c) + (1, 0)$) -- ($(#1-c) + (0, -1)$) -- cycle;
}

% actual document
\begin{document}
    \section*{CO145 - Mathematical Methods}
        \subsection*{Prelude}
            The content discussed here is part of CO145 - Mathematical Methods (Computing MEng); taught by Michael Huth, and Mario Berta, in Imperial College London during the academic year 2018/19. The notes are written for my personal use, and have no guarantee of being correct (although I hope it is, for my own sake). This should be used in conjunction with the lecture notes. This module differs as there isn't as much new content, but it requires practice - as such, I will likely be including worked examples for my own benefit (which are probably incorrect).
        \subsection*{Sequences}
            \subsubsection*{Formal Definition of a Limit}
                A sequence $a_n$, for $n \geq 1$, converges to some limit $l \in \mathbb{R}$ if, and only if, we can prove $\forall \epsilon > 0 [\exists N_\epsilon \in \mathbb{N} [\forall n > N_\epsilon [|a_n - l| < \epsilon]]]$.
                \medskip

                To show convergence for the sequence $a_n = \frac{1}{n}$, we need to first make a guess for the limit - suppose $l = 0$. We can now attempt to find some $N_\epsilon$. As $\frac{1}{n} - 0$ is positive for all $n \in \mathbb{N}$, we can drop the absolute, thus it's sufficient to find $n$ such that $\frac{1}{n} < \epsilon$. Since both are positive (hence non-zero), we can take reciprocals on both sides, to get $n > \frac{1}{\epsilon}$. However, we are restricted by the fact that $n$ must be an integer, hence it follows $N_\epsilon = \ceil{\frac{1}{\epsilon}}$. For any value of $\epsilon$, we can get some $N_\epsilon$ with the function, thus it proves that a limit exists.
            \subsubsection*{Common Converging Sequences}
                Note that for all of these, we are imiplicity saying $\limit{n}{\infty}$, and that $a_n \to 0$.
                \begin{center}
                    \begin{tabular}{l|l|c}
                        $a_n$ & condition & $N_\epsilon$ \\
                        \hline
                        $\frac{1}{n^c}$ & for some $c \in \mathbb{R}^+$ & $\ceil{\frac{1}{\epsilon^c}}$ \\
                        $\frac{1}{c^n}$ & for some $c \in \mathbb{R}$, such that $|c| > 1$ & $\ceil{\text{log}_c(\frac{1}{\epsilon})}$ \\
                        $c^n$ & for some $c \in \mathbb{R}$, such that $|c| < 1$ & $\ceil{\text{log}_c(\epsilon)}$ \\
                        $\frac{1}{n!}$ & & \\
                        $\frac{1}{\text{ln}(n)}$ & $n > 1$ & $\ceil{e^{\frac{1}{\epsilon}}}$
                    \end{tabular}
                \end{center}
            \subsubsection*{Combining Sequences}
                Suppose that $a_n \to a$, and $b_n \to b$, as $\limit{n}{\infty}$;
                \begin{itemize}
                    \itemsep0em
                    \item $\limit{n}{\infty}\lambda a_n = \lambda a$ given $\lambda \in \mathbb{R}$
                    \item $\limit{n}{\infty}(a_n + b_n) = a + b$
                    \item $\limit{n}{\infty}(a_nb_n) = ab$
                    \item $\limit{n}{\infty}{\frac{a_n}{b_n}} = \frac{a}{b}$ given $b \neq 0$
                \end{itemize}
                \medskip

                For example, the sequence $a_n = \frac{4n^2 + 3n}{7n^2 + 3n - 2}$, it's trivial to find the limit as $n \to \infty$ by inspection as $\frac{4}{7}$. However, if we divide every term by $n^2$, we end up with $a_n = \frac{4 + \frac{3}{n}}{7 + \frac{3}{n} - \frac{2}{n^2}}$, which we can break into $a_n = \frac{b_n}{c_n}$, where $b_n = 4 + \frac{3}{n}$, and $c_n = 7 + \frac{3}{n} - \frac{2}{n^2}$. Using the rules from above, we can further break down the sequences (but I really cannot be bothered to do so), to a point where we get $a = \frac{4 + 0}{7 + 0 - 0} = \frac{4}{7}$.
            \subsubsection*{Sandwich Theorem}
                In the sandwich theorem, where we want to prove that $\limit{n}{\infty}a_n = l$, we need two sequences that form upper, and lower bounds for $a_n$, namely $u_n$, and $l_n$. If such sequences exist, and satisfy $\exists N \in \mathbb{N}[\forall n \geq N [l_n \leq a_n \leq u_n]]$, and both $\limit{n}{\infty}u_n = \limit{n}{\infty}l_n = l$, then we get $\limit{n}{\infty}a_n = l$.
                \medskip

                For example, consider the sequence $a_n = \frac{\text{cos}(n)}{n}$. We know that $-1 \leq \text{cos}(n) \leq 1$, therefore $l_n = -\frac{1}{n} \leq a_n \leq \frac{1}{n} = u_n$. However, as both $u_n \to 0$, and $l_n \to 0$, when $n \to \infty$, it follows that $\limit{n}{\infty}a_n = 0$.
                \medskip

                The sandwich theorem can be proven by finding ${N_\epsilon}_l$, and ${N_\epsilon}_u$ for $l_n$, and $u_n$ respectively. As they both converge to the same limit, we can justify that for some $N_\epsilon = \text{max}({N_\epsilon}_l, {N_\epsilon}_u)$, any $n > N_\epsilon$, we have $|l_n - l| < \epsilon$, and $|u_n - l| < \epsilon$. By removing the modulus signs, we get $-\epsilon < l_n - l < \epsilon$, and $-\epsilon < l_n - l < \epsilon$. By rearranging this, and knowing $l_n < u_n$ by definition, we have $l - \epsilon < l_n < u_n < l + \epsilon$. In order to apply the sandwich theorem, we have to assume $l_n \leq a_n \leq u_n$, hence it follows $l - \epsilon < l_n \leq a_n \leq u_n < l + \epsilon$. This can then be arranged to get $-\epsilon < a_n - l < \epsilon$, thus for all $n > N_\epsilon$, $|a_n - l| < \epsilon$.
            \subsubsection*{Ratio Tests}
                The follow tests allow us to check if a sequence $a_n$ converges to 0, or diverges. If we want to verify a seqence $\limit{n}{\infty}b_n = l$, where $l \neq 0$, we can reformulate it as $a_n = b_n - l$, and prove it for $a_n$.
                \medskip

                If $|\frac{a_{n+1}}{a_n}| \leq c < 1$, for $c \in \mathbb{R}$, where $n$ is sufficiently large, then $\limit{n}{\infty}a_n = 0$. Conversely, if $|\frac{a_{n+1}}{a_n}| \geq c > 1$, then $a_n$ diverges.
                \medskip

                Suppose $a_n = 2^{-n}$, in order to show it converges, we want to find some $c$, such that $|\frac{2^{-(n + 1)}}{2^{-n}}| \leq c < 1$. By arithmetic, we can say $|\frac{2^{-(n + 1)}}{2^{-n}}| = \frac{1}{2} \leq c < 1$. As there exists real $c = \frac{1}{2} < 1$, we can conclude that $a_n$ converges to 0.
                \medskip

                However, we cannot prove that $a_n = \frac{1}{n!}$ converges, despite it being a fairly straightforward proof with just the standard ration tests. For example, we would end up with $|\frac{a_{n + 1}}{a_n}| = \frac{1}{n + 1}$. While this is fairly conclusive that it's less than 1, we don't get a constant $c$ which sits between it, and 1.
                \medskip

                Instead of analysing the behaviour of consequtive terms, we take the limit as $r = \limit{n}{\infty}|\frac{a_{n + 1}}{a_n}|$. If $r < 1$, it converges to 0, but if $r > 1$, it then diverges. Applying this to the previous factorial example, we can clearly see that $\limit{n}{\infty}\frac{1}{n + 1} = 0$, therfore $a_n$ converges to 0.
            \subsubsection*{Manipulating Absolute Values}
                A useful decomposition with absolute limits is $|x| < a \Leftrightarrow -a < x < a$. Further useful properties are;
                \begin{itemize}
                    \itemsep0em
                    \item $|xy| = |x| \cdot |y|$
                    \item $|\frac{x}{y}| = \frac{|x|}{|y|}$
                    \item $|x + y| \leq |x| + |y|$ \hfill triangle inequality
                    \item $|x - y| \geq ||x| - |y||$
                \end{itemize}
            \subsubsection*{Properties of Real Numbers}
                Suppose we have some set $S$ of real numbers, then the following properties hold;
                \begin{itemize}
                    \itemsep0em
                    \item $u$ is an upper bound on $S$ if $\forall s \in S [u \geq s]$
                    \item $l$ is a lower bound on $S$ if $\forall s \in S [l \leq s]$
                    \item $S$ is bounded above if it has an upper bound, bounded below if it has a lower bound, and bounded if it has both
                    \item a set may have no bounds, or many, therefore we say $\text{sup}(S)$ is the least upper bound of $S$, and $\text{inf}(S)$ to denote the greatet upper bound of $S$
                    \item if a set has no upper bound, then $\text{sup}(S) = \infty$, and similarly if there is no lower bound, then $\text{inf}(S) = -\infty$
                \end{itemize}
                The fundamental axiom of analysis states that if an increasing sequence of reals is bounded above, then it must converge.
        \subsection*{Series}
            A series is a sum of a sequence - we consider an infinite series as a summation in the form $S = \summation{n = 1}{\infty}{a_n}$.
            \smallskip

            We can also take a partial sum, where we sum from 1 to $n$ instead of $\infty$ as $S_n = \summation{i = 1}{n}{a_i}$.
            \medskip

            Since we're dealing with finite numbers at this point, we can consider $S_n$ as a sequence - thus whether a series converges, or diverges, depends on whether the sequence of partial sums converge, or diverge. If we know that $\forall i \geq 1 [a_i > 0]$, then the parital sum is an increasing sequence where $S_1 < S_2 < S_3 < ...$, if this is bounded above, then it must converge (from the axiom of analysis).
            \medskip

            For a series to have a chance of converging, we require $\limit{n}{\infty}a_n = 0$. However, just proving that is insufficient for concluding a series converges. It's important to note that we don't really care about the first values of a series, only how it behaves on large numbers, as it tends to infinity.
            \smallskip

            If $S$ converges, or diverges, then $\summation{n = N}{\infty}{a_n}$ also converges, or diverges, as it's equivalent to $S - S_{N - 1}$.
            \smallskip

            \subsubsection*{Geometric Series}
                To determine whether a limit $G$ exists for the geometric series, we need to determine that the partial sums converge. Hence we do the proof on the right hand side. It's important to note that the only term that changes based on $n$ is $x^{n + 1}$, therfore we can conclude that $G$ must converge when $|x| < 1$ (from earlier results).
                \smallskip

                Let us represent the geometric series as $G = \summation{n = 1}{\infty}{x^n}$. Should a limit $G$ exist - see the left side;
                \begin{center}
                    \vspace{-\baselineskip}
                    \begin{minipage}{0.485\textwidth}
                        \begin{align*}
                            G & = \summation{n = 1}{\infty}{x^n} \\
                            & = x + \summation{n = 2}{\infty}{x^n} \\
                            & = x + x\summation{n = 1}{\infty}{x^n} \\
                            & = x + xG \\
                            & = \frac{x}{1 - x}
                        \end{align*}
                    \end{minipage} \
                    \begin{minipage}{0.485\textwidth}
                        \begin{align*}
                            G_n & = \summation{i = 1}{n}{x^i} \\
                            & = x + \summation{i = 2}{n}{x^i} \\
                            & = x + x\summation{i = 1}{n - 1}{x^i} \\
                            & = x + x(G_n - x^n) \\
                            & = \frac{x - x^{n + 1}}{1 - x}
                        \end{align*}
                    \end{minipage}
                \end{center}
            \subsubsection*{Harmonic Series}
                The harmonic series is often used in comparison tests to prove that another series diverges.
                \smallskip

                Let harmonic series be written as $S = \summation{n = 1}{\infty}{\frac{1}{n}} = 1 + \frac{1}{2} + \underbrace{(\textstyle\frac{1}{3} + \frac{1}{4})}_{> \frac{1}{4} + \frac{1}{4}} + \underbrace{(\textstyle\frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8})}_{> \frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8}} + ... > 1 + \frac{1}{2} + \frac{1}{2} + \frac{1}{2} + ...$
                \smallskip

                Therefore, with partial sums, we get $S_n = \summation{i = 1}{2^n}{\frac{1}{i}} > 1 + \frac{n}{2}$. As $S_n$ clearly diverges, $S$ must also diverge.
            \subsubsection*{Inverse Squares}
                Suppose we have the sum of squares $S = \summation{n = 1}{\infty}{\frac{1}{n^2}}$, and an auxiliary partial sum $T_n = \summation{i = 1}{n}{\frac{1}{i(i + 1)}}$.
                \smallskip

                To prove that $S$ converges, we should consider $T_n = 1 - \frac{1}{n + 1}$ (write out the first few terms and a pattern should be spotted). Hence $\limit{n}{\infty}T_n = 1$. Using this, we can argue how the partial sums of the series of inverse squares are bounded. It's trivial to say the following inequality; $\frac{1}{i(i + 1)} < \frac{1}{i^2} < \frac{1}{i(i - 1)}$.
                \smallskip

                If we sum this inequality from $i = 2$ to $n$, we can then justify the following - it's important to note that the sums on the left, and right, differ by only the first, and last term (therefore we can reduce it to a partial sum);
                \medskip

                $\phantom{\Leftrightarrow} \frac{1}{2(3)} + \frac{1}{3(4)} + \frac{1}{4(5)} + ... + \frac{1}{n(n + 1)} < \summation{i = 2}{n}{\frac{1}{i^2}} < \frac{1}{1(2)} + \frac{1}{2(3)} + \frac{1}{3(4)} + ... + \frac{1}{n(n - 1)}$
                \smallskip

                $\Leftrightarrow T_n - \frac{1}{2} < \summation{i = 2}{n}{\frac{1}{i^2}} < T_{n - 1}$
                \smallskip

                $\Leftrightarrow T_n + \frac{1}{2} < \summation{i = 1}{n}{\frac{1}{i^2}} < T_{n - 1} + 1$
                \medskip

                $\Leftrightarrow \frac{3}{2} + \frac{1}{n + 1} < S_n < 2 + \frac{1}{n}$
                \medskip

                Therefore, it follows that the partial sums are bounded by $\frac{3}{2}$, and 2. The existance of an upper bound suggests the sequence converges, therefore the series must also converge.
            \subsubsection*{Important Series}
                These examples will be useful for the comparison tests covered later on. We can use these results to aid us in proving whether some other series converges, or diverges.
                \begin{center}
                    \begin{tabular}{l|l|l|l}
                        name & $S$ & condition & diverges or converges \\
                        \hline
                        harmonic series & $\summation{n = 1}{\infty}{\frac{1}{n}}$ & & diverges \\
                        harmonic primes & $\summation{p : \text{prime}}{}{\frac{1}{p}}$ & & diverges \\
                        geometric series & $\summation{n = 1}{\infty}{x^n}$ & $|x| \geq 1$ & diverges \\
                        geometric series & $\summation{n = 1}{\infty}{x^n}$ & $|x| < 1$ & converges \\
                        inverse squares series & $\summation{n = 1}{\infty}{n^2}$ & & converges \\
                        ??? & $\summation{n = 1}{\infty}{\frac{1}{n^c}}$ & $c > 1$ & converges
                    \end{tabular}
                \end{center}
            \subsubsection*{Convergence Tests}
                For brevity, suppose we have the following;
                \begin{itemize}
                    \itemsep0em
                    \item $S = \summation{i = 1}{\infty}{a_i}$ \hfill a series we want to reason about, and $a_i \geq 0$
                    \item $\summation{i = 1}{\infty}{c_i}$ \hfill a series we have already established converges to $c$
                    \item $\summation{i = 1}{\infty}{d_i}$ \hfill a series we have already established diverges
                \end{itemize}
                In the \textbf{comparison test}, we have some $\lambda > 0$, and a $N \in \mathbb{N}$. If $\forall i > N [a_i \leq \lambda c_i]$, then $S$ converges. On the other hand, if $\forall i > N [a_i \geq \lambda d_i]$, then $S$ diverges.
                \medskip

                To avoid having to find such a $\lambda$, we can use the \textbf{limit comparison test}, in which we can say if $\limit{i}{\infty}\frac{a_i}{c_i}$ exists, then $S$ converges, but if $\limit{i}{\infty}\frac{d_i}{a_i}$ exists, then $S$ diverges.
                \medskip

                Another useful test for finding convergence, without needing a pre-established series, is \textbf{D'Alembert's ratio test}. Once again, we consider this from some point $N \in \mathbb{N}$, where the cases are;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item $\forall i \geq N [\frac{a_{i + 1}}{a_i} \geq 1]$, then $S$ diverges
                    \item there exists a $k$ such that $\forall i \geq N [\frac{a_{i + 1}}{a_i} \leq k < 1]$, then $S$ converges
                \end{enumerate}
                This is similar to the comparison test for sequences, and once again the requirement of finding some $k$ between the ratio, and 1 can be avoided by taking limits. This leads to \textbf{D'Alembert's limit ratio test}, in which we have the following cases;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item $\limit{i}{\infty}\frac{a_{i + 1}}{a_i} > 1$, then $S$ diverges
                    \item $\limit{i}{\infty}\frac{a_{i + 1}}{a_i} = 1$, then it is inconclusve
                    \item $\limit{i}{\infty}\frac{a_{i + 1}}{a_i} < 1$, then $S$ converges
                \end{enumerate}
                The second case, in which it is inconclusive, can be illustrated by setting $a_n = 1$, which obviously causes $S$ to diverge, or by setting $a_n = \frac{1}{n^2}$ which causes $S$ to converge. However, both lead to a limit test of 1.
                \medskip

                The \textbf{integral test} for a sequence, where $a_n = f(n)$ is a decreasing function relies on the following idea;
                \begin{center}
                    $\summation{n = 1}{\infty}{a_{n + 1}} < \defint{1}{\infty}{f(x)}{x} < \summation{n = 1}{\infty}{a_n}$
                \end{center}
                In practice, if the integral were to diverge once evaluated, the series would also diverge by the right hand inqeuality, but if it were to converge, then the series would converge with the left hand inequality.
            \subsubsection*{Absolute Convergence}
                Consider a series with negative $a_n$ values, and another series $S^\prime = \summation{n = 1}{\infty}{|a_n|}$. If $S^\prime$ converges, so does $S$.
                \smallskip

                However, the same isn't true the other way around, for example, when we have $a_n = (-1)^{n - 1} \frac{1}{n}$, $S$ converges to $\text{ln}(2)$, however, doing this with the absolute series, $S^\prime$, it would diverge, as if it were the normal harmonic series. In order to test for \textbf{absolute} convergence - we have the following cases;
                \begin{enumerate}[1.]
                    \itemsep0em
                    \item if $\limit{n}{\infty}|\frac{a_{n + 1}}{a_n}| > 1$ then $\summation{n = 1}{\infty}{a_n}$ diverges
                    \item if $\limit{n}{\infty}|\frac{a_{n + 1}}{a_n}| = 1$ then $\summation{n = 1}{\infty}{a_n}$ can converge, or diverge
                    \item if $\limit{n}{\infty}|\frac{a_{n + 1}}{a_n}| < 1$ then $\summation{n = 1}{\infty}{a_n}$ converges absolutely, and therefore also converges
                \end{enumerate}
            \subsubsection*{Power Series, and Radius of Convergence}
                We can represent a function as a power series; $f(x) = \summation{n = 0}{\infty}{a_nx^n}$.
                \smallskip

                Consider the case where $f(x) = \frac{x}{1 - x}$, which has the expansion $\summation{n = 1}{\infty}{x^n}$, which only converges for $|x| < 1$.
                \smallskip

                Take the power series $S = \summation{n = 1}{\infty}{n^2 x^n}$, and apply the \textbf{D'Alembert ratio test}, we'd get the following;
                \begin{align*}
                    \limit{n}{\infty} |\frac{a_{n + 1}}{a_n}| & = \limit{n}{\infty}|\frac{(n + 1)^2 x^{n + 1}}{n^2 x^n}| \\
                    & = \limit{n}{\infty} |x(1 + \frac{1}{n})^2| \\
                    & = |x|
                \end{align*}
                As we want to establish convergence, we set the result $|x| < 1$, therefore it follows that the ratio of convergence for this particular power series is 1.
        \subsection*{Power Series}
            As previously mentioned, a function can be represnted in a series expansion on $x$; $f(x) = \summation{n = 0}{\infty}{a_nx^n}$.
            \subsubsection*{Maclaurin Series}
                Let some function $f(x) = a_0 + a_1x + a_2x^2 + a_3x^3 + ...$, then we can easily work out $a_0$, by setting $x = 0$, such that $f(0) = a_0$. By differentiating the function, we get $f^\prime(x) = a_1 + 2a_2x + 3a_3x^2 + ...$, therefore it follows thats $f^\prime(0) = a_1$. By differentiating again,we get $f^{\prime\prime}(x) = 2a_2 + 2 \cdot 3a_3x + ...$, therefore it follows that $\frac{f^{\prime\prime}(0)}{2!} = a_2$. Hence, generally $a_n = \frac{f^{(n)}(0)}{n!}$, where $n \geq 0$.
                \medskip

                A \textbf{Maclaurin series} is the representation of $f(x) = \summation{i = 0}{\infty}{a_ix^i}$.


\end{document}
